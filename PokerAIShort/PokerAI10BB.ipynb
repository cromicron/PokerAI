{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9431e6d4-b0d7-4bf1-a845-59012120ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from Agent2 import Agent2, ReplayBuffer2\n",
    "from Agent import Agent, ReplayBuffer\n",
    "from PokerGame import HUPoker\n",
    "from TransformVillain import transformStateVillain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "625467e1-0f0a-42d3-980f-d45525538605",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "gamma = 1\n",
    "n_actions = 12\n",
    "epsilon = 1\n",
    "batch_size = 32\n",
    "input_dims = (102,)\n",
    "stacksize = 10\n",
    "fname = 'trainedModels/PokerAI10BB.h5'\n",
    "layerSizes = (256,128,64, 32, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ff1db9-4fdd-4b04-89cd-c60af63c69d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "newAgent = Agent2(lr, gamma, n_actions, 0.2, batch_size, input_dims, stacksize, fname = fname, handEval=True, layerSizes=layerSizes,mem_size=100000)\n",
    "oldAgent = Agent2(lr, gamma, n_actions, 0, batch_size, input_dims, stacksize, fname = fname, handEval=True, layerSizes=layerSizes,mem_size=0)\n",
    "newAgent.load_model()\n",
    "oldAgent.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "661f865a-f47f-4649-95eb-8b268bbe7170",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_hero = stacksize\n",
    "stack_villain = stacksize\n",
    "agentHero = newAgent\n",
    "agentVillain = oldAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dfda127-0de2-4604-b9a6-fc34b73edef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = HUPoker(stack_hero, stack_villain, agentHero, agentVillain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2375c19f-c29c-4387-80c4-d1551c5518e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal hand by hand approach in learning\n",
    "import numpy as np\n",
    "\n",
    "n_rounds = 1001\n",
    "score = 0\n",
    "for i in range(n_rounds):\n",
    "\n",
    "    done =True\n",
    "\n",
    "    while done:\n",
    "        observation, done = game.reset()\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        error = False\n",
    "        action = agentHero.choose_action(observation)\n",
    "        observation = np.append(observation,[game.pwinHero, game.plooseHero, game.pwinAvg, game.plooseAvg, game.stdWinAvg])\n",
    "\n",
    "        try: \n",
    "            done = game.step(action) #sometimes the chosen actions lead to too many moves on a street (over 20) This happens when players both chose to engage in minraise battles.\n",
    "                                    #we want to severely punish this behavior.\n",
    "        except IndexError: #error happens when more than 20 actions are attepted on a single street.\n",
    "            done = True\n",
    "            error = True\n",
    "\n",
    "        observation_ = game.observation #if street changed from \n",
    "        observation_ = np.append(observation_,[game.pwinHero, game.plooseHero, game.pwinAvg, game.plooseAvg, game.stdWinAvg])\n",
    "        if not done:\n",
    "            reward = 0\n",
    "        else:\n",
    "            if error:\n",
    "                reward = -stacksize\n",
    "            else:\n",
    "                reward = 0.5+game.stack_sb - game.starting_hero if game.position == 0 else 1+game.stack_bb - game.starting_hero #to take into account the blinds are posted anyway regardless of action.\n",
    "        score += reward - 0.5 if game.position == 0 else reward - 1\n",
    "        avgScore = round(score//(i+0.00001),2)\n",
    "        agentHero.store_transition(observation, action, reward, observation_, done)\n",
    "        observation = game.observation\n",
    "        \n",
    "        \n",
    "        loss = agentHero.learn()\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    print(\"hands played: \", i+1, \"reward round:\", reward, \"total score:\", score, \"avg score\", avgScore, \"epsilon\", agentHero.epsilon)\n",
    "    if i %10 ==0:\n",
    "        states, actions, rewards, states_, dones = agentHero.memory.sample_buffer(2)\n",
    "        q_eval = agentHero.q_eval.predict(states)\n",
    "        pos = states[0:1][0][0]\n",
    "        street = states[0:1][0][3]\n",
    "        hand = (states[0:1][0][4],states[0:1][0][10],states[0:1][0][5],states[0:1][0][11])\n",
    "        pot = states[0:1][0][7]\n",
    "        board = states[0:1][0][-15:-5]\n",
    "        print(\"pos\", pos, \"street\", street)\n",
    "        print(\"hand\", hand)\n",
    "        print(\"pot\", pot)\n",
    "        print(\"board\",board)\n",
    "        print(q_eval[0:1])\n",
    "\n",
    "\n",
    "    if i%1000 == 0:\n",
    "        #agentHero.save_model()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fbc1acc-423c-4b4a-8662-c3aa585d2c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 8 engines with <class 'ipyparallel.cluster.launcher.LocalEngineSetLauncher'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Cluster(cluster_id='1643645003-eral', profile='default', controller=<running>, engine_sets=['1643645004'])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipyparallel as ipp\n",
    "cluster = ipp.Cluster(n=8)\n",
    "await cluster.start_cluster() # or cluster.start_cluster_sync() without await"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e3d756e-f718-48e4-bc50-6bbb6331f48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 8/8 [00:04<00:00,  1.71engine/s]\n"
     ]
    }
   ],
   "source": [
    "rc = cluster.connect_client_sync()\n",
    "rc.wait_for_engines(n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddc79fc6-be6b-4844-ae0f-aac9aa683ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-31 17:03:31.292646: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e5eea2e1-6aa2-408a-86e1-8c4856a3e99f/assets\n",
      "INFO:tensorflow:Assets written to: ram://6fb9cb25-0aad-440d-a34b-e4a046b71974/assets\n",
      "INFO:tensorflow:Assets written to: ram://d750dafc-2219-47b5-9f7f-62fcf7beaa3b/assets\n",
      "INFO:tensorflow:Assets written to: ram://6f038c4c-6209-4ec9-b4ba-05e003c03fdf/assets\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import pickle\n",
    "fname = 'trainedModels/PokerAI10BB.h5'\n",
    "layerSizes = (256,128,64, 32, 16)\n",
    "\n",
    "nDec = 10\n",
    "lr = 0.00001\n",
    "epsilon = 0# not meaningful for agentLearn, because he is not playing against anyone. Still all parameters must be included in agent.\n",
    "batch_size = 16\n",
    "input_dims = (102,)\n",
    "stacksize = 10\n",
    "nCores = 8\n",
    "agentLearn = Agent2(gamma = gamma, n_actions=n_actions,lr = lr, batch_size = batch_size, input_dims=input_dims, stacksize=stacksize, epsilon = 0, fname = fname, layerSizes=layerSizes, mem_size = nDec*nCores)\n",
    "\n",
    "try:\n",
    "    agentLearn.load_model()\n",
    "    print('Model loaded')\n",
    "except:\n",
    "    print('no Model loaded')\n",
    "K.set_value(agentLearn.q_eval.optimizer.learning_rate, lr)\n",
    "weightsHero = agentLearn.q_eval.get_weights()\n",
    "\n",
    "agentHero= Agent2(lr = 0.1, gamma=1, n_actions=12,epsilon=0.1, batch_size=16,\n",
    "        input_dims=(102,), stacksize =stacksize, \n",
    "        mem_size=nDec, \n",
    "        epsilon_end=0.05,\n",
    "        fname=fname, handEval=True,layerSizes=layerSizes)\n",
    "agent_vil= Agent2(lr = 0.1, gamma=1, n_actions=12,epsilon=0, batch_size=16,\n",
    "    input_dims=(102,), stacksize =stacksize, \n",
    "    mem_size=2, \n",
    "    epsilon_end=0.05,\n",
    "    fname=fname,layerSizes=layerSizes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "env = HUPoker(stacksize, stacksize, agentHero, agent_vil)\n",
    "rc[:]['agentHero']=agentHero\n",
    "rc[:]['agent_vil']=agent_vil\n",
    "rc[:]['weightsHero']=weightsHero\n",
    "\n",
    "#We want a diversity of opponents in the environment to prevent overfitting, and only update the weights of Villains from time to time, to keep the environment stable enough.\n",
    "#The current weights for villain are saved in the weights file.\n",
    "try:\n",
    "    with open(\"weightsVil10BB.txt\", \"rb\") as weightsFile:   # Unpickling\n",
    "        newWeights = pickle.load(weightsFile)\n",
    "    for i in range(len(newWeights)):\n",
    "        rc[i]['weightsVil']=newWeights[i]\n",
    "\n",
    "except:\n",
    "    rc[:]['weightsVil']=weightsHero\n",
    "    print(\"exception!\")\n",
    "\n",
    "\n",
    "rc[:]['ReplayBuffer2']= ReplayBuffer2\n",
    "rc[:]['env']= env\n",
    "rc[:]['nDec'] = nDec\n",
    "rc[:]['stacksize']=stacksize\n",
    "\n",
    "\n",
    "def play(instance):\n",
    "    import numpy as np\n",
    "\n",
    "    agentHero.q_eval.set_weights(weightsHero)\n",
    "    agent_vil.q_eval.set_weights(weightsVil)\n",
    "    n_rounds = 1\n",
    "    env.reset()\n",
    "\n",
    "    for i in range(n_rounds):\n",
    "        agentHero.memory = ReplayBuffer2(nDec, (107,))\n",
    "\n",
    "        while agentHero.memory.mem_cntr < nDec:\n",
    "\n",
    "            done =True\n",
    "\n",
    "            while done:\n",
    "                observation, done = env.reset()\n",
    "                hand = env.holecards\n",
    "\n",
    "            while not done:\n",
    "\n",
    "                error = False\n",
    "                action = agentHero.choose_action(observation)\n",
    "                observation = np.append(observation,[env.pwinHero, env.plooseHero, env.pwinAvg, env.plooseAvg, env.stdWinAvg])\n",
    "\n",
    "                try: \n",
    "                    done = env.step(action) #sometimes the chosen actions lead to too many moves on a street (over 20) This happens when players both chose to engage in minraise battles.\n",
    "                                            #we want to severely punish this behavior.\n",
    "                except IndexError: #error happens when more than 20 actions are attepted on a single street.\n",
    "                    done = True\n",
    "                    error = True\n",
    "\n",
    "                observation_ = env.observation\n",
    "                observation_ = np.append(observation_,[env.pwinHero, env.plooseHero, env.pwinAvg, env.plooseAvg, env.stdWinAvg])\n",
    "                if not done:\n",
    "                    reward = 0\n",
    "                else:\n",
    "                    if error:\n",
    "                        reward = -stacksize\n",
    "                    else:\n",
    "                        reward = 0.5+env.stack_sb - env.starting_hero if env.position == 0 else 1+env.stack_bb - env.starting_hero #to take into account the blinds are posted anyway regardless of action.\n",
    "\n",
    "                agentHero.store_transition(observation, action, reward, observation_, done)\n",
    "                    #If the agent is playing against himself to learn, we can use villains play to train also. Everything except for villains hand can be derived from the observation. So we only have to save villains cards.\n",
    "\n",
    "                observation = env.observation\n",
    "\n",
    "\n",
    "        memoryDict = {'states': agentHero.memory.state_memory[:nDec], 'states_': agentHero.memory.new_state_memory[:nDec], \n",
    "                      'rewards':agentHero.memory.reward_memory[:nDec], 'actions': agentHero.memory.action_memory[:nDec], \n",
    "                      'terminals': agentHero.memory.terminal_memory[:nDec]}\n",
    "\n",
    "        agentHero.memory.mem_cntr =0\n",
    "    return memoryDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2c14166-4d5b-487d-91b8-7996131084cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[ 0.  1.  0.  2.  4. 13.] [[-7.7907867  1.1726943 -9.967381  -9.958546  -9.79442   -9.960839\n",
      "  -9.946443  -9.995526  -9.99062   -9.941962  -9.896823  -9.924006 ]]\n",
      "[ 0.  7.  7.  3.  8. 13.] [[-5.4198103   1.9907929  -1.4511646   0.05822321 -5.5303807  -4.3762226\n",
      "  -1.1364164   0.05092499 -0.57884383 -0.44234785 -3.3161635  -5.1548615 ]]\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.2092\n",
      "exchanging weights of 1\n",
      "[[ 0.13891762  0.08042129  0.07012077 ... -0.12694766  0.01740397\n",
      "   0.05817319]\n",
      " [ 0.17516549  0.03936422 -0.05128472 ...  0.00323276  0.02193645\n",
      "   0.1100174 ]\n",
      " [ 0.13496321 -0.06152176  0.04033399 ...  0.03131422 -0.0251929\n",
      "  -0.08066276]\n",
      " ...\n",
      " [ 0.0882116  -0.04021711 -0.0473093  ...  0.03347914  0.02602953\n",
      "   0.07811441]\n",
      " [ 0.11722501 -0.10244302  0.0959695  ... -0.05610787  0.05985689\n",
      "  -0.09885324]\n",
      " [ 0.048425    0.09800332 -0.06000081 ...  0.0316143  -0.11625958\n",
      "  -0.01036678]]\n",
      "[[ 0.13850917  0.07992314  0.06913903 ... -0.12545016  0.01711711\n",
      "   0.05705527]\n",
      " [ 0.17504795  0.03951159 -0.05156729 ...  0.00361738  0.02098753\n",
      "   0.10995629]\n",
      " [ 0.13493286 -0.06110438  0.04001645 ...  0.03141897 -0.02620837\n",
      "  -0.08020692]\n",
      " ...\n",
      " [ 0.08809458 -0.039995   -0.04733214 ...  0.03349125  0.02571337\n",
      "   0.07833067]\n",
      " [ 0.11676752 -0.10245346  0.0956275  ... -0.05567842  0.05941088\n",
      "  -0.09875693]\n",
      " [ 0.04837724  0.09834288 -0.05981735 ...  0.03141129 -0.11641587\n",
      "  -0.0100168 ]]\n",
      "1\n",
      "[ 1.  7.  7.  1.  9. 10.] [[-9.540833   2.1074169 -1.2534609 -0.4022545  1.476261   1.1339223\n",
      "   0.9101175 -3.8305616 -1.8318044  1.6456665  0.7598435 -6.469607 ]]\n",
      "[1. 7. 9. 0. 2. 8.] [[ 1.0924649   1.7258551  -0.7298466  -0.6282955  -2.933425   -1.5664364\n",
      "   0.07666211 -1.1744659  -0.69637907 -1.5168239  -1.8385732  -2.1567168 ]]\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3585\n",
      "2\n",
      "[ 1.  1.  7.  2. 12. 12.] [[-0.1785825  4.227231  -8.89638   -8.857003  -9.318396  -9.317157\n",
      "  -8.203028  -8.518752  -8.344878  -8.256396  -9.481404  -8.499633 ]]\n",
      "[ 0.  9.  7.  0.  8. 14.] [[-1.8458723   1.5568446   0.9222284   0.5442937  -1.933077    0.20951879\n",
      "   0.58126026 -0.41463223 -0.09032018  0.7062377  -0.31878918 -2.4281547 ]]\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1934\n",
      "3\n",
      "[ 0.  1.  0.  3. 11. 14.] [[-7.001606    0.79547906 -9.906505   -9.8816     -9.740468   -9.924444\n",
      "  -9.842545   -9.975041   -9.966384   -9.796052   -9.772026   -9.807097  ]]\n",
      "[ 0.  9.  7.  0.  4. 13.] [[-2.374546    0.9792924   1.0445429   0.5711801  -1.8877795  -0.02568032\n",
      "   0.58574396 -1.0169147  -0.68975186  0.44016632  0.4028105  -2.4636726 ]]\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3644\n",
      "4\n",
      "[ 0.  8.  4.  0.  7. 12.] [[-4.1018896  -0.14037932  0.6540605   1.4059747  -3.8417616  -0.95856535\n",
      "  -0.5112738   0.20627502 -0.81927717  1.9873126  -0.18938717 -3.6099515 ]]\n",
      "[ 1.  0.  1.  3. 11. 11.] [[-8.909811  3.084021 -9.851849 -9.753295 -9.022919 -9.730951 -9.581778\n",
      "  -9.948684 -9.938607 -9.256466 -9.483016 -9.803841]]\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2712\n",
      "5\n",
      "[0.  9.5 9.  0.  3.  4. ] [[-0.36581668  0.99578536  0.6850204   0.48137036 -1.5685892  -0.2459253\n",
      "   0.5972835  -0.5403965   0.6574473  -1.1494766  -0.6536358  -0.71605504]]\n",
      "[0.  9.5 9.  0.  2.  3. ] [[-0.5349331   0.83806396  0.61749345  0.39015126 -1.6747141  -0.41214946\n",
      "   0.56414825 -0.69379425  0.4975543  -1.2725391  -0.5925964  -0.78854287]]\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7099\n",
      "6\n",
      "[ 0.  9.  7.  0.  8. 12.] [[-2.0671577   1.0961671   0.92920333  0.69665873 -1.9448149   0.14600162\n",
      "   0.70989376 -0.6864408  -0.2631973   0.743835   -0.02453657 -2.6540508 ]]\n",
      "[ 0.   9.5  9.   0.  10.  10. ] [[-0.4652567   1.6222013   0.63867515  0.4016563  -1.5233232   0.41027516\n",
      "   0.7001882  -0.18010968  0.63646317 -0.03498818 -1.0345585  -0.6975372 ]]\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7444\n",
      "7\n",
      "[ 1.  7.  7.  1.  4. 11.] [[-9.703518    1.3516946  -1.625282   -0.10659944  1.1972059   0.59668386\n",
      "   0.46392292 -4.2919474  -2.3030038   1.0912269   1.0074728  -6.6216574 ]]\n",
      "[ 1.  7.  9.  0.  8. 10.] [[ 1.4100308   2.483547   -0.98006356 -0.8773806  -2.5627425  -1.112687\n",
      "   0.7910851  -1.3605793  -0.75657517 -0.49115366 -2.3166127  -2.4701695 ]]\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9359\n",
      "8\n",
      "[ 0.  7.  7.  3.  7. 13.] [[-8.991042    0.6551645  -1.5147358   0.5495966  -3.5617995  -3.0651789\n",
      "  -0.9175741  -2.3123293  -2.3891554   0.73903805 -0.63020533 -6.388752  ]]\n",
      "[ 0.  7.  7.  3.  5. 13.] [[-6.4950566   0.58891606 -1.1171232   0.46765608 -5.659451   -4.506135\n",
      "  -1.7822847  -0.11638298 -1.3092046  -0.41656274 -2.0959978  -5.2015734 ]]\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9315\n",
      "9\n",
      "[0. 9. 7. 0. 3. 7.] [[-1.3962532  -0.28600347  0.88265294  0.9222222  -2.721729   -0.940276\n",
      "   0.3790229  -1.3531305  -1.2780039  -0.01004544  0.6865645  -2.3174233 ]]\n",
      "[ 0.   9.5  9.   0.   8.  12. ] [[ 0.19749351  1.444549    0.85713553  0.7058274  -1.7881991   0.00392335\n",
      "   0.6348706  -0.03467485  0.6828987  -0.18495032 -0.8961365  -0.75327456]]\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0398\n",
      "10\n",
      "[ 0.   9.5  9.   0.   8.  11. ] [[-0.0132642   1.2841917   0.8626365   0.6869546  -1.7520334   0.06085579\n",
      "   0.659523   -0.1635747   0.5799459  -0.17658684 -0.7487991  -0.77758604]]\n",
      "[ 0.  7.  7.  1.  8. 11.] [[-6.248419    0.03519112 -1.0613106   0.09730968 -4.5901837  -3.6395764\n",
      "  -1.1699342  -1.9241974  -2.9443882  -0.02936121 -0.5287251  -5.102542  ]]\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6313\n",
      "11\n",
      "[ 0.  8.  4.  0.  4. 12.] [[-3.7951877  -0.65331167  0.7416551   1.3596863  -4.3978553  -1.4240832\n",
      "  -0.7242191   0.2853584  -0.9917352   1.7371521  -0.08918468 -3.386096  ]]\n",
      "[ 1.  7.  7.  1.  7. 10.] [[-9.868038    2.4867716  -1.3028623  -0.97371614  3.6369262   2.510847\n",
      "   1.3829697  -4.8161883  -2.162856    2.201103    2.0290608  -7.2870107 ]]\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9191\n",
      "12\n",
      "[0.  9.5 9.  0.  4.  8. ] [[-0.02688536  0.88361293  0.94823205  0.8096092  -1.6901838  -0.15867159\n",
      "   0.6360537  -0.32826185  0.5875977  -0.60225487 -0.43020594 -0.78071266]]\n",
      "[ 1.  7.  9.  0.  4. 12.] [[ 0.633243    1.9993987  -1.0054073  -0.8642852  -2.497775   -1.221707\n",
      "   0.6670059  -1.8788929  -1.4558889  -0.48636767 -1.663617   -2.7098835 ]]\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9230\n",
      "13\n",
      "[ 0.  7.  7.  1.  6. 12.] [[-6.877658    0.771442   -1.4314115   0.26715034 -4.8459225  -3.939033\n",
      "  -1.5784888  -0.99443233 -1.9918858  -0.18029645 -1.6040266  -5.482512  ]]\n",
      "[1. 7. 9. 0. 2. 2.] [[ 0.29982343  0.90536416 -0.8043138  -0.7347597  -3.231106   -2.0015588\n",
      "  -0.16529897 -1.4670906  -1.4606199  -1.3271981  -1.2599428  -2.2259164 ]]\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0116\n",
      "14\n",
      "[1. 7. 9. 0. 6. 9.] [[ 1.0100371   2.009337   -0.99718994 -0.86585426 -2.6568122  -1.2981218\n",
      "   0.5371746  -1.5033224  -1.1201808  -0.5917024  -1.9142087  -2.4647758 ]]\n",
      "[0. 8. 4. 0. 2. 7.] [[-2.8906279  -1.4690667   0.86609745  1.0653998  -5.259404   -2.1829138\n",
      "  -1.1468126  -0.04304681 -1.4711363   0.44220984  0.13191666 -2.9480348 ]]\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6493\n",
      "15\n",
      "[0. 9. 7. 0. 2. 5.] [[-0.9311139  -0.4814428   0.7730919   0.6880755  -3.051357   -1.3678796\n",
      "   0.27338442 -1.5113678  -1.5336484  -0.37936062  0.6509514  -2.1726499 ]]\n",
      "[0. 9. 7. 0. 4. 7.] [[-1.031343   -0.15451214  0.7404591   0.7615336  -2.7189138  -1.0354757\n",
      "   0.468139   -1.4351852  -1.3739316   0.04293282  0.5467682  -2.3000336 ]]\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7825\n",
      "16\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "Result not ready.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5925/244556568.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnCores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemoryList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'states'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mstates_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemoryList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'states_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemoryList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rewards'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ipyparallel/client/asyncresult.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;34m\"\"\"getitem returns result value(s) if keyed by int/slice, or metadata if key is str.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collect_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ipyparallel/client/asyncresult.py\u001b[0m in \u001b[0;36m_check_ready\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Result not ready.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: Result not ready."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "nCores = 8#how many parallel cores were running.\n",
    "oldWeightsCount = 1\n",
    "\n",
    "for j in range (6000):\n",
    "    print (j)\n",
    "    memoryList = rc[:].map_sync(play,range(nCores))\n",
    "\n",
    "    states = []\n",
    "    states_=[]\n",
    "    rewards=[]\n",
    "    actions=[]\n",
    "    terminals=[]\n",
    "    \n",
    "    for i in range(nCores):\n",
    "        states.append(memoryList[i]['states'])\n",
    "        states_.append(memoryList[i]['states_'])\n",
    "        rewards.append(memoryList[i]['rewards'])\n",
    "        actions.append(memoryList[i]['actions'])\n",
    "        terminals.append(memoryList[i]['terminals'])\n",
    "    \n",
    "    state_memory=np.concatenate(states,axis=0)\n",
    "    new_state_memory = np.concatenate(states_,axis=0)\n",
    "    reward_memory = np.concatenate(rewards,axis=0)\n",
    "    action_memory = np.concatenate(actions,axis=0)\n",
    "    terminal_memory = np.concatenate(terminals,axis=0)\n",
    "    \n",
    "    agentLearn.memory.state_memory = state_memory\n",
    "    agentLearn.memory.new_state_memory = new_state_memory\n",
    "    agentLearn.memory.reward_memory = reward_memory\n",
    "    agentLearn.memory.action_memory = action_memory\n",
    "    agentLearn.memory.terminal_memory = terminal_memory\n",
    "    agentLearn.memory.mem_cntr = nCores*nDec\n",
    "    \n",
    "    r1 = np.random.randint(0, nCores*nDec)\n",
    "    r2 = np.random.randint(0, nCores*nDec)\n",
    "    observation = agentLearn.memory.state_memory[r1]\n",
    "    print(observation[0:6],agentLearn.q_eval.predict(np.array([observation])))\n",
    "    observation = agentLearn.memory.state_memory[r2]\n",
    "    print(observation[0:6],agentLearn.q_eval.predict(np.array([observation])))\n",
    "\n",
    " \n",
    "    agentLearn.learnMass()   \n",
    "    agentLearn.save_model()\n",
    "    \n",
    "    gc.collect()\n",
    "    weights = agentLearn.q_eval.get_weights()\n",
    "    rc[:]['weightsHero']=weights #send current weights of heros model to the engines.\n",
    "    rc[7]['weightsVillain']=weights #one opponent always has the current weights.\n",
    "    #update villain weights. After some steps, one of the villain networks gets updated.\n",
    "    frequencyUpdateVillain = 200\n",
    "    \n",
    "    if j%frequencyUpdateVillain ==0:\n",
    "        print(\"exchanging weights of\",oldWeightsCount)\n",
    "        print (rc[oldWeightsCount]['weightsVil'][0])\n",
    "        rc[oldWeightsCount]['weightsVil']= weights\n",
    "        print (rc[oldWeightsCount]['weightsVil'][0])\n",
    "        if oldWeightsCount == 6:\n",
    "            oldWeightsCount = 0\n",
    "        else:\n",
    "            oldWeightsCount+=1\n",
    "\n",
    "#save villain weights\n",
    "    if j%500 ==0:\n",
    "        weightsVil = rc[:]['weightsVil']\n",
    "        with open(\"weightsVil10BB.txt\", \"wb\") as weightsFile:   #Pickling\n",
    "            pickle.dump(weightsVil, weightsFile)\n",
    "\n",
    "weightsVil = rc[:]['weightsVil']\n",
    "with open(\"weightsVil10BB.txt\", \"wb\") as weightsFile:   #Pickling\n",
    "    pickle.dump(weightsVil, weightsFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc30b3a-f83c-4a47-ac3b-3928066afbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save villain weights\n",
    "weightsVil = rc[:]['weightsVil']\n",
    "with open(\"weightsVil10BB.txt\", \"wb\") as weightsFile:   #Pickling\n",
    "    pickle.dump(weightsVil, weightsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9776af-5e1a-4cc8-b0af-986e3375ed7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
