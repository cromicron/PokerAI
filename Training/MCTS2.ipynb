{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 14:11:50.430318: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-25 14:11:50.430344: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from AgentSimulate import Agent\n",
    "from game.PokerSimple import PokerSimple\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "game = PokerSimple(0,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 14:11:53.243427: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-25 14:11:53.243472: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-25 14:11:53.243512: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cromi-Lenovo-V15-ADA): /proc/driver/nvidia/version does not exist\n",
      "2022-05-25 14:11:53.244735: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "agent = Agent()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import random\n",
    "class MCST:\n",
    "    def __init__(self, gamestate, agent, perspective, n_runs = 10, n_sim = 10):\n",
    "        self.policies = []\n",
    "        self.observations = []\n",
    "        self.game = copy.deepcopy(gamestate)\n",
    "        if self.game.street == 0:\n",
    "            deck = self.game.deck[1:]\n",
    "            random.shuffle(deck)\n",
    "            self.game.deck[1:]=deck\n",
    "            self.game.hole_1=self.game.deck[1]\n",
    "\n",
    "        else:\n",
    "            board = self.game.board\n",
    "            deck = []\n",
    "            deck.append(self.game.deck[1])\n",
    "            deck.extend(self.game.deck[3:])\n",
    "            random.shuffle(deck)\n",
    "            self.game.deck[1]=deck[0]\n",
    "            self.game.deck[3:]= deck[1:]\n",
    "            self.game.hole_1=self.game.deck[1]\n",
    "        self.game.run_ranges = True\n",
    "        self.agent = agent\n",
    "        self.perspective = perspective\n",
    "        self.n_runs = n_runs\n",
    "        self.n_sim = n_sim\n",
    "\n",
    "    def search(self):\n",
    "        game = self.game\n",
    "        agent = self.agent\n",
    "        actions_taken = {0:0, 1:0, 2:0} #to count number of actions taken in simulations\n",
    "        evs = {} #save evs for each action\n",
    "\n",
    "        #find legal actions in state\n",
    "        if game.stacks[0] == 4.5 or game.stacks[1]==4.5: #beginning of round\n",
    "            legal_actions = [0,1,2]\n",
    "        elif game.stacks[0] != game.stacks[1]:\n",
    "            legal_actions = [0,1]\n",
    "        else:\n",
    "            legal_actions = [1,2]\n",
    "\n",
    "        #initialize policy\n",
    "        game.create_observation(game.next_to_act[0])\n",
    "        observation = game.observations[game.next_to_act[0]][:]\n",
    "        self.observation = observation[:]\n",
    "        if observation[4] == observation[6]:\n",
    "            observation.append(1)\n",
    "        else:\n",
    "            observation.append(0)\n",
    "\n",
    "        state = tf.convert_to_tensor([observation])\n",
    "        policy = np.array(agent.actor(state))[0]\n",
    "\n",
    "        for i in range(self.n_runs):\n",
    "\n",
    "            action_probabilities = tfp.distributions.Categorical(probs=policy)\n",
    "\n",
    "            action = int(np.array(action_probabilities.sample()))\n",
    "            while action not in legal_actions:\n",
    "                action = int(np.array(action_probabilities.sample()))\n",
    "\n",
    "            actions_taken[action] += 1\n",
    "            if action not in evs.keys():\n",
    "                evs[action] = 0\n",
    "                saw_flop = agent.saw_flop[:]\n",
    "                ranges = agent.ranges_vil[:]\n",
    "                reward_sim = 0\n",
    "                for j in range(self.n_sim):\n",
    "                    game_sim = copy.deepcopy(game)\n",
    "                    #add ranges villain\n",
    "                    game_sim.ranges[1-self.perspective] = agent.ranges_vil[self.perspective]\n",
    "\n",
    "                    game_sim.implement_action(game_sim.next_to_act[0],action)\n",
    "                    if (not agent.saw_flop[1-self.perspective]) and game_sim.street ==1:\n",
    "                        hole_hero = game_sim.hole_0 if self.perspective == 0 else game_sim.hole_1\n",
    "                        agent.update_range_flop(self.perspective, hole_hero, game_sim.board)\n",
    "                        game_sim.ranges[1-self.perspective] = agent.ranges_vil[self.perspective]\n",
    "\n",
    "                    if game_sim.done:\n",
    "                        reward = game_sim.stacks[self.perspective] -4.5 if game_sim.observations[self.perspective][0] == 0 else game_sim.stacks[self.perspective] - 4\n",
    "                    else:\n",
    "                        while (not game_sim.done) and game_sim.next_to_act[0]!=self.perspective: #villain acts\n",
    "                            game_sim.create_observation(1-self.perspective)\n",
    "                            observation = game_sim.observations[1-self.perspective][:]\n",
    "                            observation[4] =0\n",
    "                            observation.append(-1)\n",
    "                            states = np.array([observation for obs in range(5)])\n",
    "                            states[:,4] = [card for card in range(1,6)]\n",
    "                            states[:,-1] = (states[:,4]==states[:,6]).astype(int)\n",
    "                            policy_villain = np.array(agent.actor(states))\n",
    "                            new_policy_vil = (np.expand_dims(agent.ranges_vil[self.perspective],axis=1)*policy_villain).sum(axis=0)\n",
    "                            action_vil = random.choices([0,1,2], weights = new_policy_vil)[0]\n",
    "                            agent.update_range_action(self.perspective, observation[:-1], action_vil)\n",
    "                            game_sim.ranges[1-self.perspective] = agent.ranges_vil[self.perspective]\n",
    "                            game_sim.implement_action(1-self.perspective,action_vil)\n",
    "                    if game_sim.done:\n",
    "                        position_hero = game_sim.position_0 if self.perspective == 0 else game_sim.position_1\n",
    "                        reward = game_sim.stacks[self.perspective] -4.5 if position_hero == 0 else game_sim.stacks[self.perspective] - 4\n",
    "                    else:\n",
    "                        new_tree = MCST(game_sim,  agent, self.perspective,n_runs = 50, n_sim = 50)\n",
    "                        evs_tree=new_tree.search()[0]\n",
    "                        reward = max(evs_tree, key=evs_tree.get)\n",
    "                    reward_sim += reward\n",
    "                #reset pre-simulation ranges\n",
    "                agent.ranges_vil=ranges\n",
    "                agent.saw_flop=saw_flop\n",
    "\n",
    "\n",
    "\n",
    "                evs[action]+=reward_sim/self.n_sim\n",
    "            for act in range(3):\n",
    "                if act not in legal_actions:\n",
    "                    if policy[act]> 0.01:\n",
    "                        policy = self.update_policy(policy, act, -5)\n",
    "\n",
    "            policy = self.update_policy(policy, action, evs[action])\n",
    "            if policy[0]>0.999 or policy[1] > 0.999 or policy[2]>0.999:\n",
    "                break\n",
    "\n",
    "        agent.store_sample(self.observation, policy)\n",
    "        return evs, policy, actions_taken\n",
    "\n",
    "    def update_policy(self, old_policy, action, reward):\n",
    "        logit_action = np.log(old_policy[action]/(1-old_policy[action]))\n",
    "        logit_action += 0.05*reward/old_policy[action]\n",
    "        prob_action_new = np.exp(logit_action)/(1+np.exp(logit_action))\n",
    "        new_policy = [element/(1-old_policy[action])*(1-prob_action_new) for element in old_policy]\n",
    "        new_policy[action] = prob_action_new\n",
    "        return np.array(new_policy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "agent_0 = Agent()\n",
    "agent_1 = Agent()\n",
    "game=PokerSimple(0,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "games = []\n",
    "observations = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(False, 1, [0, 4.5, 4, 0, 1, 1.5, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "games = []\n",
    "observations = []\n",
    "import copy\n",
    "\n",
    "\n",
    "for card in range(1,6):\n",
    "    done, player, obs = game.reset()\n",
    "    while player!= 0 or obs[4] != card:\n",
    "        done, player, obs = game.reset()\n",
    "    games.append(copy.deepcopy(game))\n",
    "    observations.append(obs)\n",
    "\n",
    "for card in range(1,6):\n",
    "    done, player, obs = game.reset()\n",
    "    while player != 0 or game.hole_0 != card:\n",
    "        done, player, obs = game.reset()\n",
    "\n",
    "    game.implement_action(0,1)\n",
    "    game.implement_action(1,2)\n",
    "    games.append(copy.deepcopy(game))\n",
    "    game.create_observation(0)\n",
    "    observations.append(game.observations[0][:])\n",
    "\n",
    "for card in range(1,6):\n",
    "    done, player, obs = game.reset()\n",
    "    while player!= 1 or game.hole_0 != card:\n",
    "        done, player, obs = game.reset()\n",
    "    game.implement_action(1,1)\n",
    "    game.create_observation(0)\n",
    "    games.append(copy.deepcopy(game))\n",
    "    observations.append(game.observations[0][:])\n",
    "\n",
    "\n",
    "for card in range(1,6):\n",
    "    done, player, obs = game.reset()\n",
    "    while player!= 1 or game.hole_0 != card:\n",
    "        done, player, obs = game.reset()\n",
    "\n",
    "    game.implement_action(1,2)\n",
    "    game.create_observation(0)\n",
    "    games.append(copy.deepcopy(game))\n",
    "    observations.append(game.observations[0][:])\n",
    "\n",
    "#postflop - sb to check\n",
    "\n",
    "for card in range(1,6):\n",
    "    for board in range(1,6):\n",
    "        done, player, obs = game.reset()\n",
    "        while game.hole_0 != card or game.deck[2]!=board or player ==1:\n",
    "            done, player, obs = game.reset()\n",
    "\n",
    "        game.implement_action(0,1)\n",
    "        game.implement_action(1,1)\n",
    "        game.implement_action(1,1)\n",
    "        games.append(copy.deepcopy(game))\n",
    "        game.create_observation(0)\n",
    "        observations.append(game.observations[0][:])\n",
    "\n",
    "#postflop sb to push\n",
    "for card in range(1,6):\n",
    "    for board in range(1,6):\n",
    "        done, player, obs = game.reset()\n",
    "        while game.hole_0 != card or game.deck[2]!=board or player ==1:\n",
    "            done, player, obs = game.reset()\n",
    "\n",
    "        game.implement_action(0,1)\n",
    "        game.implement_action(1,1)\n",
    "        game.implement_action(1,2)\n",
    "        games.append(copy.deepcopy(game))\n",
    "        game.create_observation(0)\n",
    "        observations.append(game.observations[0][:])\n",
    "\n",
    "#postflop bb first in\n",
    "for card in range(1,6):\n",
    "    for board in range(1,6):\n",
    "        done, player, obs = game.reset()\n",
    "        while game.hole_0 != card or game.deck[2]!=board or player !=1:\n",
    "            done, player, obs = game.reset()\n",
    "\n",
    "        game.implement_action(1,1)\n",
    "        game.implement_action(0,1)\n",
    "        games.append(copy.deepcopy(game))\n",
    "        game.create_observation(0)\n",
    "        observations.append(game.observations[0][:])\n",
    "\n",
    "#postflop bb to push\n",
    "for card in range(1,6):\n",
    "    for board in range(1,6):\n",
    "        done, player, obs = game.reset()\n",
    "        while game.hole_0 != card or game.deck[2]!=board or player !=1:\n",
    "            done, player, obs = game.reset()\n",
    "\n",
    "        game.implement_action(1,1)\n",
    "        game.implement_action(0,1)\n",
    "        game.implement_action(0,1)\n",
    "        game.implement_action(1,2)\n",
    "        games.append(copy.deepcopy(game))\n",
    "        game.create_observation(0)\n",
    "        observations.append(game.observations[0][:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ep in range(1,100000):\n",
    "    print(ep)\n",
    "    game.reset()\n",
    "    agent_1.actor = agent_0.actor\n",
    "    agent_0.set_range_vil(0,game.hole_0)\n",
    "    agent_1.set_range_vil(1,game.hole_1)\n",
    "    agent_0.saw_flop = [False, False]\n",
    "    agent_1.saw_flop = [False, False]\n",
    "    while not game.done:\n",
    "        if game.next_to_act[0]== 0:\n",
    "            tree = MCST(game,agent_0, 0, n_runs = 50, n_sim = 50)\n",
    "            evs, policy, _ = tree.search()\n",
    "\n",
    "            action = max(evs, key=evs.get)\n",
    "            game.create_observation(0)\n",
    "            state = game.observations[0][:]\n",
    "            agent_0.store_sample(state,policy)\n",
    "\n",
    "            obs_vil = game.observations[0][:]\n",
    "            obs_vil[4]=0\n",
    "            agent_1.update_range_action(1,obs_vil, action)\n",
    "            game.implement_action(0, action)\n",
    "            if (not agent_0.saw_flop[1]) and game.street == 1:\n",
    "                agent_0.update_range_flop(0, game.hole_0, game.board)\n",
    "\n",
    "\n",
    "        else:\n",
    "            tree = MCST(game,agent_1, 1, n_runs = 50, n_sim = 50)\n",
    "            evs, policy, _ = tree.search()\n",
    "            action = max(evs, key=evs.get)\n",
    "            game.create_observation(1)\n",
    "            state = game.observations[1][:]\n",
    "            agent_0.store_sample(state,policy)\n",
    "            obs_vil = game.observations[1][:]\n",
    "            obs_vil[4]=0\n",
    "            agent_0.update_range_action(0,obs_vil, action)\n",
    "            game.implement_action(1, action)\n",
    "            if (not agent_1.saw_flop[0]) and game.street == 1:\n",
    "                agent_1.update_range_flop(1, game.hole_1, game.board)\n",
    "\n",
    "\n",
    "        if ep%50 == 0:\n",
    "            agent_0.print_strategy()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[4.9483147e-04, 4.0511883e-04, 9.9910003e-01],\n       [9.9703640e-01, 2.9637804e-03, 3.4688523e-09],\n       [9.9703640e-01, 2.9637804e-03, 3.4688523e-09],\n       ...,\n       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]], dtype=float32)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_0.memory.policy_memory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0. ,  4.5,  4. , ..., -1. , -1. ,  0. ],\n       [ 1. ,  4. ,  0. , ..., -1. , -1. ,  0. ],\n       [ 1. ,  4. ,  0. , ..., -1. , -1. ,  0. ],\n       ...,\n       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ],\n       [ 0. ,  0. ,  0. , ...,  0. ,  0. ,  0. ]], dtype=float32)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_0.memory.state_memory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(False, 1, [0, 4.5, 4, 0, 2, 1.5, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent_1.actor = agent_0.actor\n",
    "agent_0.set_range_vil(0,game.hole_0)\n",
    "agent_1.set_range_vil(1,game.hole_1)\n",
    "agent_0.saw_flop = [False, False]\n",
    "agent_1.saw_flop = [False, False]\n",
    "game.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create new tree\n",
      "new tree policies [array([2.16961716e-07, 2.41972077e-02, 9.75802576e-01])]\n",
      "new tree obs [[0, 4, 4, 1, 4, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [2.16961716e-07 2.41972077e-02 9.75802576e-01]\n",
      "new tree obs1 [0, 4, 4, 1, 4, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.00404267, 0.9789968 , 0.0169607 ])]\n",
      "new tree obs [[0, 4, 4, 1, 1, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.00404267 0.9789968  0.0169607 ]\n",
      "new tree obs1 [0, 4, 4, 1, 1, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.92466915, 0.07168951, 0.00364133])]\n",
      "new tree obs [[0, 4, 0, 0, 2, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.92466915 0.07168951 0.00364133]\n",
      "new tree obs1 [0, 4, 0, 0, 2, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([8.23755724e-04, 9.73568265e-01, 2.56080362e-02])]\n",
      "new tree obs [[0, 4, 4, 1, 2, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [8.23755724e-04 9.73568265e-01 2.56080362e-02]\n",
      "new tree obs1 [0, 4, 4, 1, 2, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.00362323, 0.97966803, 0.01670892])]\n",
      "new tree obs [[0, 4, 4, 1, 1, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.00362323 0.97966803 0.01670892]\n",
      "new tree obs1 [0, 4, 4, 1, 1, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.60049158, 0.3966941 , 0.00281431])]\n",
      "new tree obs [[0, 4, 0, 0, 2, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.60049158 0.3966941  0.00281431]\n",
      "new tree obs1 [0, 4, 0, 0, 2, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.77709034, 0.21792806, 0.0049816 ])]\n",
      "new tree obs [[0, 4, 0, 1, 2, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.77709034 0.21792806 0.0049816 ]\n",
      "new tree obs1 [0, 4, 0, 1, 2, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([1.32195698e-07, 3.04039233e-03, 9.96959476e-01])]\n",
      "new tree obs [[0, 4, 4, 1, 4, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [1.32195698e-07 3.04039233e-03 9.96959476e-01]\n",
      "new tree obs1 [0, 4, 4, 1, 4, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([2.53550372e-03, 9.97464447e-01, 4.85458289e-08])]\n",
      "new tree obs [[0, 4, 0, 0, 4, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [2.53550372e-03 9.97464447e-01 4.85458289e-08]\n",
      "new tree obs1 [0, 4, 0, 0, 4, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([5.99047972e-07, 5.61783254e-02, 9.43821076e-01])]\n",
      "new tree obs [[0, 4, 4, 1, 4, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [5.99047972e-07 5.61783254e-02 9.43821076e-01]\n",
      "new tree obs1 [0, 4, 4, 1, 4, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.97703052, 0.01637433, 0.0065959 ])]\n",
      "new tree obs [[0, 4, 0, 0, 1, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.97703052 0.01637433 0.0065959 ]\n",
      "new tree obs1 [0, 4, 0, 0, 1, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([1.68365224e-03, 9.98314716e-01, 1.63246587e-06])]\n",
      "new tree obs [[0, 4, 0, 1, 4, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [1.68365224e-03 9.98314716e-01 1.63246587e-06]\n",
      "new tree obs1 [0, 4, 0, 1, 4, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.00513616, 0.91303952, 0.08182449])]\n",
      "new tree obs [[0, 4, 4, 1, 1, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.00513616 0.91303952 0.08182449]\n",
      "new tree obs1 [0, 4, 4, 1, 1, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.00141663, 0.94751594, 0.05106759])]\n",
      "new tree obs [[0, 4, 4, 1, 1, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.00141663 0.94751594 0.05106759]\n",
      "new tree obs1 [0, 4, 4, 1, 1, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([9.60490031e-01, 3.95099686e-02, 2.34286691e-13])]\n",
      "new tree obs [[0, 4, 0, 1, 1, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [9.60490031e-01 3.95099686e-02 2.34286691e-13]\n",
      "new tree obs1 [0, 4, 0, 1, 1, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([3.28574598e-07, 2.96035262e-02, 9.70396146e-01])]\n",
      "new tree obs [[0, 4, 4, 1, 4, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [3.28574598e-07 2.96035262e-02 9.70396146e-01]\n",
      "new tree obs1 [0, 4, 4, 1, 4, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([8.11221676e-04, 9.64936513e-01, 3.42523292e-02])]\n",
      "new tree obs [[0, 4, 4, 1, 2, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [8.11221676e-04 9.64936513e-01 3.42523292e-02]\n",
      "new tree obs1 [0, 4, 4, 1, 2, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.00387579, 0.97296233, 0.02316205])]\n",
      "new tree obs [[0, 4, 4, 1, 1, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.00387579 0.97296233 0.02316205]\n",
      "new tree obs1 [0, 4, 4, 1, 1, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([2.29892230e-06, 1.17851066e-01, 8.82146636e-01])]\n",
      "new tree obs [[0, 4, 4, 1, 3, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [2.29892230e-06 1.17851066e-01 8.82146636e-01]\n",
      "new tree obs1 [0, 4, 4, 1, 3, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([9.48246707e-01, 5.17539975e-02, 2.78776918e-13])]\n",
      "new tree obs [[0, 4, 0, 0, 1, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [9.48246707e-01 5.17539975e-02 2.78776918e-13]\n",
      "new tree obs1 [0, 4, 0, 0, 1, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([3.44161275e-04, 8.91824486e-01, 1.07831412e-01])]\n",
      "new tree obs [[0, 4, 4, 1, 2, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [3.44161275e-04 8.91824486e-01 1.07831412e-01]\n",
      "new tree obs1 [0, 4, 4, 1, 2, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.00181241, 0.98680763, 0.01138012])]\n",
      "new tree obs [[0, 4, 4, 1, 1, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.00181241 0.98680763 0.01138012]\n",
      "new tree obs1 [0, 4, 4, 1, 1, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.66567494, 0.33104906, 0.003276  ])]\n",
      "new tree obs [[0, 4, 0, 0, 2, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.66567494 0.33104906 0.003276  ]\n",
      "new tree obs1 [0, 4, 0, 0, 2, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([4.92052736e-08, 9.75432523e-04, 9.99024518e-01])]\n",
      "new tree obs [[0, 4, 4, 1, 5, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 1]]\n",
      "new tree policy1 [4.92052736e-08 9.75432523e-04 9.99024518e-01]\n",
      "new tree obs1 [0, 4, 4, 1, 5, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 1]\n",
      "create new tree\n",
      "new tree policies [array([3.72409115e-06, 2.13972963e-01, 7.86023314e-01])]\n",
      "new tree obs [[0, 4, 4, 1, 4, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [3.72409115e-06 2.13972963e-01 7.86023314e-01]\n",
      "new tree obs1 [0, 4, 4, 1, 4, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([8.57120223e-04, 9.99142879e-01, 2.94742034e-10])]\n",
      "new tree obs [[0, 4, 0, 0, 5, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [8.57120223e-04 9.99142879e-01 2.94742034e-10]\n",
      "new tree obs1 [0, 4, 0, 0, 5, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([9.66292009e-04, 9.99033698e-01, 9.81752010e-09])]\n",
      "new tree obs [[0, 4, 0, 1, 5, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 1]]\n",
      "new tree policy1 [9.66292009e-04 9.99033698e-01 9.81752010e-09]\n",
      "new tree obs1 [0, 4, 0, 1, 5, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 1]\n",
      "create new tree\n",
      "new tree policies [array([0.81206185, 0.1827652 , 0.00517295])]\n",
      "new tree obs [[0, 4, 0, 1, 2, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.81206185 0.1827652  0.00517295]\n",
      "new tree obs1 [0, 4, 0, 1, 2, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([1.46238422e-07, 9.02732713e-04, 9.99097121e-01])]\n",
      "new tree obs [[0, 4, 4, 1, 5, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 1]]\n",
      "new tree policy1 [1.46238422e-07 9.02732713e-04 9.99097121e-01]\n",
      "new tree obs1 [0, 4, 4, 1, 5, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 1]\n",
      "create new tree\n",
      "new tree policies [array([2.58730200e-03, 9.97412235e-01, 4.62508481e-07])]\n",
      "new tree obs [[0, 4, 0, 0, 4, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [2.58730200e-03 9.97412235e-01 4.62508481e-07]\n",
      "new tree obs1 [0, 4, 0, 0, 4, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([4.67429379e-04, 9.14523209e-01, 8.50094248e-02])]\n",
      "new tree obs [[0, 4, 4, 1, 2, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [4.67429379e-04 9.14523209e-01 8.50094248e-02]\n",
      "new tree obs1 [0, 4, 4, 1, 2, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([6.62809759e-07, 1.39232869e-01, 8.60766468e-01])]\n",
      "new tree obs [[0, 4, 4, 1, 3, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [6.62809759e-07 1.39232869e-01 8.60766468e-01]\n",
      "new tree obs1 [0, 4, 4, 1, 3, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([5.36317748e-07, 4.18777138e-02, 9.58121750e-01])]\n",
      "new tree obs [[0, 4, 4, 1, 4, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [5.36317748e-07 4.18777138e-02 9.58121750e-01]\n",
      "new tree obs1 [0, 4, 4, 1, 4, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.98961617, 0.00300076, 0.00738307])]\n",
      "new tree obs [[0, 4, 0, 1, 1, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.98961617 0.00300076 0.00738307]\n",
      "new tree obs1 [0, 4, 0, 1, 1, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([9.32396245e-04, 9.99067549e-01, 5.45380560e-08])]\n",
      "new tree obs [[0, 4, 0, 1, 4, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [9.32396245e-04 9.99067549e-01 5.45380560e-08]\n",
      "new tree obs1 [0, 4, 0, 1, 4, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([2.58285952e-03, 9.97416387e-01, 7.52451690e-07])]\n",
      "new tree obs [[0, 4, 0, 0, 4, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [2.58285952e-03 9.97416387e-01 7.52451690e-07]\n",
      "new tree obs1 [0, 4, 0, 0, 4, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.00343138, 0.94987955, 0.04668922])]\n",
      "new tree obs [[0, 4, 4, 1, 1, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.00343138 0.94987955 0.04668922]\n",
      "new tree obs1 [0, 4, 4, 1, 1, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.69629927, 0.30107176, 0.00262897])]\n",
      "new tree obs [[0, 4, 0, 0, 2, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.69629927 0.30107176 0.00262897]\n",
      "new tree obs1 [0, 4, 0, 0, 2, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([9.46242353e-04, 9.99053757e-01, 2.44474717e-10])]\n",
      "new tree obs [[0, 4, 0, 0, 5, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [9.46242353e-04 9.99053757e-01 2.44474717e-10]\n",
      "new tree obs1 [0, 4, 0, 0, 5, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([1.91870644e-07, 3.68564130e-02, 9.63143395e-01])]\n",
      "new tree obs [[0, 4, 4, 1, 3, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [1.91870644e-07 3.68564130e-02 9.63143395e-01]\n",
      "new tree obs1 [0, 4, 4, 1, 3, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([4.99551164e-04, 8.53184272e-01, 1.46316229e-01])]\n",
      "new tree obs [[0, 4, 4, 1, 2, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [4.99551164e-04 8.53184272e-01 1.46316229e-01]\n",
      "new tree obs1 [0, 4, 4, 1, 2, 2, 5, 0.5, 0, 0, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([1.19012607e-05, 9.99988097e-01, 8.67652294e-10])]\n",
      "new tree obs [[0, 4, 0, 1, 5, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 1]]\n",
      "new tree policy1 [1.19012607e-05 9.99988097e-01 8.67652294e-10]\n",
      "new tree obs1 [0, 4, 0, 1, 5, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 1]\n",
      "create new tree\n",
      "new tree policies [array([8.46063219e-04, 9.99153937e-01, 6.78546875e-11])]\n",
      "new tree obs [[0, 4, 0, 0, 5, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [8.46063219e-04 9.99153937e-01 6.78546875e-11]\n",
      "new tree obs1 [0, 4, 0, 0, 5, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.98473808, 0.00700618, 0.00825636])]\n",
      "new tree obs [[0, 4, 0, 0, 1, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.98473808 0.00700618 0.00825636]\n",
      "new tree obs1 [0, 4, 0, 0, 1, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.92949619, 0.06454409, 0.00595973])]\n",
      "new tree obs [[0, 4, 0, 1, 2, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.92949619 0.06454409 0.00595973]\n",
      "new tree obs1 [0, 4, 0, 1, 2, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([9.33880219e-04, 9.99057108e-01, 9.01303607e-06])]\n",
      "new tree obs [[0, 4, 0, 1, 4, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [9.33880219e-04 9.99057108e-01 9.01303607e-06]\n",
      "new tree obs1 [0, 4, 0, 1, 4, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([0.87350084, 0.12130022, 0.00519894])]\n",
      "new tree obs [[0, 4, 0, 1, 2, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [0.87350084 0.12130022 0.00519894]\n",
      "new tree obs1 [0, 4, 0, 1, 2, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([1.19178266e-03, 9.98808171e-01, 4.64067626e-08])]\n",
      "new tree obs [[0, 4, 0, 1, 4, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [1.19178266e-03 9.98808171e-01 4.64067626e-08]\n",
      "new tree obs1 [0, 4, 0, 1, 4, 6, 5, 0.5, 0, 4, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([4.35587809e-02, 9.56368472e-01, 7.27669244e-05])]\n",
      "new tree obs [[0, 4, 0, 0, 3, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [4.35587809e-02 9.56368472e-01 7.27669244e-05]\n",
      "new tree obs1 [0, 4, 0, 0, 3, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]\n",
      "create new tree\n",
      "new tree policies [array([9.01358781e-04, 9.99098610e-01, 3.08822114e-08])]\n",
      "new tree obs [[0, 4, 0, 0, 5, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]\n",
      "new tree policy1 [9.01358781e-04 9.99098610e-01 3.08822114e-08]\n",
      "new tree obs1 [0, 4, 0, 0, 5, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]\n"
     ]
    }
   ],
   "source": [
    "tree = MCST(game,agent_1, 1, n_runs = 50, n_sim = 50)\n",
    "evs, policy, _ = tree.search()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[[0, 4, 0, 0, 4, 6, 0, 0.5, 4, -1, -1, -1, -1, -1, -1, -1, -1, 0]]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.observations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X = agent_0.memory.state_memory[:agent_0.memory.mem_cntr]\n",
    "y = agent_0.memory.policy_memory[:agent_0.memory.mem_cntr]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2187\n",
      "Epoch 2/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2187\n",
      "Epoch 3/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2187\n",
      "Epoch 4/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2187\n",
      "Epoch 5/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2187\n",
      "Epoch 6/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2187\n",
      "Epoch 7/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2186\n",
      "Epoch 8/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2186\n",
      "Epoch 9/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2185\n",
      "Epoch 10/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2185\n",
      "Epoch 11/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2187\n",
      "Epoch 12/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2186\n",
      "Epoch 13/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2186\n",
      "Epoch 14/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2186\n",
      "Epoch 15/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2186\n",
      "Epoch 16/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2186\n",
      "Epoch 17/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2185\n",
      "Epoch 18/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2186\n",
      "Epoch 19/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2185\n",
      "Epoch 20/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2185\n",
      "Epoch 21/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2185\n",
      "Epoch 22/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2185\n",
      "Epoch 23/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2185\n",
      "Epoch 24/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2184\n",
      "Epoch 25/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2185\n",
      "Epoch 26/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2185\n",
      "Epoch 27/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2185\n",
      "Epoch 28/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2184\n",
      "Epoch 29/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2185\n",
      "Epoch 30/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2185\n",
      "Epoch 31/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2185\n",
      "Epoch 32/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2185\n",
      "Epoch 33/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2183\n",
      "Epoch 34/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2184\n",
      "Epoch 35/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2184\n",
      "Epoch 36/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2184\n",
      "Epoch 37/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2184\n",
      "Epoch 38/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 39/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2184\n",
      "Epoch 40/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2185\n",
      "Epoch 41/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2183\n",
      "Epoch 42/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 43/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2184\n",
      "Epoch 44/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2184\n",
      "Epoch 45/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 46/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2184\n",
      "Epoch 47/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2184\n",
      "Epoch 48/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 49/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2184\n",
      "Epoch 50/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2184\n",
      "Epoch 51/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2184\n",
      "Epoch 52/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2184\n",
      "Epoch 53/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 54/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 55/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2183\n",
      "Epoch 56/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 57/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 58/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 59/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 60/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 61/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 62/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2183\n",
      "Epoch 63/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 64/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 65/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 66/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 67/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 68/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2183\n",
      "Epoch 69/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 70/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 71/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 72/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 73/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 74/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 75/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 76/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2183\n",
      "Epoch 77/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 78/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 79/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 80/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 81/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 82/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 83/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 84/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 85/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2182\n",
      "Epoch 86/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 87/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 88/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 89/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 90/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 91/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 92/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 93/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 94/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 95/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 96/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 97/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 98/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2182\n",
      "Epoch 99/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 100/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2181\n",
      "Epoch 101/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 102/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 103/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 104/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 105/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 106/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 107/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 108/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 109/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 110/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 111/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 112/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 113/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 114/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 115/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 116/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 117/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 118/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 119/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 120/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 121/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 122/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 123/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 124/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 125/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 126/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 127/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 128/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 129/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 130/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2181\n",
      "Epoch 131/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 132/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 133/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 134/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 135/1000\n",
      "2286/2286 [==============================] - 8s 3ms/step - loss: 0.2179\n",
      "Epoch 136/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 137/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 138/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 139/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 140/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 141/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 142/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 143/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 144/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 145/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 146/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 147/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 148/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 149/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 150/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 151/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 152/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2180\n",
      "Epoch 153/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 154/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 155/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 156/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 157/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 158/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 159/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 160/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 161/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 162/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 163/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 164/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 165/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 166/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 167/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 168/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 169/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 170/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 171/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 172/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 173/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 174/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 175/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 176/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 177/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 178/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 179/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 180/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 181/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 182/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 183/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 184/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 185/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 186/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 187/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 188/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 189/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 190/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 191/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 192/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 193/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 194/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 195/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 196/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 197/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 198/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 199/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 200/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 201/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2179\n",
      "Epoch 202/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 203/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 204/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 205/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 206/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 207/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 208/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 209/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 210/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 211/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 212/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 213/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 214/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 215/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 216/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 217/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 218/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 219/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 220/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 221/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 222/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 223/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 224/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 225/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 226/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 227/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 228/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 229/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 230/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 231/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 232/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 233/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 234/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 235/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 236/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 237/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 238/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2178\n",
      "Epoch 239/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 240/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 241/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 242/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 243/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 244/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 245/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 246/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 247/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 248/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 249/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 250/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 251/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 252/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 253/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 254/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 255/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 256/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 257/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 258/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 259/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 260/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 261/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 262/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 263/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 264/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 265/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 266/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 267/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 268/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 269/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 270/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 271/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 272/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 273/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 274/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 275/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 276/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 277/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 278/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 279/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 280/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 281/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 282/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 283/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 284/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 285/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 286/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 287/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 288/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 289/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 290/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 291/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 292/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 293/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 294/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 295/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 296/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 297/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 298/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 299/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 300/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2177\n",
      "Epoch 301/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 302/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 303/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 304/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 305/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 306/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 307/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 308/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 309/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 310/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 311/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 312/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 313/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 314/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 315/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 316/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 317/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 318/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 319/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 320/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 321/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 322/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 323/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 324/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 325/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 326/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 327/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 328/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 329/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 330/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 331/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 332/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 333/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 334/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 335/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 336/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 337/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 338/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 339/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 340/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 341/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 342/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 343/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 344/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 345/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 346/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 347/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 348/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 349/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 350/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 351/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 352/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 353/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 354/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 355/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 356/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 357/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 358/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 359/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 360/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 361/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 362/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 363/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 364/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 365/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 366/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 367/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 368/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 369/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 370/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 371/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 372/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 373/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 374/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 375/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 376/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 377/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 378/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 379/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 380/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 381/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 382/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 383/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 384/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 385/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 386/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 387/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 388/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 389/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 390/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 391/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 392/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 393/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 394/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 395/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2176\n",
      "Epoch 396/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 397/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 398/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 399/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 400/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 401/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 402/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 403/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 404/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 405/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 406/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 407/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 408/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 409/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 410/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 411/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 412/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 413/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 414/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 415/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 416/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 417/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 418/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 419/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 420/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 421/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 422/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 423/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 424/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 425/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 426/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 427/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 428/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 429/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 430/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 431/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 432/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 433/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 434/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 435/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 436/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 437/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 438/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 439/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 440/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 441/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 442/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 443/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 444/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 445/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 446/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 447/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 448/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 449/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 450/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 451/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 452/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 453/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 454/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 455/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 456/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 457/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 458/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 459/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 460/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 461/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 462/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 463/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 464/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 465/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 466/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 467/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 468/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 469/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 470/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 471/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 472/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 473/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 474/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 475/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 476/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 477/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 478/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 479/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2175\n",
      "Epoch 480/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 481/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 482/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 483/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 484/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 485/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 486/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 487/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 488/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 489/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 490/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 491/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 492/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 493/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 494/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 495/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 496/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 497/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 498/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 499/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 500/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 501/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 502/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 503/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 504/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 505/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 506/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 507/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 508/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 509/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 510/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 511/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 512/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 513/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 514/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 515/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 516/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 517/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 518/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 519/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 520/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 521/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 522/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 523/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 524/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 525/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 526/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 527/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 528/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 529/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 530/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 531/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 532/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 533/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 534/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 535/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 536/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 537/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 538/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 539/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 540/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 541/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 542/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 543/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 544/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 545/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 546/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 547/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 548/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 549/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 550/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 551/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 552/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 553/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 554/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 555/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 556/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 557/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 558/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 559/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 560/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 561/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 562/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 563/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 564/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 565/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 566/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 567/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 568/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 569/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 570/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 571/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 572/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 573/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 574/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 575/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 576/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 577/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 578/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 579/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 580/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 581/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 582/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 583/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 584/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 585/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 586/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 587/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 588/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 589/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 590/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 591/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 592/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 593/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 594/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 595/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 596/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 597/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 598/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 599/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 600/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 601/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 602/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 603/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 604/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 605/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 606/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 607/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 608/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 609/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 610/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 611/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 612/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 613/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 614/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 615/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 616/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 617/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 618/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 619/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 620/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 621/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 622/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 623/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 624/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 625/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 626/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2174\n",
      "Epoch 627/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 628/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 629/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 630/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 631/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 632/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 633/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 634/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 635/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 636/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 637/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 638/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 639/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 640/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 641/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 642/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 643/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 644/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 645/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 646/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 647/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 648/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 649/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 650/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 651/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 652/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 653/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 654/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 655/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 656/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 657/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2173\n",
      "Epoch 658/1000\n",
      "2286/2286 [==============================] - 7s 3ms/step - loss: 0.2172\n",
      "Epoch 659/1000\n",
      " 102/2286 [>.............................] - ETA: 6s - loss: 0.2246"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend \u001B[38;5;28;01mas\u001B[39;00m K\n\u001B[1;32m      2\u001B[0m K\u001B[38;5;241m.\u001B[39mset_value(agent_0\u001B[38;5;241m.\u001B[39mactor\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mlearning_rate, \u001B[38;5;241m0.000001\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43magent_0\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1384\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1377\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1378\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1379\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   1380\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   1381\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1382\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1383\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1384\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1385\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1386\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2953\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m   2954\u001B[0m   (graph_function,\n\u001B[1;32m   2955\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2956\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2957\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1849\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1850\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1851\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1852\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1853\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1854\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1855\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1856\u001B[0m     args,\n\u001B[1;32m   1857\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1858\u001B[0m     executing_eagerly)\n\u001B[1;32m   1859\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.set_value(agent_0.actor.optimizer.learning_rate, 0.000001)\n",
    "agent_0.actor.fit(X,y, batch_size= 4, epochs = 1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "preflop\n",
      "\n",
      "sb\n",
      " first in\n",
      "\n",
      "holecard 1 probs [0.002, 0.717, 0.281]\n",
      "holecard 2 probs [0.0, 0.677, 0.323]\n",
      "holecard 3 probs [0.0, 0.593, 0.406]\n",
      "holecard 4 probs [0.0, 0.298, 0.702]\n",
      "holecard 5 probs [0.0, 0.112, 0.888]\n",
      "preflop\n",
      "\n",
      "sb\n",
      " complete - push\n",
      "\n",
      "holecard 1 probs [0.991, 0.009, 0.0]\n",
      "holecard 2 probs [0.98, 0.02, 0.0]\n",
      "holecard 3 probs [0.302, 0.697, 0.002]\n",
      "holecard 4 probs [0.002, 0.996, 0.002]\n",
      "holecard 5 probs [0.0, 0.998, 0.002]\n",
      "\n",
      "bb\n",
      "  to complete\n",
      "\n",
      "holecard 1 probs [0.001, 0.706, 0.293]\n",
      "holecard 2 probs [0.0, 0.716, 0.284]\n",
      "holecard 3 probs [0.0, 0.579, 0.421]\n",
      "holecard 4 probs [0.0, 0.354, 0.646]\n",
      "holecard 5 probs [0.0, 0.254, 0.746]\n",
      "\n",
      "bb\n",
      "  to push\n",
      "\n",
      "holecard 1 probs [0.997, 0.003, 0.0]\n",
      "holecard 2 probs [0.993, 0.007, 0.0]\n",
      "holecard 3 probs [0.435, 0.565, 0.0]\n",
      "holecard 4 probs [0.001, 0.998, 0.0]\n",
      "holecard 5 probs [0.0, 0.999, 0.001]\n",
      "--------------------------------------\n",
      "postflop\n",
      "\n",
      "sb\n",
      "  to check\n",
      "\n",
      "board 1\n",
      "holecard 1 probs [0.0, 0.037, 0.963]\n",
      "holecard 2 probs [0.0, 0.317, 0.682]\n",
      "holecard 3 probs [0.0, 0.225, 0.775]\n",
      "holecard 4 probs [0.0, 0.177, 0.823]\n",
      "holecard 5 probs [0.0, 0.156, 0.844]\n",
      "board 2\n",
      "holecard 1 probs [0.001, 0.374, 0.624]\n",
      "holecard 2 probs [0.0, 0.034, 0.966]\n",
      "holecard 3 probs [0.0, 0.193, 0.807]\n",
      "holecard 4 probs [0.0, 0.158, 0.842]\n",
      "holecard 5 probs [0.0, 0.144, 0.856]\n",
      "board 3\n",
      "holecard 1 probs [0.001, 0.318, 0.681]\n",
      "holecard 2 probs [0.0, 0.216, 0.784]\n",
      "holecard 3 probs [0.0, 0.047, 0.953]\n",
      "holecard 4 probs [0.0, 0.146, 0.854]\n",
      "holecard 5 probs [0.0, 0.142, 0.858]\n",
      "board 4\n",
      "holecard 1 probs [0.001, 0.287, 0.712]\n",
      "holecard 2 probs [0.0, 0.216, 0.784]\n",
      "holecard 3 probs [0.0, 0.192, 0.808]\n",
      "holecard 4 probs [0.0, 0.051, 0.949]\n",
      "holecard 5 probs [0.0, 0.138, 0.862]\n",
      "board 5\n",
      "holecard 1 probs [0.001, 0.292, 0.707]\n",
      "holecard 2 probs [0.0, 0.218, 0.782]\n",
      "holecard 3 probs [0.0, 0.2, 0.8]\n",
      "holecard 4 probs [0.0, 0.14, 0.86]\n",
      "holecard 5 probs [0.0, 0.052, 0.948]\n",
      "\n",
      "  to push\n",
      "\n",
      "board 1\n",
      "holecard 1 probs [0.035, 0.961, 0.004]\n",
      "holecard 2 probs [0.931, 0.068, 0.0]\n",
      "holecard 3 probs [0.355, 0.644, 0.002]\n",
      "holecard 4 probs [0.006, 0.992, 0.002]\n",
      "holecard 5 probs [0.0, 0.998, 0.002]\n",
      "board 2\n",
      "holecard 1 probs [0.981, 0.019, 0.0]\n",
      "holecard 2 probs [0.001, 0.995, 0.003]\n",
      "holecard 3 probs [0.229, 0.769, 0.002]\n",
      "holecard 4 probs [0.002, 0.997, 0.002]\n",
      "holecard 5 probs [0.0, 0.998, 0.002]\n",
      "board 3\n",
      "holecard 1 probs [0.986, 0.014, 0.0]\n",
      "holecard 2 probs [0.779, 0.221, 0.001]\n",
      "holecard 3 probs [0.0, 0.992, 0.007]\n",
      "holecard 4 probs [0.001, 0.998, 0.001]\n",
      "holecard 5 probs [0.0, 0.997, 0.002]\n",
      "board 4\n",
      "holecard 1 probs [0.991, 0.009, 0.0]\n",
      "holecard 2 probs [0.829, 0.17, 0.001]\n",
      "holecard 3 probs [0.017, 0.981, 0.002]\n",
      "holecard 4 probs [0.0, 0.986, 0.014]\n",
      "holecard 5 probs [0.0, 0.997, 0.003]\n",
      "board 5\n",
      "holecard 1 probs [0.994, 0.006, 0.0]\n",
      "holecard 2 probs [0.798, 0.201, 0.001]\n",
      "holecard 3 probs [0.008, 0.99, 0.002]\n",
      "holecard 4 probs [0.0, 0.998, 0.002]\n",
      "holecard 5 probs [0.0, 0.987, 0.013]\n",
      "--------------------------------------\n",
      "postflop\n",
      "\n",
      "bb\n",
      "  first in\n",
      "\n",
      "board 1\n",
      "holecard 1 probs [0.0, 0.04, 0.96]\n",
      "holecard 2 probs [0.0, 0.508, 0.492]\n",
      "holecard 3 probs [0.0, 0.343, 0.657]\n",
      "holecard 4 probs [0.0, 0.175, 0.825]\n",
      "holecard 5 probs [0.0, 0.146, 0.854]\n",
      "board 2\n",
      "holecard 1 probs [0.001, 0.578, 0.422]\n",
      "holecard 2 probs [0.0, 0.04, 0.96]\n",
      "holecard 3 probs [0.0, 0.302, 0.698]\n",
      "holecard 4 probs [0.0, 0.159, 0.841]\n",
      "holecard 5 probs [0.0, 0.138, 0.862]\n",
      "board 3\n",
      "holecard 1 probs [0.0, 0.498, 0.502]\n",
      "holecard 2 probs [0.0, 0.37, 0.63]\n",
      "holecard 3 probs [0.0, 0.046, 0.954]\n",
      "holecard 4 probs [0.0, 0.15, 0.85]\n",
      "holecard 5 probs [0.0, 0.133, 0.867]\n",
      "board 4\n",
      "holecard 1 probs [0.0, 0.425, 0.574]\n",
      "holecard 2 probs [0.0, 0.344, 0.656]\n",
      "holecard 3 probs [0.0, 0.238, 0.762]\n",
      "holecard 4 probs [0.0, 0.049, 0.951]\n",
      "holecard 5 probs [0.0, 0.126, 0.874]\n",
      "board 5\n",
      "holecard 1 probs [0.0, 0.375, 0.625]\n",
      "holecard 2 probs [0.0, 0.346, 0.654]\n",
      "holecard 3 probs [0.0, 0.243, 0.757]\n",
      "holecard 4 probs [0.0, 0.145, 0.855]\n",
      "holecard 5 probs [0.0, 0.049, 0.951]\n",
      "\n",
      "  to push after check\n",
      "\n",
      "board 1\n",
      "holecard 1 probs [0.717, 0.28, 0.003]\n",
      "holecard 2 probs [0.983, 0.017, 0.0]\n",
      "holecard 3 probs [0.697, 0.301, 0.001]\n",
      "holecard 4 probs [0.028, 0.968, 0.003]\n",
      "holecard 5 probs [0.001, 0.996, 0.003]\n",
      "board 2\n",
      "holecard 1 probs [0.993, 0.007, 0.0]\n",
      "holecard 2 probs [0.022, 0.971, 0.008]\n",
      "holecard 3 probs [0.448, 0.55, 0.002]\n",
      "holecard 4 probs [0.008, 0.989, 0.003]\n",
      "holecard 5 probs [0.001, 0.996, 0.004]\n",
      "board 3\n",
      "holecard 1 probs [0.993, 0.007, 0.0]\n",
      "holecard 2 probs [0.887, 0.112, 0.001]\n",
      "holecard 3 probs [0.002, 0.987, 0.011]\n",
      "holecard 4 probs [0.002, 0.995, 0.003]\n",
      "holecard 5 probs [0.001, 0.995, 0.004]\n",
      "board 4\n",
      "holecard 1 probs [0.993, 0.007, 0.0]\n",
      "holecard 2 probs [0.783, 0.216, 0.001]\n",
      "holecard 3 probs [0.035, 0.962, 0.003]\n",
      "holecard 4 probs [0.001, 0.976, 0.023]\n",
      "holecard 5 probs [0.0, 0.994, 0.005]\n",
      "board 5\n",
      "holecard 1 probs [0.992, 0.008, 0.0]\n",
      "holecard 2 probs [0.677, 0.321, 0.002]\n",
      "holecard 3 probs [0.013, 0.984, 0.003]\n",
      "holecard 4 probs [0.001, 0.996, 0.003]\n",
      "holecard 5 probs [0.0, 0.978, 0.021]\n"
     ]
    }
   ],
   "source": [
    "agent_0.print_strategy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1927022e-04 8.2748395e-01 1.7239676e-01]\n",
      "[8.7539784e-06 6.2499702e-01 3.7499428e-01]\n",
      "{2: 1.5, 1: 1.4150000000000003}\n",
      "[8.7539784e-06 6.2499702e-01 3.7499428e-01]\n",
      "{1: 1.4400000000000002, 2: 1.5}\n",
      "[8.7539784e-06 6.2499702e-01 3.7499428e-01]\n",
      "{2: 1.5, 1: 1.5}\n",
      "[8.7539784e-06 6.2499702e-01 3.7499428e-01]\n",
      "{1: 1.5, 2: 1.5}\n",
      "[2.588930e-02 9.740409e-01 6.981559e-05]\n",
      "{1: 5.375}\n",
      "[8.7539784e-06 6.2499702e-01 3.7499428e-01]\n",
      "{2: 1.9, 1: 1.49}\n",
      "[2.588930e-02 9.740409e-01 6.981559e-05]\n",
      "{1: 5.375}\n",
      "[2.588930e-02 9.740409e-01 6.981559e-05]\n",
      "{1: 5.0}\n",
      "[2.588930e-02 9.740409e-01 6.981559e-05]\n",
      "{1: 4.625}\n",
      "[8.7539784e-06 6.2499702e-01 3.7499428e-01]\n",
      "{1: 1.385, 2: 2.3}\n",
      "[8.7539784e-06 6.2499702e-01 3.7499428e-01]\n",
      "{1: 1.475, 2: 1.825}\n",
      "[8.7539784e-06 6.2499702e-01 3.7499428e-01]\n",
      "{2: 3.7, 1: 1.49}\n",
      "[8.7539784e-06 6.2499702e-01 3.7499428e-01]\n",
      "{1: 1.4949999999999999, 2: 2.7}\n",
      "[8.7539784e-06 6.2499702e-01 3.7499428e-01]\n",
      "{1: 1.5, 2: 2.7}\n",
      "[8.7539784e-06 6.2499702e-01 3.7499428e-01]\n",
      "{1: 1.4949999999999999, 2: 2.7}\n",
      "[2.588930e-02 9.740409e-01 6.981559e-05]\n",
      "{1: 5.5, 0: -0.5}\n",
      "[8.7539784e-06 6.2499702e-01 3.7499428e-01]\n",
      "{1: 1.5, 2: 2.3}\n",
      "[8.7539784e-06 6.2499702e-01 3.7499428e-01]\n",
      "{2: 3.1, 1: 1.5}\n",
      "[8.7539784e-06 6.2499702e-01 3.7499428e-01]\n",
      "{1: 1.5, 2: 3.1}\n",
      "[8.7539784e-06 6.2499702e-01 3.7499428e-01]\n",
      "{1: 1.5, 2: 3.1}\n"
     ]
    },
    {
     "data": {
      "text/plain": "({1: 1.7, 2: -2.846875},\n array([2.55957817e-05, 9.90664778e-01, 9.30962302e-03]),\n {0: 0, 1: 19, 2: 1})"
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_0.saw_flop = [False, False]\n",
    "agent_0.set_range_vil(0, 3)\n",
    "tree = MCST(game,agent_0,0, n_runs=100, n_sim=20)\n",
    "tree.search()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "game.ranges[1-tree.perspective] = agent_0.ranges_vil[tree.perspective]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: None,\n 1: [0.2222222222222222,\n  0.2222222222222222,\n  0.2222222222222222,\n  0.2222222222222222,\n  0.1111111111111111]}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.ranges"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: None, 1: None}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.ranges"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "({1: 0.8, 2: 0.9175, 0: 0.0},\n array([0.08801841, 0.31111797, 0.60086362]),\n {0: 25, 1: 28, 2: 47})"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_0.saw_flop = [False, False]\n",
    "agent_0.set_range_vil(1, 2)\n",
    "tree = MCST(game,agent_0,1, n_runs=100, n_sim=100)\n",
    "tree.search()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('q_simple', 'rb') as q_simple_file:\n",
    "    q = pickle.load(q_simple_file)\n",
    "def choose_action_q(observation):\n",
    "\n",
    "    hole = observation[4]\n",
    "    #sb:\n",
    "    if observation[0] == 0:\n",
    "        if observation[3] == 0: #preflop\n",
    "            if observation[-10] ==-1: #first in\n",
    "                action = np.argmax(q['sb'][hole]['preflop']['preflop_fi'])\n",
    "\n",
    "            else: # bb must have gone allin, if sb has another action to perform\n",
    "                action = np.argmax(q['sb'][hole]['preflop']['preflop_to_push'])\n",
    "\n",
    "\n",
    "        else: #postflop\n",
    "            board = observation[6]\n",
    "            if observation[2] != 0: #bb did not push\n",
    "                action = np.argmax(q['sb'][hole]['postflop'][board]['to_check'])\n",
    "                if action == 0:\n",
    "                    action =1\n",
    "                else:\n",
    "                    action =2\n",
    "            else:\n",
    "                action = np.argmax(q['sb'][hole]['postflop'][board]['to_push'])\n",
    "\n",
    "\n",
    "    #bb\n",
    "    else:\n",
    "        if observation[3] == 0: #preflop\n",
    "            if observation[-10] == 0.5: #sb completed\n",
    "                action = np.argmax(q['bb'][hole]['preflop']['to_call'])\n",
    "                if action == 0:\n",
    "                    action =1\n",
    "                else:\n",
    "                    action =2\n",
    "            else: #sb pushed\n",
    "                action = np.argmax(q['bb'][hole]['preflop']['to_push'])\n",
    "\n",
    "        else:\n",
    "            board = observation[6]\n",
    "            if observation[2]!= 0: #bb is first in\n",
    "                action = np.argmax(q['bb'][hole]['postflop'][board]['postflop_fi'])\n",
    "                if action == 0:\n",
    "                    action =1\n",
    "                else:\n",
    "                    action =2\n",
    "            else: #bb checked and sb pushed\n",
    "                action = np.argmax(q['bb'][hole]['postflop'][board]['postflop_to_push'])\n",
    "\n",
    "    return action"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "total 1.0 avg 100000000000.0\n",
      "1\n",
      "total -2.75 avg -2.7499999999725\n",
      "2\n",
      "total -6.5 avg -3.24999999998375\n",
      "3\n",
      "total -10.25 avg -3.416666666655278\n",
      "4\n",
      "total -9.25 avg -2.312499999994219\n",
      "5\n",
      "total -13.0 avg -2.5999999999948\n",
      "6\n",
      "total -18.0 avg -2.999999999995\n",
      "7\n",
      "total -17.0 avg -2.428571428567959\n",
      "8\n",
      "total -20.75 avg -2.593749999996758\n",
      "9\n",
      "total -25.75 avg -2.8611111111079324\n",
      "10\n",
      "total -22.0 avg -2.1999999999978\n",
      "11\n",
      "total -18.25 avg -1.659090909089401\n",
      "12\n",
      "total -18.25 avg -1.520833333332066\n",
      "13\n",
      "total -17.25 avg -1.3269230769220564\n",
      "14\n",
      "total -18.25 avg -1.3035714285704976\n",
      "15\n",
      "total -18.25 avg -1.2166666666658557\n",
      "16\n",
      "total -17.25 avg -1.078124999999326\n",
      "17\n",
      "total -16.25 avg -0.9558823529406142\n",
      "18\n",
      "total -16.25 avg -0.9027777777772762\n",
      "19\n",
      "total -15.25 avg -0.8026315789469459\n",
      "20\n",
      "total -11.5 avg -0.5749999999997125\n",
      "21\n",
      "total -10.5 avg -0.49999999999976186\n",
      "22\n",
      "total -9.5 avg -0.43181818181798554\n",
      "23\n",
      "total -8.5 avg -0.3695652173911437\n",
      "24\n",
      "total -12.25 avg -0.510416666666454\n",
      "25\n",
      "total -16.0 avg -0.639999999999744\n",
      "26\n",
      "total -19.75 avg -0.7596153846150925\n",
      "27\n",
      "total -18.75 avg -0.6944444444441872\n",
      "28\n",
      "total -22.5 avg -0.8035714285711416\n",
      "29\n",
      "total -21.5 avg -0.7413793103445719\n",
      "30\n",
      "total -20.5 avg -0.6833333333331055\n",
      "31\n",
      "total -19.5 avg -0.6290322580643132\n",
      "32\n",
      "total -18.5 avg -0.5781249999998194\n",
      "33\n",
      "total -19.5 avg -0.5909090909089119\n",
      "34\n",
      "total -18.5 avg -0.5441176470586635\n",
      "35\n",
      "total -14.75 avg -0.421428571428451\n",
      "36\n",
      "total -13.75 avg -0.3819444444443384\n",
      "37\n",
      "total -17.5 avg -0.4729729729728452\n",
      "38\n",
      "total -16.5 avg -0.43421052631567525\n",
      "39\n",
      "total -17.5 avg -0.4487179487178337\n",
      "40\n",
      "total -13.75 avg -0.34374999999991407\n",
      "41\n",
      "total -12.75 avg -0.31097560975602173\n",
      "42\n",
      "total -11.75 avg -0.27976190476183815\n",
      "43\n",
      "total -10.75 avg -0.24999999999994188\n",
      "44\n",
      "total -7.0 avg -0.15909090909087295\n",
      "45\n",
      "total -6.0 avg -0.13333333333330372\n",
      "46\n",
      "total -7.0 avg -0.15217391304344519\n",
      "47\n",
      "total -6.0 avg -0.12765957446805795\n",
      "48\n",
      "total -5.0 avg -0.10416666666664497\n",
      "49\n",
      "total -5.0 avg -0.1020408163265098\n",
      "50\n",
      "total -10.0 avg -0.19999999999996002\n",
      "51\n",
      "total -9.0 avg -0.17647058823525952\n",
      "52\n",
      "total -8.0 avg -0.15384615384612427\n",
      "53\n",
      "total -8.0 avg -0.1509433962263866\n",
      "54\n",
      "total -3.0 avg -0.05555555555554527\n",
      "55\n",
      "total -8.0 avg -0.14545454545451902\n",
      "56\n",
      "total -7.0 avg -0.12499999999997768\n",
      "57\n",
      "total -6.0 avg -0.10526315789471838\n",
      "58\n",
      "total -5.0 avg -0.08620689655170928\n",
      "59\n",
      "total -10.0 avg -0.1694915254237001\n",
      "60\n",
      "total -15.0 avg -0.24999999999995834\n",
      "61\n",
      "total -18.75 avg -0.3073770491802775\n",
      "62\n",
      "total -22.5 avg -0.3629032258063931\n",
      "63\n",
      "total -21.5 avg -0.3412698412697871\n",
      "64\n",
      "total -22.5 avg -0.35156249999994504\n",
      "65\n",
      "total -21.5 avg -0.33076923076917986\n",
      "66\n",
      "total -25.25 avg -0.38257575757569956\n",
      "67\n",
      "total -25.25 avg -0.3768656716417348\n",
      "68\n",
      "total -21.5 avg -0.31617647058818876\n",
      "69\n",
      "total -25.25 avg -0.3659420289854542\n",
      "70\n",
      "total -24.25 avg -0.3464285714285219\n",
      "71\n",
      "total -23.25 avg -0.32746478873234824\n",
      "72\n",
      "total -27.0 avg -0.3749999999999479\n",
      "73\n",
      "total -26.0 avg -0.356164383561595\n",
      "74\n",
      "total -25.0 avg -0.33783783783779214\n",
      "75\n",
      "total -26.0 avg -0.34666666666662044\n",
      "76\n",
      "total -26.0 avg -0.3421052631578497\n",
      "77\n",
      "total -26.0 avg -0.3376623376622938\n",
      "78\n",
      "total -25.0 avg -0.3205128205127794\n",
      "79\n",
      "total -24.0 avg -0.3037974683543919\n",
      "80\n",
      "total -23.0 avg -0.28749999999996406\n",
      "81\n",
      "total -26.75 avg -0.33024691358020614\n",
      "82\n",
      "total -30.5 avg -0.37195121951214977\n",
      "83\n",
      "total -29.5 avg -0.35542168674694513\n",
      "84\n",
      "total -30.5 avg -0.36309523809519484\n",
      "85\n",
      "total -26.75 avg -0.31470588235290414\n",
      "86\n",
      "total -31.75 avg -0.369186046511585\n",
      "87\n",
      "total -32.75 avg -0.3764367816091521\n",
      "88\n",
      "total -29.0 avg -0.32954545454541706\n",
      "89\n",
      "total -28.0 avg -0.31460674157299834\n",
      "90\n",
      "total -27.0 avg -0.2999999999999666\n",
      "91\n",
      "total -26.0 avg -0.2857142857142543\n",
      "92\n",
      "total -22.25 avg -0.24184782608693023\n",
      "93\n",
      "total -26.0 avg -0.2795698924730882\n",
      "94\n",
      "total -27.0 avg -0.28723404255316093\n",
      "95\n",
      "total -27.0 avg -0.28421052631575955\n",
      "96\n",
      "total -23.25 avg -0.24218749999997477\n",
      "97\n",
      "total -22.25 avg -0.22938144329894541\n",
      "98\n",
      "total -18.5 avg -0.18877551020406236\n",
      "99\n",
      "total -17.5 avg -0.1767676767676589\n",
      "100\n",
      "total -22.5 avg -0.2249999999999775\n",
      "101\n",
      "total -21.5 avg -0.21287128712869177\n",
      "102\n",
      "total -20.5 avg -0.20098039215684305\n",
      "103\n",
      "total -19.5 avg -0.1893203883494962\n",
      "104\n",
      "total -24.5 avg -0.23557692307690042\n",
      "105\n",
      "total -23.5 avg -0.22380952380950248\n",
      "106\n",
      "total -19.75 avg -0.18632075471696355\n",
      "107\n",
      "total -18.75 avg -0.1752336448597967\n",
      "108\n",
      "total -22.5 avg -0.20833333333331402\n",
      "109\n",
      "total -21.5 avg -0.19724770642200024\n",
      "110\n",
      "total -25.25 avg -0.22954545454543368\n",
      "111\n",
      "total -24.25 avg -0.21846846846844878\n",
      "112\n",
      "total -23.25 avg -0.20758928571426716\n",
      "113\n",
      "total -24.25 avg -0.2146017699114854\n",
      "114\n",
      "total -25.25 avg -0.221491228070156\n",
      "115\n",
      "total -24.25 avg -0.21086956521737296\n",
      "116\n",
      "total -29.25 avg -0.25215517241377133\n",
      "117\n",
      "total -33.0 avg -0.28205128205125796\n",
      "118\n",
      "total -32.0 avg -0.2711864406779431\n",
      "119\n",
      "total -35.75 avg -0.3004201680672016\n",
      "120\n",
      "total -34.75 avg -0.2895833333333092\n",
      "121\n",
      "total -33.75 avg -0.27892561983468767\n",
      "122\n",
      "total -38.75 avg -0.3176229508196461\n",
      "123\n",
      "total -35.0 avg -0.28455284552843213\n",
      "124\n",
      "total -34.0 avg -0.27419354838707466\n",
      "125\n",
      "total -37.75 avg -0.30199999999997584\n",
      "126\n",
      "total -41.5 avg -0.3293650793650532\n",
      "127\n",
      "total -40.5 avg -0.3188976377952505\n",
      "128\n",
      "total -39.5 avg -0.3085937499999759\n",
      "129\n",
      "total -38.5 avg -0.2984496124030776\n",
      "130\n",
      "total -34.75 avg -0.26730769230767176\n",
      "131\n",
      "total -38.5 avg -0.29389312977096993\n",
      "132\n",
      "total -37.5 avg -0.2840909090908876\n",
      "133\n",
      "total -37.5 avg -0.2819548872180239\n",
      "134\n",
      "total -36.5 avg -0.2723880597014722\n",
      "135\n",
      "total -41.5 avg -0.30740740740738465\n",
      "136\n",
      "total -40.5 avg -0.2977941176470369\n",
      "137\n",
      "total -39.5 avg -0.2883211678831906\n",
      "138\n",
      "total -35.75 avg -0.259057971014474\n",
      "139\n",
      "total -39.5 avg -0.2841726618704831\n",
      "140\n",
      "total -38.5 avg -0.27499999999998037\n",
      "141\n",
      "total -38.5 avg -0.27304964539005155\n",
      "142\n",
      "total -37.5 avg -0.2640845070422349\n",
      "143\n",
      "total -38.5 avg -0.2692307692307504\n",
      "144\n",
      "total -43.5 avg -0.30208333333331233\n",
      "145\n",
      "total -42.5 avg -0.29310344827584184\n",
      "146\n",
      "total -41.5 avg -0.2842465753424463\n",
      "147\n",
      "total -40.5 avg -0.2755102040816139\n",
      "148\n",
      "total -39.5 avg -0.26689189189187384\n",
      "149\n",
      "total -43.25 avg -0.29026845637581944\n",
      "150\n",
      "total -48.25 avg -0.32166666666664523\n",
      "151\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [34]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     26\u001B[0m     game_sim\u001B[38;5;241m.\u001B[39mhole_1\u001B[38;5;241m=\u001B[39mgame_sim\u001B[38;5;241m.\u001B[39mdeck[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     27\u001B[0m tree \u001B[38;5;241m=\u001B[39m MCST(game_sim,agent_0, \u001B[38;5;241m0\u001B[39m, n_runs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m25\u001B[39m, n_sim \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m25\u001B[39m)\n\u001B[0;32m---> 28\u001B[0m evs, policy, _ \u001B[38;5;241m=\u001B[39m \u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(evs, key\u001B[38;5;241m=\u001B[39mevs\u001B[38;5;241m.\u001B[39mget)\n\u001B[1;32m     30\u001B[0m game\u001B[38;5;241m.\u001B[39mimplement_action(\u001B[38;5;241m0\u001B[39m, action)\n",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36mMCST.search\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     83\u001B[0m     new_tree \u001B[38;5;241m=\u001B[39m MCST(game_sim,  agent, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperspective)\n\u001B[0;32m---> 84\u001B[0m     evs_tree\u001B[38;5;241m=\u001B[39m\u001B[43mnew_tree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     85\u001B[0m     reward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(evs_tree, key\u001B[38;5;241m=\u001B[39mevs_tree\u001B[38;5;241m.\u001B[39mget)\n\u001B[1;32m     86\u001B[0m reward_sim \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m reward\n",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36mMCST.search\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     83\u001B[0m     new_tree \u001B[38;5;241m=\u001B[39m MCST(game_sim,  agent, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperspective)\n\u001B[0;32m---> 84\u001B[0m     evs_tree\u001B[38;5;241m=\u001B[39m\u001B[43mnew_tree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     85\u001B[0m     reward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(evs_tree, key\u001B[38;5;241m=\u001B[39mevs_tree\u001B[38;5;241m.\u001B[39mget)\n\u001B[1;32m     86\u001B[0m reward_sim \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m reward\n",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36mMCST.search\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;66;03m#add ranges villain\u001B[39;00m\n\u001B[1;32m     54\u001B[0m game_sim\u001B[38;5;241m.\u001B[39mranges[\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperspective] \u001B[38;5;241m=\u001B[39m agent\u001B[38;5;241m.\u001B[39mranges_vil[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperspective]\n\u001B[0;32m---> 56\u001B[0m \u001B[43mgame_sim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimplement_action\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgame_sim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext_to_act\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m agent\u001B[38;5;241m.\u001B[39msaw_flop[\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperspective]) \u001B[38;5;129;01mand\u001B[39;00m game_sim\u001B[38;5;241m.\u001B[39mstreet \u001B[38;5;241m==\u001B[39m\u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     58\u001B[0m     hole_hero \u001B[38;5;241m=\u001B[39m game_sim\u001B[38;5;241m.\u001B[39mhole_0 \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperspective \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m game_sim\u001B[38;5;241m.\u001B[39mhole_1\n",
      "File \u001B[0;32m~/Documents/Code/Python/PokerAI/Training/game/PokerSimple.py:178\u001B[0m, in \u001B[0;36mPokerSimple.implement_action\u001B[0;34m(self, player, action)\u001B[0m\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;66;03m#sake. We are not using the actual hand of villain,\u001B[39;00m\n\u001B[1;32m    174\u001B[0m     \u001B[38;5;66;03m#because it is unknown.\u001B[39;00m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    176\u001B[0m     hand_villain \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhole_1\n\u001B[0;32m--> 178\u001B[0m game \u001B[38;5;241m=\u001B[39m \u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;66;03m#draw new hand_villain from range\u001B[39;00m\n\u001B[1;32m    181\u001B[0m new_hand_vil \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39mchoices([\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m4\u001B[39m,\u001B[38;5;241m5\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mranges[player])[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m/usr/lib/python3.8/copy.py:172\u001B[0m, in \u001B[0;36mdeepcopy\u001B[0;34m(x, memo, _nil)\u001B[0m\n\u001B[1;32m    170\u001B[0m                 y \u001B[38;5;241m=\u001B[39m x\n\u001B[1;32m    171\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 172\u001B[0m                 y \u001B[38;5;241m=\u001B[39m \u001B[43m_reconstruct\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;66;03m# If is its own copy, don't memoize.\u001B[39;00m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m x:\n",
      "File \u001B[0;32m/usr/lib/python3.8/copy.py:270\u001B[0m, in \u001B[0;36m_reconstruct\u001B[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001B[0m\n\u001B[1;32m    268\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m state \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    269\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m deep:\n\u001B[0;32m--> 270\u001B[0m         state \u001B[38;5;241m=\u001B[39m \u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(y, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__setstate__\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    272\u001B[0m         y\u001B[38;5;241m.\u001B[39m__setstate__(state)\n",
      "File \u001B[0;32m/usr/lib/python3.8/copy.py:146\u001B[0m, in \u001B[0;36mdeepcopy\u001B[0;34m(x, memo, _nil)\u001B[0m\n\u001B[1;32m    144\u001B[0m copier \u001B[38;5;241m=\u001B[39m _deepcopy_dispatch\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 146\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[0;32m/usr/lib/python3.8/copy.py:230\u001B[0m, in \u001B[0;36m_deepcopy_dict\u001B[0;34m(x, memo, deepcopy)\u001B[0m\n\u001B[1;32m    228\u001B[0m memo[\u001B[38;5;28mid\u001B[39m(x)] \u001B[38;5;241m=\u001B[39m y\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m x\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m--> 230\u001B[0m     y[deepcopy(key, memo)] \u001B[38;5;241m=\u001B[39m \u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "File \u001B[0;32m/usr/lib/python3.8/copy.py:146\u001B[0m, in \u001B[0;36mdeepcopy\u001B[0;34m(x, memo, _nil)\u001B[0m\n\u001B[1;32m    144\u001B[0m copier \u001B[38;5;241m=\u001B[39m _deepcopy_dispatch\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 146\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[0;32m/usr/lib/python3.8/copy.py:230\u001B[0m, in \u001B[0;36m_deepcopy_dict\u001B[0;34m(x, memo, deepcopy)\u001B[0m\n\u001B[1;32m    228\u001B[0m memo[\u001B[38;5;28mid\u001B[39m(x)] \u001B[38;5;241m=\u001B[39m y\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m x\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m--> 230\u001B[0m     y[deepcopy(key, memo)] \u001B[38;5;241m=\u001B[39m \u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "File \u001B[0;32m/usr/lib/python3.8/copy.py:146\u001B[0m, in \u001B[0;36mdeepcopy\u001B[0;34m(x, memo, _nil)\u001B[0m\n\u001B[1;32m    144\u001B[0m copier \u001B[38;5;241m=\u001B[39m _deepcopy_dispatch\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 146\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[0;32m/usr/lib/python3.8/copy.py:205\u001B[0m, in \u001B[0;36m_deepcopy_list\u001B[0;34m(x, memo, deepcopy)\u001B[0m\n\u001B[1;32m    203\u001B[0m append \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mappend\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m x:\n\u001B[0;32m--> 205\u001B[0m     append(\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "n_games = 1000\n",
    "total_chips = 0\n",
    "for ep in range(n_games):\n",
    "    print(ep)\n",
    "    game.reset()\n",
    "    agent_0.set_range_vil(0,game.hole_0)\n",
    "    agent_0.saw_flop = [False, False]\n",
    "\n",
    "    while not game.done:\n",
    "        if game.next_to_act[0]== 0:\n",
    "            game_sim = copy.deepcopy(game)\n",
    "            if game_sim.street == 0:\n",
    "                deck = game_sim.deck[1:]\n",
    "                random.shuffle(deck)\n",
    "                game_sim.deck[1:]=deck\n",
    "                game_sim.hole_1=game_sim.deck[1]\n",
    "\n",
    "            else:\n",
    "                board = game_sim.board\n",
    "                deck = []\n",
    "                deck.append(game_sim.deck[1])\n",
    "                deck.extend(game_sim.deck[3:])\n",
    "                random.shuffle(deck)\n",
    "                game_sim.deck[1]=deck[0]\n",
    "                game_sim.deck[3:]= deck[1:]\n",
    "                game_sim.hole_1=game_sim.deck[1]\n",
    "            tree = MCST(game_sim,agent_0, 0, n_runs = 25, n_sim = 25)\n",
    "            evs, policy, _ = tree.search()\n",
    "            action = max(evs, key=evs.get)\n",
    "            game.implement_action(0, action)\n",
    "            if (not agent_0.saw_flop[1]) and game.street == 1:\n",
    "                agent_0.update_range_flop(0, game.hole_0, game.board)\n",
    "\n",
    "\n",
    "        else:\n",
    "            game.create_observation(1)\n",
    "            action = choose_action_q(game.observations[1])\n",
    "            obs_vil = game.observations[1][:]\n",
    "            obs_vil[4] = 0\n",
    "            agent_0.update_range_action(0,obs_vil,action)\n",
    "            if (not agent_0.saw_flop[1]) and game.street == 1:\n",
    "                agent_0.update_range_flop(0, game.hole_0, game.board)\n",
    "            game.implement_action(1, action)\n",
    "\n",
    "    result = game.stacks[0] - 5\n",
    "    total_chips += result\n",
    "    avg_chips = total_chips/(ep+0.00000000001)\n",
    "    print(\"total\", total_chips, \"avg\", avg_chips)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "total 1.0 avg 100000000000.0\n",
      "1\n",
      "total 2.0 avg 1.99999999998\n",
      "2\n",
      "total 3.0 avg 1.4999999999925\n",
      "3\n",
      "total 2.0 avg 0.6666666666644444\n",
      "4\n",
      "total 1.0 avg 0.249999999999375\n",
      "5\n",
      "total 2.0 avg 0.3999999999992\n",
      "6\n",
      "total 5.75 avg 0.9583333333317361\n",
      "7\n",
      "total 6.75 avg 0.9642857142843367\n",
      "8\n",
      "total 7.75 avg 0.9687499999987892\n",
      "9\n",
      "total 8.75 avg 0.9722222222211421\n",
      "10\n",
      "total 9.75 avg 0.9749999999990251\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "n_games = 10000\n",
    "total_chips = 0\n",
    "for ep in range(n_games):\n",
    "    print(ep)\n",
    "    game.reset()\n",
    "    agent_0.set_range_vil(0,game.hole_0)\n",
    "    agent_0.saw_flop = [False, False]\n",
    "\n",
    "    while not game.done:\n",
    "\n",
    "        if game.next_to_act[0]== 0:\n",
    "            game_sim = copy.deepcopy(game)\n",
    "            if game_sim.street == 0:\n",
    "                deck = game_sim.deck[1:]\n",
    "                random.shuffle(deck)\n",
    "                game_sim.deck[1:]=deck\n",
    "                game_sim.hole_1=game_sim.deck[1]\n",
    "\n",
    "            else:\n",
    "                board = game_sim.board\n",
    "                deck = []\n",
    "                deck.append(game_sim.deck[1])\n",
    "                deck.extend(game_sim.deck[3:])\n",
    "                random.shuffle(deck)\n",
    "                game_sim.deck[1]=deck[0]\n",
    "                game_sim.deck[3:]= deck[1:]\n",
    "                game_sim.hole_1=game_sim.deck[1]\n",
    "\n",
    "            tree = MCST(game_sim,agent_0, 0, n_runs = 50, n_sim = 50)\n",
    "            evs, policy, _ = tree.search()\n",
    "            action = max(evs, key=evs.get)\n",
    "            game.implement_action(0, action)\n",
    "            if (not agent_0.saw_flop[1]) and game.street == 1:\n",
    "                agent_0.update_range_flop(0, game.hole_0, game.board)\n",
    "\n",
    "\n",
    "        else:\n",
    "            game.create_observation(1)\n",
    "            action = choose_action_q(game.observations[1])\n",
    "            obs_vil = game.observations[1][:]\n",
    "            obs_vil[4] = 0\n",
    "            agent_0.update_range_action(0,obs_vil,action)\n",
    "            if (not agent_0.saw_flop[1]) and game.street == 1:\n",
    "                agent_0.update_range_flop(0, game.hole_0, game.board)\n",
    "            game.implement_action(1, action)\n",
    "\n",
    "    result = game.stacks[0] - 5\n",
    "    total_chips += result\n",
    "    avg_chips = total_chips/(ep+0.00000000001)\n",
    "    print(\"total\", total_chips, \"avg\", avg_chips)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "preflop\n",
      "\n",
      "sb\n",
      " first in\n",
      "\n",
      "holecard 1 probs [0.002, 0.717, 0.281]\n",
      "holecard 2 probs [0.0, 0.677, 0.323]\n",
      "holecard 3 probs [0.0, 0.593, 0.406]\n",
      "holecard 4 probs [0.0, 0.298, 0.702]\n",
      "holecard 5 probs [0.0, 0.112, 0.888]\n",
      "preflop\n",
      "\n",
      "sb\n",
      " complete - push\n",
      "\n",
      "holecard 1 probs [0.991, 0.009, 0.0]\n",
      "holecard 2 probs [0.98, 0.02, 0.0]\n",
      "holecard 3 probs [0.302, 0.697, 0.002]\n",
      "holecard 4 probs [0.002, 0.996, 0.002]\n",
      "holecard 5 probs [0.0, 0.998, 0.002]\n",
      "\n",
      "bb\n",
      "  to complete\n",
      "\n",
      "holecard 1 probs [0.001, 0.706, 0.293]\n",
      "holecard 2 probs [0.0, 0.716, 0.284]\n",
      "holecard 3 probs [0.0, 0.579, 0.421]\n",
      "holecard 4 probs [0.0, 0.354, 0.646]\n",
      "holecard 5 probs [0.0, 0.254, 0.746]\n",
      "\n",
      "bb\n",
      "  to push\n",
      "\n",
      "holecard 1 probs [0.997, 0.003, 0.0]\n",
      "holecard 2 probs [0.993, 0.007, 0.0]\n",
      "holecard 3 probs [0.435, 0.565, 0.0]\n",
      "holecard 4 probs [0.001, 0.998, 0.0]\n",
      "holecard 5 probs [0.0, 0.999, 0.001]\n",
      "--------------------------------------\n",
      "postflop\n",
      "\n",
      "sb\n",
      "  to check\n",
      "\n",
      "board 1\n",
      "holecard 1 probs [0.0, 0.037, 0.963]\n",
      "holecard 2 probs [0.0, 0.317, 0.682]\n",
      "holecard 3 probs [0.0, 0.225, 0.775]\n",
      "holecard 4 probs [0.0, 0.177, 0.823]\n",
      "holecard 5 probs [0.0, 0.156, 0.844]\n",
      "board 2\n",
      "holecard 1 probs [0.001, 0.374, 0.624]\n",
      "holecard 2 probs [0.0, 0.034, 0.966]\n",
      "holecard 3 probs [0.0, 0.193, 0.807]\n",
      "holecard 4 probs [0.0, 0.158, 0.842]\n",
      "holecard 5 probs [0.0, 0.144, 0.856]\n",
      "board 3\n",
      "holecard 1 probs [0.001, 0.318, 0.681]\n",
      "holecard 2 probs [0.0, 0.216, 0.784]\n",
      "holecard 3 probs [0.0, 0.047, 0.953]\n",
      "holecard 4 probs [0.0, 0.146, 0.854]\n",
      "holecard 5 probs [0.0, 0.142, 0.858]\n",
      "board 4\n",
      "holecard 1 probs [0.001, 0.287, 0.712]\n",
      "holecard 2 probs [0.0, 0.216, 0.784]\n",
      "holecard 3 probs [0.0, 0.192, 0.808]\n",
      "holecard 4 probs [0.0, 0.051, 0.949]\n",
      "holecard 5 probs [0.0, 0.138, 0.862]\n",
      "board 5\n",
      "holecard 1 probs [0.001, 0.292, 0.707]\n",
      "holecard 2 probs [0.0, 0.218, 0.782]\n",
      "holecard 3 probs [0.0, 0.2, 0.8]\n",
      "holecard 4 probs [0.0, 0.14, 0.86]\n",
      "holecard 5 probs [0.0, 0.052, 0.948]\n",
      "\n",
      "  to push\n",
      "\n",
      "board 1\n",
      "holecard 1 probs [0.035, 0.961, 0.004]\n",
      "holecard 2 probs [0.931, 0.068, 0.0]\n",
      "holecard 3 probs [0.355, 0.644, 0.002]\n",
      "holecard 4 probs [0.006, 0.992, 0.002]\n",
      "holecard 5 probs [0.0, 0.998, 0.002]\n",
      "board 2\n",
      "holecard 1 probs [0.981, 0.019, 0.0]\n",
      "holecard 2 probs [0.001, 0.995, 0.003]\n",
      "holecard 3 probs [0.229, 0.769, 0.002]\n",
      "holecard 4 probs [0.002, 0.997, 0.002]\n",
      "holecard 5 probs [0.0, 0.998, 0.002]\n",
      "board 3\n",
      "holecard 1 probs [0.986, 0.014, 0.0]\n",
      "holecard 2 probs [0.779, 0.221, 0.001]\n",
      "holecard 3 probs [0.0, 0.992, 0.007]\n",
      "holecard 4 probs [0.001, 0.998, 0.001]\n",
      "holecard 5 probs [0.0, 0.997, 0.002]\n",
      "board 4\n",
      "holecard 1 probs [0.991, 0.009, 0.0]\n",
      "holecard 2 probs [0.829, 0.17, 0.001]\n",
      "holecard 3 probs [0.017, 0.981, 0.002]\n",
      "holecard 4 probs [0.0, 0.986, 0.014]\n",
      "holecard 5 probs [0.0, 0.997, 0.003]\n",
      "board 5\n",
      "holecard 1 probs [0.994, 0.006, 0.0]\n",
      "holecard 2 probs [0.798, 0.201, 0.001]\n",
      "holecard 3 probs [0.008, 0.99, 0.002]\n",
      "holecard 4 probs [0.0, 0.998, 0.002]\n",
      "holecard 5 probs [0.0, 0.987, 0.013]\n",
      "--------------------------------------\n",
      "postflop\n",
      "\n",
      "bb\n",
      "  first in\n",
      "\n",
      "board 1\n",
      "holecard 1 probs [0.0, 0.04, 0.96]\n",
      "holecard 2 probs [0.0, 0.508, 0.492]\n",
      "holecard 3 probs [0.0, 0.343, 0.657]\n",
      "holecard 4 probs [0.0, 0.175, 0.825]\n",
      "holecard 5 probs [0.0, 0.146, 0.854]\n",
      "board 2\n",
      "holecard 1 probs [0.001, 0.578, 0.422]\n",
      "holecard 2 probs [0.0, 0.04, 0.96]\n",
      "holecard 3 probs [0.0, 0.302, 0.698]\n",
      "holecard 4 probs [0.0, 0.159, 0.841]\n",
      "holecard 5 probs [0.0, 0.138, 0.862]\n",
      "board 3\n",
      "holecard 1 probs [0.0, 0.498, 0.502]\n",
      "holecard 2 probs [0.0, 0.37, 0.63]\n",
      "holecard 3 probs [0.0, 0.046, 0.954]\n",
      "holecard 4 probs [0.0, 0.15, 0.85]\n",
      "holecard 5 probs [0.0, 0.133, 0.867]\n",
      "board 4\n",
      "holecard 1 probs [0.0, 0.425, 0.574]\n",
      "holecard 2 probs [0.0, 0.344, 0.656]\n",
      "holecard 3 probs [0.0, 0.238, 0.762]\n",
      "holecard 4 probs [0.0, 0.049, 0.951]\n",
      "holecard 5 probs [0.0, 0.126, 0.874]\n",
      "board 5\n",
      "holecard 1 probs [0.0, 0.375, 0.625]\n",
      "holecard 2 probs [0.0, 0.346, 0.654]\n",
      "holecard 3 probs [0.0, 0.243, 0.757]\n",
      "holecard 4 probs [0.0, 0.145, 0.855]\n",
      "holecard 5 probs [0.0, 0.049, 0.951]\n",
      "\n",
      "  to push after check\n",
      "\n",
      "board 1\n",
      "holecard 1 probs [0.717, 0.28, 0.003]\n",
      "holecard 2 probs [0.983, 0.017, 0.0]\n",
      "holecard 3 probs [0.697, 0.301, 0.001]\n",
      "holecard 4 probs [0.028, 0.968, 0.003]\n",
      "holecard 5 probs [0.001, 0.996, 0.003]\n",
      "board 2\n",
      "holecard 1 probs [0.993, 0.007, 0.0]\n",
      "holecard 2 probs [0.022, 0.971, 0.008]\n",
      "holecard 3 probs [0.448, 0.55, 0.002]\n",
      "holecard 4 probs [0.008, 0.989, 0.003]\n",
      "holecard 5 probs [0.001, 0.996, 0.004]\n",
      "board 3\n",
      "holecard 1 probs [0.993, 0.007, 0.0]\n",
      "holecard 2 probs [0.887, 0.112, 0.001]\n",
      "holecard 3 probs [0.002, 0.987, 0.011]\n",
      "holecard 4 probs [0.002, 0.995, 0.003]\n",
      "holecard 5 probs [0.001, 0.995, 0.004]\n",
      "board 4\n",
      "holecard 1 probs [0.993, 0.007, 0.0]\n",
      "holecard 2 probs [0.783, 0.216, 0.001]\n",
      "holecard 3 probs [0.035, 0.962, 0.003]\n",
      "holecard 4 probs [0.001, 0.976, 0.023]\n",
      "holecard 5 probs [0.0, 0.994, 0.005]\n",
      "board 5\n",
      "holecard 1 probs [0.992, 0.008, 0.0]\n",
      "holecard 2 probs [0.677, 0.321, 0.002]\n",
      "holecard 3 probs [0.013, 0.984, 0.003]\n",
      "holecard 4 probs [0.001, 0.996, 0.003]\n",
      "holecard 5 probs [0.0, 0.978, 0.021]\n"
     ]
    }
   ],
   "source": [
    "agent_0.print_strategy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "total 1 avg 100000000000.0\n",
      "1\n",
      "total -2.75 avg -2.7499999999725\n",
      "2\n",
      "total -7.75 avg -3.874999999980625\n",
      "3\n",
      "total -6.75 avg -2.2499999999925\n",
      "4\n",
      "total -5.75 avg -1.4374999999964062\n",
      "5\n",
      "total -4.75 avg -0.9499999999981\n",
      "6\n",
      "total -3.75 avg -0.6249999999989584\n",
      "7\n",
      "total -2.75 avg -0.39285714285658163\n",
      "8\n",
      "total -2.75 avg -0.34374999999957034\n",
      "9\n",
      "total -1.75 avg -0.19444444444422843\n",
      "10\n",
      "total -0.75 avg -0.074999999999925\n",
      "11\n",
      "total 0.25 avg 0.022727272727252067\n",
      "12\n",
      "total -4.75 avg -0.3958333333330035\n",
      "13\n",
      "total -3.75 avg -0.2884615384613166\n",
      "14\n",
      "total -4.75 avg -0.33928571428547194\n",
      "15\n",
      "total -4.75 avg -0.3166666666664556\n",
      "16\n",
      "total -8.5 avg -0.5312499999996679\n",
      "17\n",
      "total -7.5 avg -0.44117647058797577\n",
      "18\n",
      "total -6.5 avg -0.3611111111109105\n",
      "19\n",
      "total -11.5 avg -0.6052631578944182\n",
      "20\n",
      "total -10.5 avg -0.5249999999997375\n",
      "21\n",
      "total -9.5 avg -0.45238095238073694\n",
      "22\n",
      "total -13.25 avg -0.6022727272724535\n",
      "23\n",
      "total -13.25 avg -0.5760869565214887\n",
      "24\n",
      "total -12.25 avg -0.510416666666454\n",
      "25\n",
      "total -8.5 avg -0.33999999999986397\n",
      "26\n",
      "total -7.5 avg -0.2884615384614275\n",
      "27\n",
      "total -6.5 avg -0.24074074074065158\n",
      "28\n",
      "total -5.5 avg -0.19642857142850126\n",
      "29\n",
      "total -9.25 avg -0.3189655172412693\n",
      "30\n",
      "total -10.25 avg -0.34166666666655277\n",
      "31\n",
      "total -9.25 avg -0.2983870967740973\n",
      "32\n",
      "total -8.25 avg -0.25781249999991945\n",
      "33\n",
      "total -7.25 avg -0.21969696969690314\n",
      "34\n",
      "total -8.25 avg -0.24264705882345805\n",
      "35\n",
      "total -7.25 avg -0.20714285714279798\n",
      "36\n",
      "total -6.25 avg -0.1736111111110629\n",
      "37\n",
      "total -11.25 avg -0.3040540540539719\n",
      "38\n",
      "total -10.25 avg -0.2697368421051922\n",
      "39\n",
      "total -9.25 avg -0.23717948717942638\n",
      "40\n",
      "total -8.25 avg -0.20624999999994845\n",
      "41\n",
      "total -7.25 avg -0.1768292682926398\n",
      "42\n",
      "total -11.0 avg -0.2619047619046996\n",
      "43\n",
      "total -14.75 avg -0.3430232558138737\n",
      "44\n",
      "total -14.75 avg -0.33522727272719655\n",
      "45\n",
      "total -18.5 avg -0.4111111111110198\n",
      "46\n",
      "total -22.25 avg -0.48369565217380794\n",
      "47\n",
      "total -21.25 avg -0.4521276595743719\n",
      "48\n",
      "total -21.25 avg -0.4427083333332411\n",
      "49\n",
      "total -22.25 avg -0.4540816326529686\n",
      "50\n",
      "total -26.0 avg -0.519999999999896\n",
      "51\n",
      "total -29.75 avg -0.583333333333219\n",
      "52\n",
      "total -28.75 avg -0.5528846153845091\n",
      "53\n",
      "total -27.75 avg -0.5235849056602786\n",
      "54\n",
      "total -28.75 avg -0.5324074074073089\n",
      "55\n",
      "total -32.5 avg -0.5909090909089835\n",
      "56\n",
      "total -31.5 avg -0.5624999999998996\n",
      "57\n",
      "total -32.5 avg -0.5701754385963912\n",
      "58\n",
      "total -31.5 avg -0.5431034482757685\n",
      "59\n",
      "total -30.5 avg -0.5169491525422852\n",
      "60\n",
      "total -29.5 avg -0.49166666666658476\n",
      "61\n",
      "total -28.5 avg -0.4672131147540218\n",
      "62\n",
      "total -27.5 avg -0.4435483870967027\n",
      "63\n",
      "total -26.5 avg -0.42063492063485386\n",
      "64\n",
      "total -25.5 avg -0.3984374999999377\n",
      "65\n",
      "total -24.5 avg -0.3769230769230189\n",
      "66\n",
      "total -24.5 avg -0.3712121212120649\n",
      "67\n",
      "total -24.5 avg -0.36567164179099015\n",
      "68\n",
      "total -23.5 avg -0.3455882352940668\n",
      "69\n",
      "total -22.5 avg -0.32608695652169184\n",
      "70\n",
      "total -21.5 avg -0.30714285714281325\n",
      "71\n",
      "total -17.75 avg -0.24999999999996478\n",
      "72\n",
      "total -16.75 avg -0.23263888888885656\n",
      "73\n",
      "total -15.75 avg -0.2157534246575047\n",
      "74\n",
      "total -14.75 avg -0.19932432432429736\n",
      "75\n",
      "total -19.75 avg -0.2633333333332982\n",
      "76\n",
      "total -19.75 avg -0.2598684210525974\n",
      "77\n",
      "total -18.75 avg -0.24350649350646186\n",
      "78\n",
      "total -17.75 avg -0.2275641025640734\n",
      "79\n",
      "total -18.75 avg -0.2373417721518687\n",
      "80\n",
      "total -17.75 avg -0.22187499999997226\n",
      "81\n",
      "total -21.5 avg -0.2654320987653993\n",
      "82\n",
      "total -20.5 avg -0.2499999999999695\n",
      "83\n",
      "total -19.5 avg -0.23493975903611625\n",
      "84\n",
      "total -23.25 avg -0.27678571428568133\n",
      "85\n",
      "total -27.0 avg -0.31764705882349203\n",
      "86\n",
      "total -26.0 avg -0.3023255813953137\n",
      "87\n",
      "total -25.0 avg -0.2873563218390474\n",
      "88\n",
      "total -20.0 avg -0.22727272727270142\n",
      "89\n",
      "total -15.0 avg -0.1685393258426777\n",
      "90\n",
      "total -11.25 avg -0.12499999999998611\n",
      "91\n",
      "total -10.25 avg -0.11263736263735026\n",
      "92\n",
      "total -9.25 avg -0.10054347826085863\n",
      "93\n",
      "total -8.25 avg -0.0887096774193453\n",
      "94\n",
      "total -13.25 avg -0.14095744680849565\n",
      "95\n",
      "total -12.25 avg -0.12894736842103904\n",
      "96\n",
      "total -11.25 avg -0.11718749999998779\n",
      "97\n",
      "total -10.25 avg -0.10567010309277261\n",
      "98\n",
      "total -14.0 avg -0.14285714285712828\n",
      "99\n",
      "total -13.0 avg -0.13131313131311803\n",
      "100\n",
      "total -13.0 avg -0.129999999999987\n",
      "101\n",
      "total -18.0 avg -0.17821782178216056\n",
      "102\n",
      "total -14.25 avg -0.13970588235292747\n",
      "103\n",
      "total -13.25 avg -0.12864077669901663\n",
      "104\n",
      "total -12.25 avg -0.11778846153845021\n",
      "105\n",
      "total -11.25 avg -0.10714285714284694\n",
      "106\n",
      "total -10.25 avg -0.09669811320753804\n",
      "107\n",
      "total -9.25 avg -0.08644859813083304\n",
      "108\n",
      "total -5.5 avg -0.05092592592592121\n",
      "109\n",
      "total -10.5 avg -0.09633027522934896\n",
      "110\n",
      "total -14.25 avg -0.12954545454544275\n",
      "111\n",
      "total -13.25 avg -0.11936936936935862\n",
      "112\n",
      "total -12.25 avg -0.10937499999999023\n",
      "113\n",
      "total -17.25 avg -0.15265486725662367\n",
      "114\n",
      "total -16.25 avg -0.1425438596491103\n",
      "115\n",
      "total -15.25 avg -0.13260869565216238\n",
      "116\n",
      "total -14.25 avg -0.1228448275861963\n",
      "117\n",
      "total -19.25 avg -0.16452991452990046\n",
      "118\n",
      "total -24.25 avg -0.20550847457625376\n",
      "119\n",
      "total -23.25 avg -0.19537815126048777\n",
      "120\n",
      "total -27.0 avg -0.22499999999998124\n",
      "121\n",
      "total -27.0 avg -0.22314049586775014\n",
      "122\n",
      "total -32.0 avg -0.2622950819671916\n",
      "123\n",
      "total -27.0 avg -0.21951219512193337\n",
      "124\n",
      "total -26.0 avg -0.2096774193548218\n",
      "125\n",
      "total -25.0 avg -0.199999999999984\n",
      "126\n",
      "total -24.0 avg -0.19047619047617534\n",
      "127\n",
      "total -24.0 avg -0.18897637795274103\n",
      "128\n",
      "total -23.0 avg -0.17968749999998596\n",
      "129\n",
      "total -22.0 avg -0.17054263565890151\n",
      "130\n",
      "total -22.0 avg -0.1692307692307562\n",
      "131\n",
      "total -27.0 avg -0.2061068702289919\n",
      "132\n",
      "total -26.0 avg -0.19696969696968203\n",
      "133\n",
      "total -29.75 avg -0.22368421052629897\n",
      "134\n",
      "total -29.75 avg -0.22201492537311776\n",
      "135\n",
      "total -26.0 avg -0.19259259259257833\n",
      "136\n",
      "total -25.0 avg -0.18382352941175117\n",
      "137\n",
      "total -28.75 avg -0.20985401459852482\n",
      "138\n",
      "total -32.5 avg -0.23550724637679452\n",
      "139\n",
      "total -31.5 avg -0.2266187050359549\n",
      "140\n",
      "total -30.5 avg -0.2178571428571273\n",
      "141\n",
      "total -29.5 avg -0.20921985815601352\n",
      "142\n",
      "total -24.5 avg -0.17253521126759347\n",
      "143\n",
      "total -29.5 avg -0.20629370629369187\n",
      "144\n",
      "total -28.5 avg -0.19791666666665292\n",
      "145\n",
      "total -24.75 avg -0.170689655172402\n",
      "146\n",
      "total -23.75 avg -0.16267123287670118\n",
      "147\n",
      "total -22.75 avg -0.15476190476189422\n",
      "148\n",
      "total -21.75 avg -0.14695945945944952\n",
      "149\n",
      "total -25.5 avg -0.17114093959730395\n",
      "150\n",
      "total -30.5 avg -0.20333333333331977\n",
      "151\n",
      "total -29.5 avg -0.1953642384105831\n",
      "152\n",
      "total -28.5 avg -0.18749999999998765\n",
      "153\n",
      "total -27.5 avg -0.17973856209149153\n",
      "154\n",
      "total -31.25 avg -0.20292207792206474\n",
      "155\n",
      "total -36.25 avg -0.2338709677419204\n",
      "156\n",
      "total -35.25 avg -0.22596153846152398\n",
      "157\n",
      "total -40.25 avg -0.25636942675157603\n",
      "158\n",
      "total -39.25 avg -0.24841772151897162\n",
      "159\n",
      "total -44.25 avg -0.27830188679243534\n",
      "160\n",
      "total -43.25 avg -0.2703124999999831\n",
      "161\n",
      "total -42.25 avg -0.2624223602484309\n",
      "162\n",
      "total -41.25 avg -0.2546296296296139\n",
      "163\n",
      "total -41.25 avg -0.2530674846625612\n",
      "164\n",
      "total -41.25 avg -0.2515243902438871\n",
      "165\n",
      "total -41.25 avg -0.24999999999998485\n",
      "166\n",
      "total -46.25 avg -0.2786144578313085\n",
      "167\n",
      "total -45.25 avg -0.2709580838323191\n",
      "168\n",
      "total -44.25 avg -0.26339285714284144\n",
      "169\n",
      "total -48.0 avg -0.28402366863903644\n",
      "170\n",
      "total -47.0 avg -0.27647058823527787\n",
      "171\n",
      "total -50.75 avg -0.2967836257309768\n",
      "172\n",
      "total -49.75 avg -0.2892441860464948\n",
      "173\n",
      "total -48.75 avg -0.28179190751443456\n",
      "174\n",
      "total -45.0 avg -0.25862068965515755\n",
      "175\n",
      "total -44.0 avg -0.25142857142855707\n",
      "176\n",
      "total -45.0 avg -0.25568181818180363\n",
      "177\n",
      "total -50.0 avg -0.2824858757061987\n",
      "178\n",
      "total -49.0 avg -0.275280898876389\n",
      "179\n",
      "total -48.0 avg -0.2681564245809906\n",
      "180\n",
      "total -48.0 avg -0.26666666666665184\n",
      "181\n",
      "total -47.0 avg -0.25966850828727844\n",
      "182\n",
      "total -42.0 avg -0.2307692307692181\n",
      "183\n",
      "total -45.75 avg -0.24999999999998634\n",
      "184\n",
      "total -44.75 avg -0.24320652173911722\n",
      "185\n",
      "total -43.75 avg -0.2364864864864737\n",
      "186\n",
      "total -42.75 avg -0.229838709677407\n",
      "187\n",
      "total -41.75 avg -0.22326203208554957\n",
      "188\n",
      "total -45.5 avg -0.2420212765957318\n",
      "189\n",
      "total -44.5 avg -0.23544973544972297\n",
      "190\n",
      "total -49.5 avg -0.26052631578945995\n",
      "191\n",
      "total -48.5 avg -0.2539267015706673\n",
      "192\n",
      "total -53.5 avg -0.2786458333333188\n",
      "193\n",
      "total -48.5 avg -0.2512953367875517\n",
      "194\n",
      "total -49.5 avg -0.25515463917524456\n",
      "195\n",
      "total -44.5 avg -0.2282051282051165\n",
      "196\n",
      "total -43.5 avg -0.22193877551019275\n",
      "197\n",
      "total -42.5 avg -0.2157360406091261\n",
      "198\n",
      "total -41.5 avg -0.209595959595949\n",
      "199\n",
      "total -36.5 avg -0.18341708542712645\n",
      "200\n",
      "total -41.5 avg -0.2074999999999896\n",
      "201\n",
      "total -45.25 avg -0.22512437810944153\n",
      "202\n",
      "total -44.25 avg -0.2190594059405832\n",
      "203\n",
      "total -48.0 avg -0.2364532019704317\n",
      "204\n",
      "total -47.0 avg -0.2303921568627338\n",
      "205\n",
      "total -50.75 avg -0.24756097560974402\n",
      "206\n",
      "total -49.75 avg -0.2415048543689203\n",
      "207\n",
      "total -50.75 avg -0.24516908212559202\n",
      "208\n",
      "total -49.75 avg -0.2391826923076808\n",
      "209\n",
      "total -54.75 avg -0.26196172248802574\n",
      "210\n",
      "total -54.75 avg -0.2607142857142733\n",
      "211\n",
      "total -54.75 avg -0.2594786729857697\n",
      "212\n",
      "total -58.5 avg -0.27594339622640207\n",
      "213\n",
      "total -59.5 avg -0.2793427230046817\n",
      "214\n",
      "total -58.5 avg -0.27336448598129565\n",
      "215\n",
      "total -58.5 avg -0.2720930232558013\n",
      "216\n",
      "total -63.5 avg -0.29398148148146785\n",
      "217\n",
      "total -62.5 avg -0.2880184331797102\n",
      "218\n",
      "total -58.75 avg -0.26949541284402434\n",
      "219\n",
      "total -57.75 avg -0.26369863013697425\n",
      "220\n",
      "total -56.75 avg -0.2579545454545337\n",
      "221\n",
      "total -60.5 avg -0.2737556561085849\n",
      "222\n",
      "total -59.5 avg -0.26801801801800595\n",
      "223\n",
      "total -63.25 avg -0.28363228699550297\n",
      "224\n",
      "total -59.5 avg -0.2656249999999881\n",
      "225\n",
      "total -60.5 avg -0.2688888888888769\n",
      "226\n",
      "total -59.5 avg -0.2632743362831742\n",
      "227\n",
      "total -59.5 avg -0.26211453744492236\n",
      "228\n",
      "total -58.5 avg -0.2565789473684098\n",
      "229\n",
      "total -57.5 avg -0.2510917030567576\n",
      "230\n",
      "total -58.5 avg -0.25434782608694545\n",
      "231\n",
      "total -57.5 avg -0.24891774891773813\n",
      "232\n",
      "total -56.5 avg -0.2435344827586102\n",
      "233\n",
      "total -55.5 avg -0.23819742489269363\n",
      "234\n",
      "total -56.5 avg -0.24145299145298113\n",
      "235\n",
      "total -55.5 avg -0.23617021276594738\n",
      "236\n",
      "total -54.5 avg -0.2309322033898207\n",
      "237\n",
      "total -53.5 avg -0.22573839662446304\n",
      "238\n",
      "total -52.5 avg -0.22058823529410837\n",
      "239\n",
      "total -51.5 avg -0.21548117154810814\n",
      "240\n",
      "total -50.5 avg -0.2104166666666579\n",
      "241\n",
      "total -49.5 avg -0.20539419087136077\n",
      "242\n",
      "total -49.5 avg -0.2045454545454461\n",
      "243\n",
      "total -48.5 avg -0.19958847736624694\n",
      "244\n",
      "total -52.25 avg -0.2141393442622863\n",
      "245\n",
      "total -53.25 avg -0.21734693877550132\n",
      "246\n",
      "total -52.25 avg -0.2123983739837312\n",
      "247\n",
      "total -51.25 avg -0.20748987854250173\n",
      "248\n",
      "total -50.25 avg -0.2026209677419273\n",
      "249\n",
      "total -49.25 avg -0.1977911646586266\n",
      "250\n",
      "total -48.25 avg -0.1929999999999923\n",
      "251\n",
      "total -47.25 avg -0.18824701195218374\n",
      "252\n",
      "total -51.0 avg -0.20238095238094433\n",
      "253\n",
      "total -47.25 avg -0.18675889328062503\n",
      "254\n",
      "total -51.0 avg -0.20078740157479524\n",
      "255\n",
      "total -50.0 avg -0.19607843137254133\n",
      "256\n",
      "total -49.0 avg -0.19140624999999253\n",
      "257\n",
      "total -52.75 avg -0.20525291828792974\n",
      "258\n",
      "total -51.75 avg -0.20058139534882943\n",
      "259\n",
      "total -56.75 avg -0.21911196911196065\n",
      "260\n",
      "total -60.5 avg -0.23269230769229873\n",
      "261\n",
      "total -59.5 avg -0.2279693486589951\n",
      "262\n",
      "total -60.5 avg -0.23091603053434231\n",
      "263\n",
      "total -59.5 avg -0.2262357414448583\n",
      "264\n",
      "total -59.5 avg -0.22537878787877932\n",
      "265\n",
      "total -58.5 avg -0.22075471698112373\n",
      "266\n",
      "total -54.75 avg -0.2058270676691652\n",
      "267\n",
      "total -53.75 avg -0.20131086142321344\n",
      "268\n",
      "total -52.75 avg -0.19682835820894787\n",
      "269\n",
      "total -53.75 avg -0.1998141263940446\n",
      "270\n",
      "total -52.75 avg -0.19537037037036314\n",
      "271\n",
      "total -51.75 avg -0.19095940959408889\n",
      "272\n",
      "total -50.75 avg -0.18658088235293432\n",
      "273\n",
      "total -49.75 avg -0.18223443223442556\n",
      "274\n",
      "total -48.75 avg -0.17791970802919058\n",
      "275\n",
      "total -53.75 avg -0.19545454545453833\n",
      "276\n",
      "total -52.75 avg -0.19112318840579018\n",
      "277\n",
      "total -51.75 avg -0.18682310469313404\n",
      "278\n",
      "total -50.75 avg -0.1825539568345258\n",
      "279\n",
      "total -49.75 avg -0.17831541218637353\n",
      "280\n",
      "total -48.75 avg -0.17410714285713663\n",
      "281\n",
      "total -47.75 avg -0.16992882562276976\n",
      "282\n",
      "total -46.75 avg -0.16578014184396575\n",
      "283\n",
      "total -45.75 avg -0.1616607773851533\n",
      "284\n",
      "total -50.75 avg -0.17869718309858526\n",
      "285\n",
      "total -49.75 avg -0.1745614035087658\n",
      "286\n",
      "total -48.75 avg -0.1704545454545395\n",
      "287\n",
      "total -53.75 avg -0.18728222996515026\n",
      "288\n",
      "total -52.75 avg -0.18315972222221585\n",
      "289\n",
      "total -51.75 avg -0.17906574394463048\n",
      "290\n",
      "total -52.75 avg -0.18189655172413166\n",
      "291\n",
      "total -53.75 avg -0.18470790378006238\n",
      "292\n",
      "total -52.75 avg -0.18065068493150066\n",
      "293\n",
      "total -51.75 avg -0.17662116040955028\n",
      "294\n",
      "total -55.5 avg -0.1887755102040752\n",
      "295\n",
      "total -56.5 avg -0.19152542372880707\n",
      "296\n",
      "total -55.5 avg -0.18749999999999367\n",
      "297\n",
      "total -54.5 avg -0.1835016835016773\n",
      "298\n",
      "total -55.5 avg -0.18624161073824877\n",
      "299\n",
      "total -54.5 avg -0.1822742474916327\n",
      "300\n",
      "total -55.5 avg -0.18499999999999384\n",
      "301\n",
      "total -54.5 avg -0.181063122923582\n",
      "302\n",
      "total -58.25 avg -0.19288079470198036\n",
      "303\n",
      "total -57.25 avg -0.1889438943894327\n",
      "304\n",
      "total -56.25 avg -0.185032894736836\n",
      "305\n",
      "total -60.0 avg -0.1967213114754034\n",
      "306\n",
      "total -65.0 avg -0.21241830065358783\n",
      "307\n",
      "total -64.0 avg -0.20846905537458604\n",
      "308\n",
      "total -63.0 avg -0.2045454545454479\n",
      "309\n",
      "total -62.0 avg -0.20064724919093202\n",
      "310\n",
      "total -65.75 avg -0.21209677419354153\n",
      "311\n",
      "total -70.75 avg -0.22749196141478367\n",
      "312\n",
      "total -69.75 avg -0.22355769230768513\n",
      "313\n",
      "total -73.5 avg -0.23482428115015225\n",
      "314\n",
      "total -74.5 avg -0.23726114649680774\n",
      "315\n",
      "total -69.5 avg -0.22063492063491363\n",
      "316\n",
      "total -68.5 avg -0.2167721518987273\n",
      "317\n",
      "total -67.5 avg -0.21293375394321096\n",
      "318\n",
      "total -66.5 avg -0.20911949685533934\n",
      "319\n",
      "total -67.5 avg -0.21159874608149806\n",
      "320\n",
      "total -66.5 avg -0.20781249999999352\n",
      "321\n",
      "total -71.5 avg -0.2227414330217999\n",
      "322\n",
      "total -70.5 avg -0.21894409937887518\n",
      "323\n",
      "total -71.5 avg -0.22136222910216033\n",
      "324\n",
      "total -70.5 avg -0.21759259259258587\n",
      "325\n",
      "total -75.5 avg -0.23230769230768517\n",
      "326\n",
      "total -74.5 avg -0.22852760736195618\n",
      "327\n",
      "total -73.5 avg -0.224770642201828\n",
      "328\n",
      "total -77.25 avg -0.23551829268291966\n",
      "329\n",
      "total -76.25 avg -0.23176291793312365\n",
      "330\n",
      "total -81.25 avg -0.24621212121211375\n",
      "331\n",
      "total -82.25 avg -0.2484894259818656\n",
      "332\n",
      "total -81.25 avg -0.24472891566264324\n",
      "333\n",
      "total -80.25 avg -0.24099099099098376\n",
      "334\n",
      "total -80.25 avg -0.24026946107783712\n",
      "335\n",
      "total -81.25 avg -0.24253731343282858\n",
      "336\n",
      "total -82.25 avg -0.24479166666665939\n",
      "337\n",
      "total -78.5 avg -0.23293768545993374\n",
      "338\n",
      "total -77.5 avg -0.22928994082839557\n",
      "339\n",
      "total -77.5 avg -0.22861356932152718\n",
      "340\n",
      "total -82.5 avg -0.24264705882352228\n",
      "341\n",
      "total -83.5 avg -0.24486803519060865\n",
      "342\n",
      "total -83.5 avg -0.2441520467836186\n",
      "343\n",
      "total -87.25 avg -0.2543731778425582\n",
      "344\n",
      "total -91.0 avg -0.26453488372092254\n",
      "345\n",
      "total -90.0 avg -0.26086956521738375\n",
      "346\n",
      "total -89.0 avg -0.25722543352600413\n",
      "347\n",
      "total -88.0 avg -0.253602305475497\n",
      "348\n",
      "total -91.75 avg -0.26364942528734875\n",
      "349\n",
      "total -90.75 avg -0.2600286532951215\n",
      "350\n",
      "total -89.75 avg -0.2564285714285641\n",
      "351\n",
      "total -90.75 avg -0.2585470085470012\n",
      "352\n",
      "total -89.75 avg -0.25497159090908367\n",
      "353\n",
      "total -94.75 avg -0.26841359773370344\n",
      "354\n",
      "total -93.75 avg -0.2648305084745688\n",
      "355\n",
      "total -94.75 avg -0.2669014084506967\n",
      "356\n",
      "total -93.75 avg -0.26334269662920606\n",
      "357\n",
      "total -92.75 avg -0.25980392156862014\n",
      "358\n",
      "total -91.75 avg -0.25628491620111016\n",
      "359\n",
      "total -96.75 avg -0.2694986072423323\n",
      "360\n",
      "total -95.75 avg -0.26597222222221484\n",
      "361\n",
      "total -92.0 avg -0.25484764542935584\n",
      "362\n",
      "total -87.0 avg -0.24033149171270055\n",
      "363\n",
      "total -90.75 avg -0.24999999999999312\n",
      "364\n",
      "total -89.75 avg -0.24656593406592728\n",
      "365\n",
      "total -93.5 avg -0.2561643835616368\n",
      "366\n",
      "total -92.5 avg -0.25273224043715153\n",
      "367\n",
      "total -97.5 avg -0.2656675749318729\n",
      "368\n",
      "total -96.5 avg -0.2622282608695581\n",
      "369\n",
      "total -95.5 avg -0.25880758807587373\n",
      "370\n",
      "total -94.5 avg -0.2554054054053985\n",
      "371\n",
      "total -94.5 avg -0.2547169811320686\n",
      "372\n",
      "total -93.5 avg -0.2513440860214986\n",
      "373\n",
      "total -92.5 avg -0.24798927613940352\n",
      "374\n",
      "total -93.5 avg -0.2499999999999933\n",
      "375\n",
      "total -92.5 avg -0.2466666666666601\n",
      "376\n",
      "total -91.5 avg -0.24335106382978075\n",
      "377\n",
      "total -90.5 avg -0.24005305039787161\n",
      "378\n",
      "total -94.25 avg -0.24933862433861773\n",
      "379\n",
      "total -99.25 avg -0.2618733509234759\n",
      "380\n",
      "total -100.25 avg -0.2638157894736773\n",
      "381\n",
      "total -99.25 avg -0.26049868766403517\n",
      "382\n",
      "total -98.25 avg -0.2571989528795744\n",
      "383\n",
      "total -102.0 avg -0.2663185378590009\n",
      "384\n",
      "total -103.0 avg -0.2682291666666597\n",
      "385\n",
      "total -106.75 avg -0.27727272727272007\n",
      "386\n",
      "total -103.0 avg -0.26683937823833503\n",
      "387\n",
      "total -103.0 avg -0.2661498708010267\n",
      "388\n",
      "total -108.0 avg -0.2783505154639104\n",
      "389\n",
      "total -107.0 avg -0.27506426735217804\n",
      "390\n",
      "total -108.0 avg -0.27692307692306983\n",
      "391\n",
      "total -107.0 avg -0.27365728900255054\n",
      "392\n",
      "total -108.0 avg -0.27551020408162563\n",
      "393\n",
      "total -109.0 avg -0.27735368956742296\n",
      "394\n",
      "total -108.0 avg -0.2741116751268966\n",
      "395\n",
      "total -107.0 avg -0.2708860759493602\n",
      "396\n",
      "total -112.0 avg -0.28282828282827566\n",
      "397\n",
      "total -111.0 avg -0.27959697732996774\n",
      "398\n",
      "total -116.0 avg -0.29145728643215346\n",
      "399\n",
      "total -121.0 avg -0.3032581453634009\n",
      "400\n",
      "total -121.0 avg -0.30249999999999244\n",
      "401\n",
      "total -120.0 avg -0.29925187032418205\n",
      "402\n",
      "total -125.0 avg -0.31094527363183305\n",
      "403\n",
      "total -121.25 avg -0.30086848635234986\n",
      "404\n",
      "total -120.25 avg -0.29764851485147775\n",
      "405\n",
      "total -116.5 avg -0.2876543209876472\n",
      "406\n",
      "total -120.25 avg -0.29618226600984493\n",
      "407\n",
      "total -121.25 avg -0.29791154791154056\n",
      "408\n",
      "total -116.25 avg -0.2849264705882283\n",
      "409\n",
      "total -115.25 avg -0.2817848410757877\n",
      "410\n",
      "total -114.25 avg -0.27865853658535905\n",
      "411\n",
      "total -119.25 avg -0.2901459854014528\n",
      "412\n",
      "total -118.25 avg -0.28701456310678913\n",
      "413\n",
      "total -118.25 avg -0.2863196125907921\n",
      "414\n",
      "total -117.25 avg -0.2832125603864666\n",
      "415\n",
      "total -116.25 avg -0.2801204819277041\n",
      "416\n",
      "total -115.25 avg -0.27704326923076256\n",
      "417\n",
      "total -114.25 avg -0.27398081534771523\n",
      "418\n",
      "total -118.0 avg -0.2822966507176966\n",
      "419\n",
      "total -119.0 avg -0.2840095465393727\n",
      "420\n",
      "total -118.0 avg -0.28095238095237424\n",
      "421\n",
      "total -117.0 avg -0.27790973871733304\n",
      "422\n",
      "total -116.0 avg -0.2748815165876712\n",
      "423\n",
      "total -115.0 avg -0.2718676122931378\n",
      "424\n",
      "total -116.0 avg -0.2735849056603709\n",
      "425\n",
      "total -115.0 avg -0.2705882352941113\n",
      "426\n",
      "total -120.0 avg -0.28169014084506383\n",
      "427\n",
      "total -123.75 avg -0.28981264637001664\n",
      "428\n",
      "total -122.75 avg -0.28679906542055406\n",
      "429\n",
      "total -126.5 avg -0.294871794871788\n",
      "430\n",
      "total -125.5 avg -0.2918604651162723\n",
      "431\n",
      "total -120.5 avg -0.2795823665893207\n",
      "432\n",
      "total -119.5 avg -0.27662037037036397\n",
      "433\n",
      "total -115.75 avg -0.26732101616627557\n",
      "434\n",
      "total -114.75 avg -0.2644009216589801\n",
      "435\n",
      "total -115.75 avg -0.2660919540229824\n",
      "436\n",
      "total -114.75 avg -0.26318807339448935\n",
      "437\n",
      "total -119.75 avg -0.2740274599542271\n",
      "438\n",
      "total -119.75 avg -0.273401826484012\n",
      "439\n",
      "total -118.75 avg -0.2705011389521578\n",
      "440\n",
      "total -119.75 avg -0.27215909090908474\n",
      "441\n",
      "total -118.75 avg -0.26927437641722746\n",
      "442\n",
      "total -118.75 avg -0.26866515837103466\n",
      "443\n",
      "total -119.75 avg -0.27031602708803\n",
      "444\n",
      "total -118.75 avg -0.2674549549549489\n",
      "445\n",
      "total -119.75 avg -0.2691011235954996\n",
      "446\n",
      "total -118.75 avg -0.26625560538115994\n",
      "447\n",
      "total -117.75 avg -0.2634228187919404\n",
      "448\n",
      "total -114.0 avg -0.25446428571428004\n",
      "449\n",
      "total -115.0 avg -0.25612472160355776\n",
      "450\n",
      "total -114.0 avg -0.2533333333333277\n",
      "451\n",
      "total -110.25 avg -0.24445676274944025\n",
      "452\n",
      "total -115.25 avg -0.25497787610618905\n",
      "453\n",
      "total -114.25 avg -0.2522075055187582\n",
      "454\n",
      "total -113.25 avg -0.24944933920704296\n",
      "455\n",
      "total -112.25 avg -0.24670329670329127\n",
      "456\n",
      "total -108.5 avg -0.23793859649122284\n",
      "457\n",
      "total -107.5 avg -0.23522975929977602\n",
      "458\n",
      "total -106.5 avg -0.23253275109169796\n",
      "459\n",
      "total -106.5 avg -0.2320261437908446\n",
      "460\n",
      "total -105.5 avg -0.22934782608695153\n",
      "461\n",
      "total -104.5 avg -0.2266811279826415\n",
      "462\n",
      "total -109.5 avg -0.23701298701298187\n",
      "463\n",
      "total -108.5 avg -0.23434125269977896\n",
      "464\n",
      "total -107.5 avg -0.23168103448275362\n",
      "465\n",
      "total -103.75 avg -0.22311827956988767\n",
      "466\n",
      "total -104.75 avg -0.22478540772531705\n",
      "467\n",
      "total -105.75 avg -0.22644539614560544\n",
      "468\n",
      "total -104.75 avg -0.22382478632478153\n",
      "469\n",
      "total -108.5 avg -0.2313432835820846\n",
      "470\n",
      "total -113.5 avg -0.2414893617021225\n",
      "471\n",
      "total -118.5 avg -0.25159235668789276\n",
      "472\n",
      "total -123.5 avg -0.26165254237287583\n",
      "473\n",
      "total -124.5 avg -0.26321353065538555\n",
      "474\n",
      "total -125.5 avg -0.2647679324894459\n",
      "475\n",
      "total -124.5 avg -0.26210526315788923\n",
      "476\n",
      "total -124.5 avg -0.261554621848734\n",
      "477\n",
      "total -123.5 avg -0.25890985324947047\n",
      "478\n",
      "total -127.25 avg -0.26621338912133335\n",
      "479\n",
      "total -126.25 avg -0.26356993736951434\n",
      "480\n",
      "total -126.25 avg -0.2630208333333279\n",
      "481\n",
      "total -127.25 avg -0.26455301455300906\n",
      "482\n",
      "total -126.25 avg -0.26192946058090744\n",
      "483\n",
      "total -130.0 avg -0.26915113871635055\n",
      "484\n",
      "total -133.75 avg -0.27634297520660583\n",
      "485\n",
      "total -134.75 avg -0.27783505154638605\n",
      "486\n",
      "total -134.75 avg -0.277263374485591\n",
      "487\n",
      "total -133.75 avg -0.2746406570841833\n",
      "488\n",
      "total -132.75 avg -0.27202868852458456\n",
      "489\n",
      "total -131.75 avg -0.26942740286298017\n",
      "490\n",
      "total -135.5 avg -0.27653061224489234\n",
      "491\n",
      "total -140.5 avg -0.2861507128309514\n",
      "492\n",
      "total -144.25 avg -0.29319105691056313\n",
      "493\n",
      "total -143.25 avg -0.29056795131845253\n",
      "494\n",
      "total -147.0 avg -0.29757085020242313\n",
      "495\n",
      "total -152.0 avg -0.3070707070707009\n",
      "496\n",
      "total -151.0 avg -0.3044354838709616\n",
      "497\n",
      "total -150.0 avg -0.3018108651911408\n",
      "498\n",
      "total -155.0 avg -0.3112449799196725\n",
      "499\n",
      "total -154.0 avg -0.3086172344689317\n",
      "500\n",
      "total -159.0 avg -0.3179999999999936\n",
      "501\n",
      "total -162.75 avg -0.32485029940119114\n",
      "502\n",
      "total -163.75 avg -0.32619521912349947\n",
      "503\n",
      "total -162.75 avg -0.32355864811132556\n",
      "504\n",
      "total -161.75 avg -0.3209325396825333\n",
      "505\n",
      "total -165.5 avg -0.32772277227722124\n",
      "506\n",
      "total -164.5 avg -0.3250988142292426\n",
      "507\n",
      "total -163.5 avg -0.32248520710058537\n",
      "508\n",
      "total -164.5 avg -0.32381889763778887\n",
      "509\n",
      "total -163.5 avg -0.3212180746561823\n",
      "510\n",
      "total -167.25 avg -0.3279411764705818\n",
      "511\n",
      "total -168.25 avg -0.3292563600782714\n",
      "512\n",
      "total -169.25 avg -0.33056640624999356\n",
      "513\n",
      "total -174.25 avg -0.33966861598439885\n",
      "514\n",
      "total -173.25 avg -0.33706225680933194\n",
      "515\n",
      "total -172.25 avg -0.33446601941746923\n",
      "516\n",
      "total -171.25 avg -0.33187984496123385\n",
      "517\n",
      "total -175.0 avg -0.3384912959380979\n",
      "518\n",
      "total -174.0 avg -0.3359073359073294\n",
      "519\n",
      "total -173.0 avg -0.33333333333332693\n",
      "520\n",
      "total -172.0 avg -0.33076923076922443\n",
      "521\n",
      "total -168.25 avg -0.3229366602687078\n",
      "522\n",
      "total -167.25 avg -0.3204022988505686\n",
      "523\n",
      "total -166.25 avg -0.3178776290630914\n",
      "524\n",
      "total -166.25 avg -0.31727099236640616\n",
      "525\n",
      "total -171.25 avg -0.32619047619047\n",
      "526\n",
      "total -167.5 avg -0.3184410646387772\n",
      "527\n",
      "total -171.25 avg -0.32495256166982306\n",
      "528\n",
      "total -175.0 avg -0.33143939393938765\n",
      "529\n",
      "total -174.0 avg -0.32892249527409584\n",
      "530\n",
      "total -179.0 avg -0.3377358490565974\n",
      "531\n",
      "total -184.0 avg -0.34651600753295014\n",
      "532\n",
      "total -183.0 avg -0.34398496240600857\n",
      "533\n",
      "total -182.0 avg -0.34146341463413993\n",
      "534\n",
      "total -187.0 avg -0.3501872659175964\n",
      "535\n",
      "total -186.0 avg -0.34766355140186267\n",
      "536\n",
      "total -185.0 avg -0.3451492537313368\n",
      "537\n",
      "total -184.0 avg -0.3426443202979452\n",
      "538\n",
      "total -189.0 avg -0.35130111524162916\n",
      "539\n",
      "total -192.75 avg -0.35760667903524385\n",
      "540\n",
      "total -191.75 avg -0.355092592592586\n",
      "541\n",
      "total -196.75 avg -0.36367837338261805\n",
      "542\n",
      "total -201.75 avg -0.3722324723247164\n",
      "543\n",
      "total -200.75 avg -0.36970534069980904\n",
      "544\n",
      "total -197.0 avg -0.3621323529411698\n",
      "545\n",
      "total -196.0 avg -0.3596330275229292\n",
      "546\n",
      "total -192.25 avg -0.35210622710622064\n",
      "547\n",
      "total -197.25 avg -0.3606032906764102\n",
      "548\n",
      "total -201.0 avg -0.3667883211678765\n",
      "549\n",
      "total -200.0 avg -0.36429872495445603\n",
      "550\n",
      "total -201.0 avg -0.3654545454545388\n",
      "551\n",
      "total -204.75 avg -0.371597096188741\n",
      "552\n",
      "total -203.75 avg -0.369112318840573\n",
      "553\n",
      "total -204.75 avg -0.37025316455695534\n",
      "554\n",
      "total -203.75 avg -0.36777978339349515\n",
      "555\n",
      "total -203.75 avg -0.3671171171171105\n",
      "556\n",
      "total -202.75 avg -0.3646582733812884\n",
      "557\n",
      "total -201.75 avg -0.3622082585278211\n",
      "558\n",
      "total -200.75 avg -0.3597670250895993\n",
      "559\n",
      "total -204.5 avg -0.3658318425760221\n",
      "560\n",
      "total -208.25 avg -0.37187499999999335\n",
      "561\n",
      "total -207.25 avg -0.3694295900178187\n",
      "562\n",
      "total -206.25 avg -0.36699288256227103\n",
      "563\n",
      "total -205.25 avg -0.3645648312610948\n",
      "564\n",
      "total -204.25 avg -0.36214539007091556\n",
      "565\n",
      "total -200.5 avg -0.35486725663716184\n",
      "566\n",
      "total -201.5 avg -0.3560070671378029\n",
      "567\n",
      "total -200.5 avg -0.3536155202821807\n",
      "568\n",
      "total -204.25 avg -0.35959507042252886\n",
      "569\n",
      "total -208.0 avg -0.3655536028119444\n",
      "570\n",
      "total -207.0 avg -0.36315789473683574\n",
      "571\n",
      "total -207.0 avg -0.36252189141855756\n",
      "572\n",
      "total -206.0 avg -0.36013986013985383\n",
      "573\n",
      "total -205.0 avg -0.357766143106451\n",
      "574\n",
      "total -204.0 avg -0.3554006968641053\n",
      "575\n",
      "total -207.75 avg -0.3613043478260807\n",
      "576\n",
      "total -206.75 avg -0.358940972222216\n",
      "577\n",
      "total -210.5 avg -0.36481802426342524\n",
      "578\n",
      "total -209.5 avg -0.362456747404838\n",
      "579\n",
      "total -213.25 avg -0.36830742659757565\n",
      "580\n",
      "total -212.25 avg -0.36594827586206263\n",
      "581\n",
      "total -213.25 avg -0.36703958691909866\n",
      "582\n",
      "total -212.25 avg -0.36469072164947824\n",
      "583\n",
      "total -212.25 avg -0.3640651801029097\n",
      "584\n",
      "total -217.25 avg -0.3720034246575279\n",
      "585\n",
      "total -216.25 avg -0.36965811965811335\n",
      "586\n",
      "total -211.25 avg -0.36049488054606893\n",
      "587\n",
      "total -210.25 avg -0.3581771720613227\n",
      "588\n",
      "total -209.25 avg -0.3558673469387695\n",
      "589\n",
      "total -205.5 avg -0.3488964346349686\n",
      "590\n",
      "total -204.5 avg -0.34661016949151957\n",
      "591\n",
      "total -203.5 avg -0.3443316412859502\n",
      "592\n",
      "total -202.5 avg -0.342060810810805\n",
      "593\n",
      "total -198.75 avg -0.33516020236087124\n",
      "594\n",
      "total -197.75 avg -0.33291245791245233\n",
      "595\n",
      "total -194.0 avg -0.32605042016806174\n",
      "596\n",
      "total -193.0 avg -0.32382550335569926\n",
      "597\n",
      "total -192.0 avg -0.32160804020099965\n",
      "598\n",
      "total -197.0 avg -0.3294314381270848\n",
      "599\n",
      "total -196.0 avg -0.3272120200333835\n",
      "600\n",
      "total -199.75 avg -0.33291666666666114\n",
      "601\n",
      "total -203.5 avg -0.3386023294509095\n",
      "602\n",
      "total -203.5 avg -0.3380398671096289\n",
      "603\n",
      "total -208.5 avg -0.34577114427860123\n",
      "604\n",
      "total -204.75 avg -0.3389900662251599\n",
      "605\n",
      "total -208.5 avg -0.34462809917354803\n",
      "606\n",
      "total -209.5 avg -0.34570957095709\n",
      "607\n",
      "total -208.5 avg -0.3434925864909334\n",
      "608\n",
      "total -212.25 avg -0.3490953947368364\n",
      "609\n",
      "total -211.25 avg -0.34688013136288426\n",
      "610\n",
      "total -210.25 avg -0.3446721311475353\n",
      "611\n",
      "total -215.25 avg -0.35229132569557525\n",
      "612\n",
      "total -214.25 avg -0.3500816993463995\n",
      "613\n",
      "total -213.25 avg -0.3478792822185914\n",
      "614\n",
      "total -214.25 avg -0.3489413680781702\n",
      "615\n",
      "total -213.25 avg -0.3467479674796692\n",
      "616\n",
      "total -212.25 avg -0.3445616883116827\n",
      "617\n",
      "total -213.25 avg -0.3456239870340301\n",
      "618\n",
      "total -209.5 avg -0.3389967637540398\n",
      "619\n",
      "total -208.5 avg -0.33683360258480877\n",
      "620\n",
      "total -207.5 avg -0.3346774193548333\n",
      "621\n",
      "total -206.5 avg -0.33252818035426196\n",
      "622\n",
      "total -205.5 avg -0.33038585209002685\n",
      "623\n",
      "total -205.5 avg -0.329855537720701\n",
      "624\n",
      "total -204.5 avg -0.3277243589743537\n",
      "625\n",
      "total -209.5 avg -0.3351999999999946\n",
      "626\n",
      "total -208.5 avg -0.3330670926517519\n",
      "627\n",
      "total -209.5 avg -0.3341307814991972\n",
      "628\n",
      "total -208.5 avg -0.33200636942674633\n",
      "629\n",
      "total -212.25 avg -0.33744038155802325\n",
      "630\n",
      "total -211.25 avg -0.335317460317455\n",
      "631\n",
      "total -212.25 avg -0.3363708399366032\n",
      "632\n",
      "total -208.5 avg -0.329905063291134\n",
      "633\n",
      "total -207.5 avg -0.3278041074249553\n",
      "634\n",
      "total -211.25 avg -0.33320189274447426\n",
      "635\n",
      "total -210.25 avg -0.33110236220471917\n",
      "636\n",
      "total -215.25 avg -0.3384433962264098\n",
      "637\n",
      "total -214.25 avg -0.3363422291993668\n",
      "638\n",
      "total -218.0 avg -0.34169278996864666\n",
      "639\n",
      "total -221.75 avg -0.34702660406885216\n",
      "640\n",
      "total -222.75 avg -0.34804687499999454\n",
      "641\n",
      "total -219.0 avg -0.34165366614664056\n",
      "642\n",
      "total -218.0 avg -0.3395638629283436\n",
      "643\n",
      "total -217.0 avg -0.33748055987557796\n",
      "644\n",
      "total -216.0 avg -0.33540372670806934\n",
      "645\n",
      "total -221.0 avg -0.34263565891472336\n",
      "646\n",
      "total -220.0 avg -0.3405572755417904\n",
      "647\n",
      "total -216.25 avg -0.3342349304482174\n",
      "648\n",
      "total -221.25 avg -0.3414351851851799\n",
      "649\n",
      "total -220.25 avg -0.33936825885977906\n",
      "650\n",
      "total -219.25 avg -0.3373076923076871\n",
      "651\n",
      "total -218.25 avg -0.335253456221193\n",
      "652\n",
      "total -217.25 avg -0.3332055214723875\n",
      "653\n",
      "total -216.25 avg -0.33116385911178664\n",
      "654\n",
      "total -220.0 avg -0.33639143730886334\n",
      "655\n",
      "total -219.0 avg -0.3343511450381628\n",
      "656\n",
      "total -222.75 avg -0.3395579268292631\n",
      "657\n",
      "total -222.75 avg -0.3390410958904058\n",
      "658\n",
      "total -221.75 avg -0.3370060790273505\n",
      "659\n",
      "total -218.0 avg -0.33080424886190696\n",
      "660\n",
      "total -214.25 avg -0.3246212121212072\n",
      "661\n",
      "total -213.25 avg -0.32261724659606167\n",
      "662\n",
      "total -217.0 avg -0.3277945619335298\n",
      "663\n",
      "total -216.0 avg -0.325791855203615\n",
      "664\n",
      "total -219.75 avg -0.3309487951807179\n",
      "665\n",
      "total -220.75 avg -0.3319548872180401\n",
      "666\n",
      "total -219.75 avg -0.32995495495495\n",
      "667\n",
      "total -218.75 avg -0.32796101949024997\n",
      "668\n",
      "total -219.75 avg -0.3289670658682585\n",
      "669\n",
      "total -218.75 avg -0.32698056801195324\n",
      "670\n",
      "total -217.75 avg -0.3249999999999951\n",
      "671\n",
      "total -214.0 avg -0.31892697466467484\n",
      "672\n",
      "total -217.75 avg -0.32403273809523325\n",
      "673\n",
      "total -222.75 avg -0.3309806835066816\n",
      "674\n",
      "total -219.0 avg -0.32492581602373405\n",
      "675\n",
      "total -218.0 avg -0.3229629629629582\n",
      "676\n",
      "total -214.25 avg -0.3169378698224805\n",
      "677\n",
      "total -213.25 avg -0.3149926144756231\n",
      "678\n",
      "total -218.25 avg -0.3219026548672519\n",
      "679\n",
      "total -217.25 avg -0.3199558173784931\n",
      "680\n",
      "total -222.25 avg -0.3268382352941128\n",
      "681\n",
      "total -227.25 avg -0.33370044052862946\n",
      "682\n",
      "total -226.25 avg -0.33174486803518577\n",
      "683\n",
      "total -226.25 avg -0.331259150805266\n",
      "684\n",
      "total -226.25 avg -0.3307748538011647\n",
      "685\n",
      "total -221.25 avg -0.3229927007299223\n",
      "686\n",
      "total -226.25 avg -0.32981049562681736\n",
      "687\n",
      "total -230.0 avg -0.3347889374090199\n",
      "688\n",
      "total -233.75 avg -0.33975290697673927\n",
      "689\n",
      "total -232.75 avg -0.3378084179970923\n",
      "690\n",
      "total -231.75 avg -0.3358695652173864\n",
      "691\n",
      "total -232.75 avg -0.33683068017365647\n",
      "692\n",
      "total -231.75 avg -0.334898843930631\n",
      "693\n",
      "total -235.5 avg -0.3398268398268349\n",
      "694\n",
      "total -239.25 avg -0.3447406340057587\n",
      "695\n",
      "total -238.25 avg -0.34280575539567854\n",
      "696\n",
      "total -237.25 avg -0.3408764367816043\n",
      "697\n",
      "total -233.5 avg -0.33500717360114296\n",
      "698\n",
      "total -232.5 avg -0.33309455587392073\n",
      "699\n",
      "total -231.5 avg -0.3311874105865475\n",
      "700\n",
      "total -236.5 avg -0.337857142857138\n",
      "701\n",
      "total -241.5 avg -0.34450784593437456\n",
      "702\n",
      "total -240.5 avg -0.34259259259258773\n",
      "703\n",
      "total -244.25 avg -0.3474395448079609\n",
      "704\n",
      "total -243.25 avg -0.3455255681818133\n",
      "705\n",
      "total -242.25 avg -0.3436170212765909\n",
      "706\n",
      "total -242.25 avg -0.343130311614726\n",
      "707\n",
      "total -243.25 avg -0.3440594059405892\n",
      "708\n",
      "total -248.25 avg -0.35063559322033405\n",
      "709\n",
      "total -248.25 avg -0.35014104372354937\n",
      "710\n",
      "total -252.0 avg -0.3549295774647837\n",
      "711\n",
      "total -251.0 avg -0.35302390998593036\n",
      "712\n",
      "total -256.0 avg -0.35955056179774775\n",
      "713\n",
      "total -255.0 avg -0.35764375876577337\n",
      "714\n",
      "total -254.0 avg -0.3557422969187625\n",
      "715\n",
      "total -253.0 avg -0.35384615384614887\n",
      "716\n",
      "total -252.0 avg -0.3519553072625649\n",
      "717\n",
      "total -251.0 avg -0.35006973500696864\n",
      "718\n",
      "total -247.25 avg -0.3443593314763183\n",
      "719\n",
      "total -243.5 avg -0.3386648122392164\n",
      "720\n",
      "total -242.5 avg -0.33680555555555086\n",
      "721\n",
      "total -241.5 avg -0.33495145631067497\n",
      "722\n",
      "total -246.5 avg -0.34141274238226677\n",
      "723\n",
      "total -246.5 avg -0.3409405255878238\n",
      "724\n",
      "total -250.25 avg -0.34564917127071343\n",
      "725\n",
      "total -249.25 avg -0.34379310344827113\n",
      "726\n",
      "total -248.25 avg -0.34194214876032586\n",
      "727\n",
      "total -247.25 avg -0.34009628610728554\n",
      "728\n",
      "total -247.25 avg -0.33962912087911623\n",
      "729\n",
      "total -246.25 avg -0.33779149519889795\n",
      "730\n",
      "total -241.25 avg -0.33047945205479\n",
      "731\n",
      "total -246.25 avg -0.3368673050615549\n",
      "732\n",
      "total -245.25 avg -0.3350409836065528\n",
      "733\n",
      "total -244.25 avg -0.3332196452933106\n",
      "734\n",
      "total -248.0 avg -0.33787465940054034\n",
      "735\n",
      "total -247.0 avg -0.3360544217687029\n",
      "736\n",
      "total -246.0 avg -0.33423913043477804\n",
      "737\n",
      "total -247.0 avg -0.33514246947082316\n",
      "738\n",
      "total -246.0 avg -0.3333333333333288\n",
      "739\n",
      "total -251.0 avg -0.33964817320703194\n",
      "740\n",
      "total -254.75 avg -0.3442567567567521\n",
      "741\n",
      "total -251.0 avg -0.3387314439945973\n",
      "742\n",
      "total -250.0 avg -0.336927223719672\n",
      "743\n",
      "total -249.0 avg -0.3351278600269134\n",
      "744\n",
      "total -254.0 avg -0.341397849462361\n",
      "745\n",
      "total -253.0 avg -0.33959731543623706\n",
      "746\n",
      "total -252.0 avg -0.3378016085790839\n",
      "747\n",
      "total -251.0 avg -0.3360107095046809\n",
      "748\n",
      "total -254.75 avg -0.3405748663101559\n",
      "749\n",
      "total -254.75 avg -0.34012016021361363\n",
      "750\n",
      "total -258.5 avg -0.34466666666666207\n",
      "751\n",
      "total -257.5 avg -0.34287616511317787\n",
      "752\n",
      "total -262.5 avg -0.3490691489361656\n",
      "753\n",
      "total -263.5 avg -0.34993359893757836\n",
      "754\n",
      "total -267.25 avg -0.35444297082227644\n",
      "755\n",
      "total -271.0 avg -0.3589403973509886\n",
      "756\n",
      "total -270.0 avg -0.35714285714285243\n",
      "757\n",
      "total -269.0 avg -0.3553500660501935\n",
      "758\n",
      "total -268.0 avg -0.3535620052770402\n",
      "759\n",
      "total -267.0 avg -0.3517786561264776\n",
      "760\n",
      "total -266.0 avg -0.34999999999999537\n",
      "761\n",
      "total -262.25 avg -0.3446123521681952\n",
      "762\n",
      "total -261.25 avg -0.3428477690288669\n",
      "763\n",
      "total -260.25 avg -0.34108781127129306\n",
      "764\n",
      "total -259.25 avg -0.33933246073297985\n",
      "765\n",
      "total -258.25 avg -0.3375816993464008\n",
      "766\n",
      "total -257.25 avg -0.33583550913837684\n",
      "767\n",
      "total -258.25 avg -0.3367014341590569\n",
      "768\n",
      "total -262.0 avg -0.3411458333333289\n",
      "769\n",
      "total -258.25 avg -0.33582574772431295\n",
      "770\n",
      "total -257.25 avg -0.3340909090909048\n",
      "771\n",
      "total -261.0 avg -0.33852140077820575\n",
      "772\n",
      "total -257.25 avg -0.33322538860103196\n",
      "773\n",
      "total -262.25 avg -0.3392626131953384\n",
      "774\n",
      "total -266.0 avg -0.3436692506459904\n",
      "775\n",
      "total -269.75 avg -0.3480645161290278\n",
      "776\n",
      "total -268.75 avg -0.3463273195876244\n",
      "777\n",
      "total -269.75 avg -0.3471685971685927\n",
      "778\n",
      "total -274.75 avg -0.35314910025706486\n",
      "779\n",
      "total -274.75 avg -0.3526957637997387\n",
      "780\n",
      "total -273.75 avg -0.35096153846153394\n",
      "781\n",
      "total -272.75 avg -0.3492317541613272\n",
      "782\n",
      "total -271.75 avg -0.34750639386188814\n",
      "783\n",
      "total -272.75 avg -0.3483397190293698\n",
      "784\n",
      "total -273.75 avg -0.3491709183673425\n",
      "785\n",
      "total -272.75 avg -0.34745222929935865\n",
      "786\n",
      "total -269.0 avg -0.3422391857506318\n",
      "787\n",
      "total -272.75 avg -0.3465692503176576\n",
      "788\n",
      "total -277.75 avg -0.3524746192893356\n",
      "789\n",
      "total -277.75 avg -0.3520278833967002\n",
      "790\n",
      "total -276.75 avg -0.35031645569619807\n",
      "791\n",
      "total -275.75 avg -0.348609355246519\n",
      "792\n",
      "total -279.5 avg -0.35290404040403595\n",
      "793\n",
      "total -284.5 avg -0.35876418663303455\n",
      "794\n",
      "total -283.5 avg -0.35705289672543633\n",
      "795\n",
      "total -282.5 avg -0.35534591194968107\n",
      "796\n",
      "total -281.5 avg -0.35364321608039756\n",
      "797\n",
      "total -286.5 avg -0.3594730238393932\n",
      "798\n",
      "total -285.5 avg -0.35776942355889274\n",
      "799\n",
      "total -289.25 avg -0.3620150187734623\n",
      "800\n",
      "total -285.5 avg -0.35687499999999556\n",
      "801\n",
      "total -284.5 avg -0.3551810237203451\n",
      "802\n",
      "total -285.5 avg -0.35598503740647935\n",
      "803\n",
      "total -284.5 avg -0.3542963885429595\n",
      "804\n",
      "total -283.5 avg -0.35261194029850307\n",
      "805\n",
      "total -282.5 avg -0.3509316770186292\n",
      "806\n",
      "total -281.5 avg -0.34925558312654653\n",
      "807\n",
      "total -280.5 avg -0.34758364312267226\n",
      "808\n",
      "total -279.5 avg -0.3459158415841541\n",
      "809\n",
      "total -275.75 avg -0.34085290482076214\n",
      "810\n",
      "total -276.75 avg -0.34166666666666246\n",
      "811\n",
      "total -281.75 avg -0.3474106041923508\n",
      "812\n",
      "total -280.75 avg -0.3457512315270893\n",
      "813\n",
      "total -279.75 avg -0.3440959409594054\n",
      "814\n",
      "total -276.0 avg -0.3390663390663349\n",
      "815\n",
      "total -277.0 avg -0.33987730061349275\n",
      "816\n",
      "total -276.0 avg -0.3382352941176429\n",
      "817\n",
      "total -275.0 avg -0.33659730722153813\n",
      "818\n",
      "total -280.0 avg -0.34229828850855326\n",
      "819\n",
      "total -279.0 avg -0.3406593406593365\n",
      "820\n",
      "total -278.0 avg -0.3390243902438983\n",
      "821\n",
      "total -277.0 avg -0.3373934226552943\n",
      "822\n",
      "total -280.75 avg -0.34154501216544597\n",
      "823\n",
      "total -280.75 avg -0.34113001215066413\n",
      "824\n",
      "total -279.75 avg -0.3395024271844619\n",
      "825\n",
      "total -283.5 avg -0.34363636363635947\n",
      "826\n",
      "total -282.5 avg -0.34200968523002007\n",
      "827\n",
      "total -281.5 avg -0.3403869407496936\n",
      "828\n",
      "total -280.5 avg -0.3387681159420249\n",
      "829\n",
      "total -279.5 avg -0.3371531966224326\n",
      "830\n",
      "total -278.5 avg -0.3355421686746948\n",
      "831\n",
      "total -277.5 avg -0.3339350180505375\n",
      "832\n",
      "total -277.5 avg -0.33353365384614986\n",
      "833\n",
      "total -276.5 avg -0.3319327731092397\n",
      "834\n",
      "total -272.75 avg -0.32703836930455243\n",
      "835\n",
      "total -277.75 avg -0.3326347305389182\n",
      "836\n",
      "total -276.75 avg -0.33104066985645536\n",
      "837\n",
      "total -275.75 avg -0.32945041816009163\n",
      "838\n",
      "total -280.75 avg -0.33502386634844467\n",
      "839\n",
      "total -279.75 avg -0.33343265792609855\n",
      "840\n",
      "total -278.75 avg -0.33184523809523414\n",
      "841\n",
      "total -273.75 avg -0.32550535077288556\n",
      "842\n",
      "total -272.75 avg -0.32393111638954486\n",
      "843\n",
      "total -277.75 avg -0.3294780545670186\n",
      "844\n",
      "total -274.0 avg -0.3246445497630293\n",
      "845\n",
      "total -277.75 avg -0.3286982248520671\n",
      "846\n",
      "total -276.75 avg -0.3271276595744642\n",
      "847\n",
      "total -275.75 avg -0.3255608028335263\n",
      "848\n",
      "total -274.75 avg -0.3239976415094301\n",
      "849\n",
      "total -273.75 avg -0.3224381625441658\n",
      "850\n",
      "total -272.75 avg -0.3208823529411727\n",
      "851\n",
      "total -269.0 avg -0.3160987074030515\n",
      "852\n",
      "total -268.0 avg -0.31455399061032496\n",
      "853\n",
      "total -263.0 avg -0.30832356389214177\n",
      "854\n",
      "total -262.0 avg -0.30679156908664745\n",
      "855\n",
      "total -265.75 avg -0.3108187134502888\n",
      "856\n",
      "total -264.75 avg -0.3092873831775665\n",
      "857\n",
      "total -268.5 avg -0.31330221703616906\n",
      "858\n",
      "total -267.5 avg -0.3117715617715581\n",
      "859\n",
      "total -263.75 avg -0.3070430733410907\n",
      "860\n",
      "total -267.5 avg -0.31104651162790337\n",
      "861\n",
      "total -272.5 avg -0.31649245063878845\n",
      "862\n",
      "total -277.5 avg -0.3219257540603211\n",
      "863\n",
      "total -282.5 avg -0.32734646581691396\n",
      "864\n",
      "total -286.25 avg -0.3313078703703665\n",
      "865\n",
      "total -285.25 avg -0.3297687861271638\n",
      "866\n",
      "total -286.25 avg -0.3305427251732063\n",
      "867\n",
      "total -285.25 avg -0.3290080738177586\n",
      "868\n",
      "total -284.25 avg -0.32747695852534187\n",
      "869\n",
      "total -285.25 avg -0.3282508630609859\n",
      "870\n",
      "total -284.25 avg -0.3267241379310307\n",
      "871\n",
      "total -283.25 avg -0.32520091848449684\n",
      "872\n",
      "total -288.25 avg -0.3305619266055008\n",
      "873\n",
      "total -287.25 avg -0.32903780068728145\n",
      "874\n",
      "total -286.25 avg -0.3275171624713921\n",
      "875\n",
      "total -282.5 avg -0.3228571428571392\n",
      "876\n",
      "total -286.25 avg -0.3267694063926903\n",
      "877\n",
      "total -285.25 avg -0.32525655644241364\n",
      "878\n",
      "total -284.25 avg -0.3237471526195863\n",
      "879\n",
      "total -283.25 avg -0.3222411831626812\n",
      "880\n",
      "total -282.25 avg -0.3207386363636327\n",
      "881\n",
      "total -278.5 avg -0.31611804767309515\n",
      "882\n",
      "total -283.5 avg -0.3214285714285678\n",
      "883\n",
      "total -283.5 avg -0.321064552661378\n",
      "884\n",
      "total -284.5 avg -0.3218325791855167\n",
      "885\n",
      "total -280.75 avg -0.3172316384180755\n",
      "886\n",
      "total -279.75 avg -0.31574492099322443\n",
      "887\n",
      "total -278.75 avg -0.3142615558060844\n",
      "888\n",
      "total -278.75 avg -0.3139076576576541\n",
      "889\n",
      "total -282.5 avg -0.3177727784026961\n",
      "890\n",
      "total -281.5 avg -0.31629213483145713\n",
      "891\n",
      "total -280.5 avg -0.3148148148148113\n",
      "892\n",
      "total -279.5 avg -0.3133408071748844\n",
      "893\n",
      "total -278.5 avg -0.31187010078387106\n",
      "894\n",
      "total -277.5 avg -0.3104026845637549\n",
      "895\n",
      "total -276.5 avg -0.30893854748603006\n",
      "896\n",
      "total -280.25 avg -0.31277901785713935\n",
      "897\n",
      "total -279.25 avg -0.31131549609810133\n",
      "898\n",
      "total -275.5 avg -0.30679287305122155\n",
      "899\n",
      "total -279.25 avg -0.3106229143492735\n",
      "900\n",
      "total -283.0 avg -0.314444444444441\n",
      "901\n",
      "total -282.0 avg -0.3129855715871219\n",
      "902\n",
      "total -287.0 avg -0.3181818181818147\n",
      "903\n",
      "total -290.75 avg -0.3219822812846033\n",
      "904\n",
      "total -289.75 avg -0.3205199115044212\n",
      "905\n",
      "total -288.75 avg -0.3190607734806595\n",
      "906\n",
      "total -293.75 avg -0.3242273730684291\n",
      "907\n",
      "total -294.75 avg -0.32497243660418607\n",
      "908\n",
      "total -298.5 avg -0.32874449339206685\n",
      "909\n",
      "total -297.5 avg -0.3272827282728237\n",
      "910\n",
      "total -297.5 avg -0.3269230769230733\n",
      "911\n",
      "total -296.5 avg -0.32546652030735096\n",
      "912\n",
      "total -292.75 avg -0.3209978070175403\n",
      "913\n",
      "total -291.75 avg -0.3195509309967106\n",
      "914\n",
      "total -286.75 avg -0.31373085339168144\n",
      "915\n",
      "total -287.75 avg -0.31448087431693644\n",
      "916\n",
      "total -286.75 avg -0.3130458515283809\n",
      "917\n",
      "total -287.75 avg -0.31379498364230846\n",
      "918\n",
      "total -284.0 avg -0.3093681917211295\n",
      "919\n",
      "total -283.0 avg -0.3079434167573416\n",
      "920\n",
      "total -282.0 avg -0.30652173913043146\n",
      "921\n",
      "total -281.0 avg -0.3051031487513539\n",
      "922\n",
      "total -286.0 avg -0.31019522776572334\n",
      "923\n",
      "total -287.0 avg -0.310942578548209\n",
      "924\n",
      "total -286.0 avg -0.30952380952380615\n",
      "925\n",
      "total -289.75 avg -0.3132432432432399\n",
      "926\n",
      "total -288.75 avg -0.311825053995677\n",
      "927\n",
      "total -287.75 avg -0.310409924487591\n",
      "928\n",
      "total -286.75 avg -0.30899784482758286\n",
      "929\n",
      "total -290.5 avg -0.3127018299246468\n",
      "930\n",
      "total -289.5 avg -0.3112903225806418\n",
      "931\n",
      "total -288.5 avg -0.3098818474758291\n",
      "932\n",
      "total -287.5 avg -0.3084763948497821\n",
      "933\n",
      "total -286.5 avg -0.30707395498391954\n",
      "934\n",
      "total -290.25 avg -0.31076017130620653\n",
      "935\n",
      "total -289.25 avg -0.30935828877005017\n",
      "936\n",
      "total -290.25 avg -0.3100961538461505\n",
      "937\n",
      "total -291.25 avg -0.31083244397011406\n",
      "938\n",
      "total -290.25 avg -0.3094349680170543\n",
      "939\n",
      "total -290.25 avg -0.30910543130990087\n",
      "940\n",
      "total -289.25 avg -0.3077127659574435\n",
      "941\n",
      "total -289.25 avg -0.30738575982996486\n",
      "942\n",
      "total -288.25 avg -0.3059978768577462\n",
      "943\n",
      "total -287.25 avg -0.3046129374337189\n",
      "944\n",
      "total -286.25 avg -0.3032309322033866\n",
      "945\n",
      "total -290.0 avg -0.30687830687830364\n",
      "946\n",
      "total -289.0 avg -0.30549682875263945\n",
      "947\n",
      "total -288.0 avg -0.3041182682154139\n",
      "948\n",
      "total -287.0 avg -0.3027426160337521\n",
      "949\n",
      "total -288.0 avg -0.3034773445732318\n",
      "950\n",
      "total -287.0 avg -0.30210526315789155\n",
      "951\n",
      "total -286.0 avg -0.30073606729757835\n",
      "952\n",
      "total -289.75 avg -0.3043592436974758\n",
      "953\n",
      "total -288.75 avg -0.3029905561385068\n",
      "954\n",
      "total -285.0 avg -0.29874213836477675\n",
      "955\n",
      "total -285.0 avg -0.2984293193717246\n",
      "956\n",
      "total -286.0 avg -0.29916317991631486\n",
      "957\n",
      "total -285.0 avg -0.29780564263322573\n",
      "958\n",
      "total -284.0 avg -0.2964509394571994\n",
      "959\n",
      "total -280.25 avg -0.2922314911365976\n",
      "960\n",
      "total -279.25 avg -0.2908854166666636\n",
      "961\n",
      "total -274.25 avg -0.2853798126951063\n",
      "962\n",
      "total -278.0 avg -0.288981288981286\n",
      "963\n",
      "total -277.0 avg -0.28764278296988277\n",
      "964\n",
      "total -280.75 avg -0.29123443983402186\n",
      "965\n",
      "total -279.75 avg -0.28989637305699184\n",
      "966\n",
      "total -278.75 avg -0.2885610766045519\n",
      "967\n",
      "total -279.75 avg -0.2892967942088905\n",
      "968\n",
      "total -283.5 avg -0.29287190082644327\n",
      "969\n",
      "total -287.25 avg -0.29643962848296906\n",
      "970\n",
      "total -291.0 avg -0.2999999999999969\n",
      "971\n",
      "total -290.0 avg -0.29866117404737075\n",
      "972\n",
      "total -289.0 avg -0.2973251028806554\n",
      "973\n",
      "total -294.0 avg -0.30215827338129186\n",
      "974\n",
      "total -293.0 avg -0.30082135523613657\n",
      "975\n",
      "total -298.0 avg -0.3056410256410225\n",
      "976\n",
      "total -297.0 avg -0.3043032786885215\n",
      "977\n",
      "total -293.25 avg -0.30015353121801125\n",
      "978\n",
      "total -289.5 avg -0.29601226993864727\n",
      "979\n",
      "total -288.5 avg -0.2946884576098029\n",
      "980\n",
      "total -287.5 avg -0.29336734693877253\n",
      "981\n",
      "total -286.5 avg -0.29204892966360557\n",
      "982\n",
      "total -285.5 avg -0.2907331975560052\n",
      "983\n",
      "total -284.5 avg -0.28942014242115677\n",
      "984\n",
      "total -283.5 avg -0.28810975609755807\n",
      "985\n",
      "total -282.5 avg -0.2868020304568499\n",
      "986\n",
      "total -283.5 avg -0.2875253549695711\n",
      "987\n",
      "total -282.5 avg -0.2862208713272514\n",
      "988\n",
      "total -281.5 avg -0.2849190283400781\n",
      "989\n",
      "total -281.5 avg -0.2846309403437787\n",
      "990\n",
      "total -285.25 avg -0.28813131313131024\n",
      "991\n",
      "total -281.5 avg -0.2840565085771919\n",
      "992\n",
      "total -280.5 avg -0.2827620967741907\n",
      "993\n",
      "total -279.5 avg -0.28147029204430735\n",
      "994\n",
      "total -278.5 avg -0.2801810865191119\n",
      "995\n",
      "total -277.5 avg -0.27889447236180626\n",
      "996\n",
      "total -273.75 avg -0.2748493975903587\n",
      "997\n",
      "total -274.75 avg -0.27557673019056894\n",
      "998\n",
      "total -273.75 avg -0.27429859719438604\n",
      "999\n",
      "total -277.5 avg -0.277777777777775\n",
      "1000\n",
      "total -278.5 avg -0.2784999999999972\n",
      "1001\n",
      "total -283.5 avg -0.2832167832167804\n",
      "1002\n",
      "total -282.5 avg -0.28193612774450816\n",
      "1003\n",
      "total -283.5 avg -0.282652043868392\n",
      "1004\n",
      "total -288.5 avg -0.2873505976095589\n",
      "1005\n",
      "total -287.5 avg -0.2860696517412907\n",
      "1006\n",
      "total -286.5 avg -0.28479125248508663\n",
      "1007\n",
      "total -285.5 avg -0.2835153922542176\n",
      "1008\n",
      "total -284.5 avg -0.2822420634920607\n",
      "1009\n",
      "total -283.5 avg -0.28097125867194966\n",
      "1010\n",
      "total -288.5 avg -0.2856435643564328\n",
      "1011\n",
      "total -289.5 avg -0.2863501483679497\n",
      "1012\n",
      "total -288.5 avg -0.2850790513833964\n",
      "1013\n",
      "total -287.5 avg -0.28381046396840787\n",
      "1014\n",
      "total -286.5 avg -0.2825443786982221\n",
      "1015\n",
      "total -287.5 avg -0.2832512315270908\n",
      "1016\n",
      "total -286.5 avg -0.2819881889763752\n",
      "1017\n",
      "total -285.5 avg -0.28072763028514963\n",
      "1018\n",
      "total -284.5 avg -0.27946954813359254\n",
      "1019\n",
      "total -285.5 avg -0.2801766437683976\n",
      "1020\n",
      "total -284.5 avg -0.27892156862744827\n",
      "1021\n",
      "total -283.5 avg -0.27766895200783276\n",
      "1022\n",
      "total -287.25 avg -0.28106653620351973\n",
      "1023\n",
      "total -291.0 avg -0.2844574780058623\n",
      "1024\n",
      "total -290.0 avg -0.2832031249999972\n",
      "1025\n",
      "total -291.0 avg -0.2839024390243875\n",
      "1026\n",
      "total -296.0 avg -0.2884990253411278\n",
      "1027\n",
      "total -295.0 avg -0.287244401168449\n",
      "1028\n",
      "total -294.0 avg -0.2859922178988299\n",
      "1029\n",
      "total -297.75 avg -0.28935860058308754\n",
      "1030\n",
      "total -296.75 avg -0.28810679611650203\n",
      "1031\n",
      "total -293.0 avg -0.28419010669252875\n",
      "1032\n",
      "total -294.0 avg -0.2848837209302298\n",
      "1033\n",
      "total -294.0 avg -0.2846079380445277\n",
      "1034\n",
      "total -295.0 avg -0.2852998065763996\n",
      "1035\n",
      "total -300.0 avg -0.2898550724637653\n",
      "1036\n",
      "total -299.0 avg -0.2886100386100358\n",
      "1037\n",
      "total -302.75 avg -0.2919479267116655\n",
      "1038\n",
      "total -307.75 avg -0.2964836223506715\n",
      "1039\n",
      "total -306.75 avg -0.29523580365736\n",
      "1040\n",
      "total -311.75 avg -0.2997596153846125\n",
      "1041\n",
      "total -312.75 avg -0.30043227665705763\n",
      "1042\n",
      "total -313.75 avg -0.30110364683301055\n",
      "1043\n",
      "total -313.75 avg -0.3008149568552224\n",
      "1044\n",
      "total -313.75 avg -0.30052681992336877\n",
      "1045\n",
      "total -312.75 avg -0.2992822966507148\n",
      "1046\n",
      "total -311.75 avg -0.29804015296366826\n",
      "1047\n",
      "total -310.75 avg -0.2968003820439322\n",
      "1048\n",
      "total -309.75 avg -0.2955629770992338\n",
      "1049\n",
      "total -314.75 avg -0.30004766444232317\n",
      "1050\n",
      "total -313.75 avg -0.29880952380952097\n",
      "1051\n",
      "total -312.75 avg -0.2975737392959058\n",
      "1052\n",
      "total -311.75 avg -0.2963403041825067\n",
      "1053\n",
      "total -310.75 avg -0.2951092117758756\n",
      "1054\n",
      "total -309.75 avg -0.29388045540796687\n",
      "1055\n",
      "total -309.75 avg -0.2936018957345944\n",
      "1056\n",
      "total -308.75 avg -0.29237689393939115\n",
      "1057\n",
      "total -307.75 avg -0.29115421002837943\n",
      "1058\n",
      "total -306.75 avg -0.2899338374291088\n",
      "1059\n",
      "total -303.0 avg -0.28611898016996895\n",
      "1060\n",
      "total -302.0 avg -0.2849056603773558\n",
      "1061\n",
      "total -305.75 avg -0.2881715362865194\n",
      "1062\n",
      "total -304.75 avg -0.28695856873822706\n",
      "1063\n",
      "total -305.75 avg -0.2876293508936944\n",
      "1064\n",
      "total -304.75 avg -0.28641917293232816\n",
      "1065\n",
      "total -308.5 avg -0.2896713615023447\n",
      "1066\n",
      "total -307.5 avg -0.28846153846153577\n",
      "1067\n",
      "total -306.5 avg -0.2872539831302691\n",
      "1068\n",
      "total -305.5 avg -0.2860486891385741\n",
      "1069\n",
      "total -310.5 avg -0.2904583723105679\n",
      "1070\n",
      "total -309.5 avg -0.28925233644859544\n",
      "1071\n",
      "total -314.5 avg -0.2936507936507909\n",
      "1072\n",
      "total -313.5 avg -0.2924440298507435\n",
      "1073\n",
      "total -312.5 avg -0.2912395153774437\n",
      "1074\n",
      "total -313.5 avg -0.2918994413407794\n",
      "1075\n",
      "total -313.5 avg -0.29162790697674146\n",
      "1076\n",
      "total -314.5 avg -0.2922862453531571\n",
      "1077\n",
      "total -318.25 avg -0.2954967502321235\n",
      "1078\n",
      "total -322.0 avg -0.2987012987012959\n",
      "1079\n",
      "total -321.0 avg -0.29749768303984897\n",
      "1080\n",
      "total -320.0 avg -0.29629629629629356\n",
      "1081\n",
      "total -319.0 avg -0.29509713228491863\n",
      "1082\n",
      "total -319.5 avg -0.29528650646949817\n",
      "1083\n",
      "total -320.5 avg -0.2959372114496741\n",
      "1084\n",
      "total -319.5 avg -0.2947416974169714\n",
      "1085\n",
      "total -323.25 avg -0.2979262672811032\n",
      "1086\n",
      "total -322.25 avg -0.2967311233885792\n",
      "1087\n",
      "total -321.25 avg -0.29553817847285835\n",
      "1088\n",
      "total -325.0 avg -0.2987132352941149\n",
      "1089\n",
      "total -328.75 avg -0.3018824609733673\n",
      "1090\n",
      "total -325.0 avg -0.29816513761467617\n",
      "1091\n",
      "total -324.0 avg -0.2969752520623254\n",
      "1092\n",
      "total -323.0 avg -0.29578754578754307\n",
      "1093\n",
      "total -328.0 avg -0.30009149130832297\n",
      "1094\n",
      "total -327.0 avg -0.2989031078610576\n",
      "1095\n",
      "total -330.75 avg -0.3020547945205452\n",
      "1096\n",
      "total -331.75 avg -0.3026916058394133\n",
      "1097\n",
      "total -328.0 avg -0.2989972652689125\n",
      "1098\n",
      "total -327.0 avg -0.2978142076502705\n",
      "1099\n",
      "total -326.0 avg -0.29663330300272706\n",
      "1100\n",
      "total -322.25 avg -0.2929545454545428\n",
      "1101\n",
      "total -317.25 avg -0.28814713896457506\n",
      "1102\n",
      "total -321.0 avg -0.29128856624319155\n",
      "1103\n",
      "total -317.25 avg -0.28762466001812975\n",
      "1104\n",
      "total -316.25 avg -0.28645833333333076\n",
      "1105\n",
      "total -315.25 avg -0.28529411764705626\n",
      "1106\n",
      "total -320.25 avg -0.28955696202531384\n",
      "1107\n",
      "total -319.25 avg -0.28839205058716993\n",
      "1108\n",
      "total -314.25 avg -0.28361913357400464\n",
      "1109\n",
      "total -313.25 avg -0.2824616771866521\n",
      "1110\n",
      "total -312.25 avg -0.28130630630630377\n",
      "1111\n",
      "total -311.25 avg -0.28015301530152764\n",
      "1112\n",
      "total -316.25 avg -0.2843974820143859\n",
      "1113\n",
      "total -315.25 avg -0.2832434860736722\n",
      "1114\n",
      "total -314.25 avg -0.2820915619389562\n",
      "1115\n",
      "total -310.5 avg -0.2784753363228675\n",
      "1116\n",
      "total -309.5 avg -0.27732974910394015\n",
      "1117\n",
      "total -308.5 avg -0.27618621307072266\n",
      "1118\n",
      "total -309.5 avg -0.2768336314847918\n",
      "1119\n",
      "total -308.5 avg -0.2756925826630896\n",
      "1120\n",
      "total -307.5 avg -0.27455357142856895\n",
      "1121\n",
      "total -306.5 avg -0.27341659232827586\n",
      "1122\n",
      "total -305.5 avg -0.2722816399286963\n",
      "1123\n",
      "total -310.5 avg -0.2764915405164713\n",
      "1124\n",
      "total -309.5 avg -0.27535587188611854\n",
      "1125\n",
      "total -308.5 avg -0.27422222222221976\n",
      "1126\n",
      "total -307.5 avg -0.2730905861456459\n",
      "1127\n",
      "total -303.75 avg -0.26952085181898605\n",
      "1128\n",
      "total -303.75 avg -0.26928191489361464\n",
      "1129\n",
      "total -302.75 avg -0.2681576616474733\n",
      "1130\n",
      "total -303.75 avg -0.2688053097345109\n",
      "1131\n",
      "total -304.75 avg -0.26945181255525846\n",
      "1132\n",
      "total -308.5 avg -0.27252650176678206\n",
      "1133\n",
      "total -307.5 avg -0.2714033539276234\n",
      "1134\n",
      "total -306.5 avg -0.27028218694885126\n",
      "1135\n",
      "total -305.5 avg -0.2691629955947113\n",
      "1136\n",
      "total -306.5 avg -0.2698063380281666\n",
      "1137\n",
      "total -305.5 avg -0.26868953386103545\n",
      "1138\n",
      "total -304.5 avg -0.2675746924428799\n",
      "1139\n",
      "total -303.5 avg -0.2664618086040363\n",
      "1140\n",
      "total -304.5 avg -0.2671052631578924\n",
      "1141\n",
      "total -305.5 avg -0.2677475898334771\n",
      "1142\n",
      "total -304.5 avg -0.2666374781085791\n",
      "1143\n",
      "total -303.5 avg -0.26552930883639314\n",
      "1144\n",
      "total -302.5 avg -0.2644230769230746\n",
      "1145\n",
      "total -301.5 avg -0.26331877729257414\n",
      "1146\n",
      "total -305.25 avg -0.26636125654450027\n",
      "1147\n",
      "total -304.25 avg -0.2652571926765452\n",
      "1148\n",
      "total -303.25 avg -0.26415505226480607\n",
      "1149\n",
      "total -308.25 avg -0.2682767624020864\n",
      "1150\n",
      "total -307.25 avg -0.26717391304347593\n",
      "1151\n",
      "total -303.5 avg -0.2636837532580342\n",
      "1152\n",
      "total -302.5 avg -0.26258680555555325\n",
      "1153\n",
      "total -301.5 avg -0.26149176062445567\n",
      "1154\n",
      "total -305.25 avg -0.2645147313691485\n",
      "1155\n",
      "total -301.5 avg -0.2610389610389588\n",
      "1156\n",
      "total -300.5 avg -0.2599480968858109\n",
      "1157\n",
      "total -299.5 avg -0.25885911840967796\n",
      "1158\n",
      "total -298.5 avg -0.25777202072538635\n",
      "1159\n",
      "total -297.5 avg -0.2566867989646225\n",
      "1160\n",
      "total -293.75 avg -0.25323275862068745\n",
      "1161\n",
      "total -292.75 avg -0.2521533161068023\n",
      "1162\n",
      "total -291.75 avg -0.2510757314974161\n",
      "1163\n",
      "total -290.75 avg -0.24999999999999786\n",
      "1164\n",
      "total -294.5 avg -0.2530068728522315\n",
      "1165\n",
      "total -293.5 avg -0.25193133047210087\n",
      "1166\n",
      "total -298.5 avg -0.25600343053173025\n",
      "1167\n",
      "total -302.25 avg -0.25899742930591035\n",
      "1168\n",
      "total -301.25 avg -0.257919520547943\n",
      "1169\n",
      "total -300.25 avg -0.25684345594525015\n",
      "1170\n",
      "total -304.0 avg -0.25982905982905763\n",
      "1171\n",
      "total -309.0 avg -0.2638770281810396\n",
      "1172\n",
      "total -309.0 avg -0.26365187713310356\n",
      "1173\n",
      "total -308.0 avg -0.26257459505541125\n",
      "1174\n",
      "total -307.0 avg -0.2614991482112414\n",
      "1175\n",
      "total -312.0 avg -0.2655319148936148\n",
      "1176\n",
      "total -311.0 avg -0.26445578231292294\n",
      "1177\n",
      "total -310.0 avg -0.2633814783347471\n",
      "1178\n",
      "total -315.0 avg -0.2674023769100147\n",
      "1179\n",
      "total -314.0 avg -0.2663273960983862\n",
      "1180\n",
      "total -310.25 avg -0.2629237288135571\n",
      "1181\n",
      "total -309.25 avg -0.26185436071125945\n",
      "1182\n",
      "total -308.25 avg -0.2607868020304546\n",
      "1183\n",
      "total -312.0 avg -0.2637362637362615\n",
      "1184\n",
      "total -311.0 avg -0.2626689189189167\n",
      "1185\n",
      "total -310.0 avg -0.26160337552742396\n",
      "1186\n",
      "total -311.0 avg -0.26222596964586625\n",
      "1187\n",
      "total -310.0 avg -0.2611625947767459\n",
      "1188\n",
      "total -310.0 avg -0.26094276094275876\n",
      "1189\n",
      "total -309.0 avg -0.2598822539949516\n",
      "1190\n",
      "total -310.0 avg -0.26050420168067007\n",
      "1191\n",
      "total -313.75 avg -0.2634340890008374\n",
      "1192\n",
      "total -312.75 avg -0.2623741610738233\n",
      "1193\n",
      "total -311.75 avg -0.26131601005867344\n",
      "1194\n",
      "total -310.75 avg -0.26025963149078507\n",
      "1195\n",
      "total -309.75 avg -0.2592050209204999\n",
      "1196\n",
      "total -308.75 avg -0.2581521739130413\n",
      "1197\n",
      "total -307.75 avg -0.25710108604845233\n",
      "1198\n",
      "total -306.75 avg -0.25605175292153376\n",
      "1199\n",
      "total -303.0 avg -0.2527105921601313\n",
      "1200\n",
      "total -303.0 avg -0.2524999999999979\n",
      "1201\n",
      "total -298.0 avg -0.24812656119899876\n",
      "1202\n",
      "total -299.0 avg -0.24875207986688644\n",
      "1203\n",
      "total -298.0 avg -0.24771404821279927\n",
      "1204\n",
      "total -297.0 avg -0.24667774086378533\n",
      "1205\n",
      "total -296.0 avg -0.24564315352696892\n",
      "1206\n",
      "total -295.0 avg -0.24461028192371273\n",
      "1207\n",
      "total -294.0 avg -0.24357912178955887\n",
      "1208\n",
      "total -294.0 avg -0.2433774834437066\n",
      "1209\n",
      "total -293.0 avg -0.2423490488006597\n",
      "1210\n",
      "total -293.0 avg -0.2421487603305765\n",
      "1211\n",
      "total -292.0 avg -0.24112303881089808\n",
      "1212\n",
      "total -297.0 avg -0.24504950495049302\n",
      "1213\n",
      "total -296.0 avg -0.24402308326463112\n",
      "1214\n",
      "total -296.0 avg -0.24382207578253506\n",
      "1215\n",
      "total -295.0 avg -0.24279835390946303\n",
      "1216\n",
      "total -294.0 avg -0.2417763157894717\n",
      "1217\n",
      "total -293.0 avg -0.2407559572719783\n",
      "1218\n",
      "total -292.0 avg -0.23973727422003088\n",
      "1219\n",
      "total -295.75 avg -0.24261689909761902\n",
      "1220\n",
      "total -294.75 avg -0.24159836065573573\n",
      "1221\n",
      "total -293.75 avg -0.24058149058148862\n",
      "1222\n",
      "total -290.0 avg -0.237315875613746\n",
      "1223\n",
      "total -295.0 avg -0.241210139002451\n",
      "1224\n",
      "total -294.0 avg -0.24019607843137059\n",
      "1225\n",
      "total -293.0 avg -0.2391836734693858\n",
      "1226\n",
      "total -296.75 avg -0.242047308319737\n",
      "1227\n",
      "total -295.75 avg -0.24103504482477392\n",
      "1228\n",
      "total -300.75 avg -0.24491042345276673\n",
      "1229\n",
      "total -299.75 avg -0.24389747762408265\n",
      "1230\n",
      "total -298.75 avg -0.24288617886178665\n",
      "1231\n",
      "total -298.75 avg -0.24268887083671614\n",
      "1232\n",
      "total -303.75 avg -0.24655032467532267\n",
      "1233\n",
      "total -303.75 avg -0.24635036496350166\n",
      "1234\n",
      "total -308.75 avg -0.2502025931928667\n",
      "1235\n",
      "total -307.75 avg -0.2491902834008077\n",
      "1236\n",
      "total -312.75 avg -0.25303398058252224\n",
      "1237\n",
      "total -316.5 avg -0.255860953920774\n",
      "1238\n",
      "total -315.5 avg -0.2548465266558945\n",
      "1239\n",
      "total -314.5 avg -0.2538337368845823\n",
      "1240\n",
      "total -313.5 avg -0.2528225806451592\n",
      "1241\n",
      "total -312.5 avg -0.25181305398871673\n",
      "1242\n",
      "total -316.25 avg -0.2546296296296276\n",
      "1243\n",
      "total -320.0 avg -0.2574416733708748\n",
      "1244\n",
      "total -319.0 avg -0.2564308681672005\n",
      "1245\n",
      "total -318.0 avg -0.2554216867469859\n",
      "1246\n",
      "total -317.0 avg -0.25441412520064\n",
      "1247\n",
      "total -320.75 avg -0.2572173215717702\n",
      "1248\n",
      "total -319.75 avg -0.25620993589743385\n",
      "1249\n",
      "total -318.75 avg -0.2552041633306625\n",
      "1250\n",
      "total -317.75 avg -0.254199999999998\n",
      "1251\n",
      "total -316.75 avg -0.2531974420463609\n",
      "1252\n",
      "total -321.75 avg -0.25698881789137173\n",
      "1253\n",
      "total -318.0 avg -0.25379090183559255\n",
      "1254\n",
      "total -314.25 avg -0.25059808612439993\n",
      "1255\n",
      "total -318.0 avg -0.2533864541832649\n",
      "1256\n",
      "total -321.75 avg -0.25617038216560306\n",
      "1257\n",
      "total -320.75 avg -0.2551710421638802\n",
      "1258\n",
      "total -317.0 avg -0.2519872813990441\n",
      "1259\n",
      "total -320.75 avg -0.25476568705321484\n",
      "1260\n",
      "total -324.5 avg -0.2575396825396805\n",
      "1261\n",
      "total -325.5 avg -0.2581284694686736\n",
      "1262\n",
      "total -324.5 avg -0.25713153724247023\n",
      "1263\n",
      "total -323.5 avg -0.2561361836896258\n",
      "1264\n",
      "total -322.5 avg -0.2551424050632891\n",
      "1265\n",
      "total -323.5 avg -0.25573122529644066\n",
      "1266\n",
      "total -328.5 avg -0.2594786729857799\n",
      "1267\n",
      "total -323.5 avg -0.255327545382792\n",
      "1268\n",
      "total -327.25 avg -0.258083596214509\n",
      "1269\n",
      "total -331.0 avg -0.2608353033884928\n",
      "1270\n",
      "total -331.0 avg -0.26062992125984047\n",
      "1271\n",
      "total -330.0 avg -0.2596380802517682\n",
      "1272\n",
      "total -329.0 avg -0.25864779874213634\n",
      "1273\n",
      "total -328.0 avg -0.25765907305577174\n",
      "1274\n",
      "total -327.0 avg -0.25667189952904035\n",
      "1275\n",
      "total -332.0 avg -0.26039215686274303\n",
      "1276\n",
      "total -335.75 avg -0.26312695924764684\n",
      "1277\n",
      "total -339.5 avg -0.2658574784651506\n",
      "1278\n",
      "total -335.75 avg -0.26271517996869903\n",
      "1279\n",
      "total -334.75 avg -0.2617279124315851\n",
      "1280\n",
      "total -333.75 avg -0.26074218749999795\n",
      "1281\n",
      "total -338.75 avg -0.26444184231069273\n",
      "1282\n",
      "total -337.75 avg -0.2634555382215268\n",
      "1283\n",
      "total -336.75 avg -0.2624707716289925\n",
      "1284\n",
      "total -333.0 avg -0.25934579439252137\n",
      "1285\n",
      "total -332.0 avg -0.2583657587548618\n",
      "1286\n",
      "total -331.0 avg -0.2573872472783806\n",
      "1287\n",
      "total -330.0 avg -0.25641025641025444\n",
      "1288\n",
      "total -333.75 avg -0.2591226708074514\n",
      "1289\n",
      "total -337.5 avg -0.26183087664856275\n",
      "1290\n",
      "total -336.5 avg -0.26085271317829256\n",
      "1291\n",
      "total -335.5 avg -0.25987606506583844\n",
      "1292\n",
      "total -334.5 avg -0.25890092879256765\n",
      "1293\n",
      "total -333.5 avg -0.25792730085073273\n",
      "1294\n",
      "total -332.5 avg -0.25695517774342924\n",
      "1295\n",
      "total -331.5 avg -0.255984555984554\n",
      "1296\n",
      "total -330.5 avg -0.2550154320987635\n",
      "1297\n",
      "total -334.25 avg -0.25771010023130103\n",
      "1298\n",
      "total -339.25 avg -0.26136363636363436\n",
      "1299\n",
      "total -338.25 avg -0.2603926096997671\n",
      "1300\n",
      "total -337.25 avg -0.2594230769230749\n",
      "1301\n",
      "total -341.0 avg -0.26210607225211174\n",
      "1302\n",
      "total -344.75 avg -0.26478494623655713\n",
      "1303\n",
      "total -348.5 avg -0.26745970836530875\n",
      "1304\n",
      "total -347.5 avg -0.2664877300613476\n",
      "1305\n",
      "total -343.75 avg -0.26340996168582176\n",
      "1306\n",
      "total -342.75 avg -0.2624425727411925\n",
      "1307\n",
      "total -341.75 avg -0.2614766641162949\n",
      "1308\n",
      "total -341.75 avg -0.2612767584097839\n",
      "1309\n",
      "total -340.75 avg -0.26031321619556713\n",
      "1310\n",
      "total -339.75 avg -0.259351145038166\n",
      "1311\n",
      "total -338.75 avg -0.25839054157131763\n",
      "1312\n",
      "total -337.75 avg -0.2574314024390224\n",
      "1313\n",
      "total -336.75 avg -0.2564737242955045\n",
      "1314\n",
      "total -333.0 avg -0.25342465753424465\n",
      "1315\n",
      "total -332.0 avg -0.2524714828897319\n",
      "1316\n",
      "total -335.75 avg -0.2551291793313051\n",
      "1317\n",
      "total -332.0 avg -0.25208807896734814\n",
      "1318\n",
      "total -331.0 avg -0.2511380880121377\n",
      "1319\n",
      "total -330.0 avg -0.2501895375284287\n",
      "1320\n",
      "total -329.0 avg -0.24924242424242235\n",
      "1321\n",
      "total -328.0 avg -0.2482967448902328\n",
      "1322\n",
      "total -328.0 avg -0.24810892586989222\n",
      "1323\n",
      "total -327.0 avg -0.2471655328798167\n",
      "1324\n",
      "total -326.0 avg -0.24622356495468092\n",
      "1325\n",
      "total -325.0 avg -0.24528301886792267\n",
      "1326\n",
      "total -324.0 avg -0.2443438914027131\n",
      "1327\n",
      "total -324.0 avg -0.24415975885455732\n",
      "1328\n",
      "total -327.75 avg -0.24679969879517885\n",
      "1329\n",
      "total -328.75 avg -0.24736644093303048\n",
      "1330\n",
      "total -327.75 avg -0.24642857142856958\n",
      "1331\n",
      "total -326.75 avg -0.2454921111945887\n",
      "1332\n",
      "total -325.75 avg -0.24455705705705522\n",
      "1333\n",
      "total -330.75 avg -0.24812453113278132\n",
      "1334\n",
      "total -335.75 avg -0.2516866566716623\n",
      "1335\n",
      "total -334.75 avg -0.2507490636704101\n",
      "1336\n",
      "total -339.75 avg -0.254303892215567\n",
      "1337\n",
      "total -344.75 avg -0.25785340314135935\n",
      "1338\n",
      "total -345.75 avg -0.258408071748877\n",
      "1339\n",
      "total -349.5 avg -0.26101568334577846\n",
      "1340\n",
      "total -344.5 avg -0.25708955223880403\n",
      "1341\n",
      "total -343.5 avg -0.25615212527964015\n",
      "1342\n",
      "total -342.5 avg -0.25521609538002793\n",
      "1343\n",
      "total -347.5 avg -0.25874906924795044\n",
      "1344\n",
      "total -346.5 avg -0.25781249999999806\n",
      "1345\n",
      "total -350.25 avg -0.26040892193308357\n",
      "1346\n",
      "total -349.25 avg -0.25947251114412884\n",
      "1347\n",
      "total -354.25 avg -0.2629918337045266\n",
      "1348\n",
      "total -353.25 avg -0.26205489614243127\n",
      "1349\n",
      "total -352.25 avg -0.26111934766493505\n",
      "1350\n",
      "total -356.0 avg -0.2637037037037018\n",
      "1351\n",
      "total -355.0 avg -0.26276831976313647\n",
      "1352\n",
      "total -358.75 avg -0.2653476331360927\n",
      "1353\n",
      "total -363.75 avg -0.2688470066518827\n",
      "1354\n",
      "total -367.5 avg -0.27141802067946624\n",
      "1355\n",
      "total -372.5 avg -0.27490774907748877\n",
      "1356\n",
      "total -376.25 avg -0.2774705014749242\n",
      "1357\n",
      "total -376.25 avg -0.27726602800294564\n",
      "1358\n",
      "total -377.25 avg -0.27779823269513787\n",
      "1359\n",
      "total -382.25 avg -0.2812729948491517\n",
      "1360\n",
      "total -382.25 avg -0.2810661764705862\n",
      "1361\n",
      "total -383.25 avg -0.28159441587068124\n",
      "1362\n",
      "total -382.25 avg -0.28065345080763376\n",
      "1363\n",
      "total -381.25 avg -0.27971386647101776\n",
      "1364\n",
      "total -380.25 avg -0.2787756598240449\n",
      "1365\n",
      "total -379.25 avg -0.2778388278388258\n",
      "1366\n",
      "total -378.25 avg -0.27690336749633765\n",
      "1367\n",
      "total -373.25 avg -0.2730431602048261\n",
      "1368\n",
      "total -369.5 avg -0.27010233918128457\n",
      "1369\n",
      "total -373.25 avg -0.2726442658875071\n",
      "1370\n",
      "total -373.25 avg -0.2724452554744506\n",
      "1371\n",
      "total -372.25 avg -0.2715171407731563\n",
      "1372\n",
      "total -377.25 avg -0.27496355685130996\n",
      "1373\n",
      "total -381.0 avg -0.27749453750910213\n",
      "1374\n",
      "total -382.0 avg -0.2780203784570577\n",
      "1375\n",
      "total -381.0 avg -0.27709090909090706\n",
      "1376\n",
      "total -386.0 avg -0.28052325581395143\n",
      "1377\n",
      "total -385.0 avg -0.27959331880900307\n",
      "1378\n",
      "total -385.0 avg -0.27939042089985283\n",
      "1379\n",
      "total -388.75 avg -0.2819071791152989\n",
      "1380\n",
      "total -392.5 avg -0.2844202898550704\n",
      "1381\n",
      "total -391.5 avg -0.28349022447501604\n",
      "1382\n",
      "total -395.25 avg -0.28599855282199504\n",
      "1383\n",
      "total -399.0 avg -0.2885032537960934\n",
      "1384\n",
      "total -398.0 avg -0.287572254335258\n",
      "1385\n",
      "total -394.25 avg -0.2846570397111893\n",
      "1386\n",
      "total -393.25 avg -0.28373015873015667\n",
      "1387\n",
      "total -392.25 avg -0.28280461427541254\n",
      "1388\n",
      "total -391.25 avg -0.28188040345821125\n",
      "1389\n",
      "total -390.25 avg -0.28095752339812613\n",
      "1390\n",
      "total -395.25 avg -0.28435251798560945\n",
      "1391\n",
      "total -395.25 avg -0.28414809489575643\n",
      "1392\n",
      "total -394.25 avg -0.28322557471264165\n",
      "1393\n",
      "total -398.0 avg -0.28571428571428364\n",
      "1394\n",
      "total -397.0 avg -0.28479196556671244\n",
      "1395\n",
      "total -400.75 avg -0.2872759856630804\n",
      "1396\n",
      "total -399.75 avg -0.2863538681948404\n",
      "1397\n",
      "total -398.75 avg -0.28543307086613967\n",
      "1398\n",
      "total -402.5 avg -0.28791130185979763\n",
      "1399\n",
      "total -398.75 avg -0.28502501786990503\n",
      "1400\n",
      "total -397.75 avg -0.28410714285714084\n",
      "1401\n",
      "total -397.75 avg -0.28390435403283165\n",
      "1402\n",
      "total -396.75 avg -0.2829885877318097\n",
      "1403\n",
      "total -400.5 avg -0.2854597291518155\n",
      "1404\n",
      "total -399.5 avg -0.2845441595441575\n",
      "1405\n",
      "total -404.5 avg -0.28790035587188406\n",
      "1406\n",
      "total -408.25 avg -0.2903627311522028\n",
      "1407\n",
      "total -412.0 avg -0.29282160625444\n",
      "1408\n",
      "total -411.0 avg -0.291903409090907\n",
      "1409\n",
      "total -412.0 avg -0.2924059616749447\n",
      "1410\n",
      "total -411.0 avg -0.2914893617021256\n",
      "1411\n",
      "total -410.0 avg -0.290574060949679\n",
      "1412\n",
      "total -406.25 avg -0.2877124645892331\n",
      "1413\n",
      "total -410.0 avg -0.2901627742392053\n",
      "1414\n",
      "total -409.0 avg -0.2892503536067872\n",
      "1415\n",
      "total -408.0 avg -0.28833922261483896\n",
      "1416\n",
      "total -409.0 avg -0.28884180790960245\n",
      "1417\n",
      "total -408.0 avg -0.2879322512350015\n",
      "1418\n",
      "total -407.0 avg -0.28702397743300223\n",
      "1419\n",
      "total -410.75 avg -0.2894644115574328\n",
      "1420\n",
      "total -411.75 avg -0.28996478873239234\n",
      "1421\n",
      "total -416.75 avg -0.2932793807178023\n",
      "1422\n",
      "total -416.75 avg -0.2930731364275647\n",
      "1423\n",
      "total -421.75 avg -0.2963808854532657\n",
      "1424\n",
      "total -420.75 avg -0.29547050561797544\n",
      "1425\n",
      "total -424.5 avg -0.29789473684210316\n",
      "1426\n",
      "total -429.5 avg -0.3011921458625505\n",
      "1427\n",
      "total -428.5 avg -0.30028030833917096\n",
      "1428\n",
      "total -427.5 avg -0.29936974789915755\n",
      "1429\n",
      "total -428.5 avg -0.2998600419874017\n",
      "1430\n",
      "total -432.25 avg -0.30227272727272514\n",
      "1431\n",
      "total -431.25 avg -0.30136268343815303\n",
      "1432\n",
      "total -430.25 avg -0.30045391061452303\n",
      "1433\n",
      "total -434.0 avg -0.3028611304954619\n",
      "1434\n",
      "total -433.0 avg -0.3019525801952559\n",
      "1435\n",
      "total -429.25 avg -0.2991289198606251\n",
      "1436\n",
      "total -428.25 avg -0.29822423398328485\n",
      "1437\n",
      "total -424.5 avg -0.2954070981210835\n",
      "1438\n",
      "total -428.25 avg -0.2978094575799701\n",
      "1439\n",
      "total -427.25 avg -0.29690757470465395\n",
      "1440\n",
      "total -426.25 avg -0.29600694444444237\n",
      "1441\n",
      "total -425.25 avg -0.2951075641915316\n",
      "1442\n",
      "total -424.25 avg -0.29420943134535166\n",
      "1443\n",
      "total -423.25 avg -0.29331254331254125\n",
      "1444\n",
      "total -428.25 avg -0.29657202216066275\n",
      "1445\n",
      "total -427.25 avg -0.29567474048442705\n",
      "1446\n",
      "total -426.25 avg -0.29477869986168537\n",
      "1447\n",
      "total -431.25 avg -0.29803040774015\n",
      "1448\n",
      "total -431.25 avg -0.2978245856353571\n",
      "1449\n",
      "total -435.0 avg -0.30020703933747206\n",
      "1450\n",
      "total -434.0 avg -0.2993103448275841\n",
      "1451\n",
      "total -439.0 avg -0.3025499655410041\n",
      "1452\n",
      "total -442.75 avg -0.3049242424242403\n",
      "1453\n",
      "total -442.75 avg -0.304714384033033\n",
      "1454\n",
      "total -441.75 avg -0.3038170563961465\n",
      "1455\n",
      "total -440.75 avg -0.30292096219931064\n",
      "1456\n",
      "total -441.75 avg -0.3033997252747232\n",
      "1457\n",
      "total -440.75 avg -0.30250514756348457\n",
      "1458\n",
      "total -445.75 avg -0.3057270233196138\n",
      "1459\n",
      "total -444.75 avg -0.30483207676490537\n",
      "1460\n",
      "total -443.75 avg -0.3039383561643815\n",
      "1461\n",
      "total -440.0 avg -0.3011635865845291\n",
      "1462\n",
      "total -443.75 avg -0.3035225718194234\n",
      "1463\n",
      "total -442.75 avg -0.30263157894736636\n",
      "1464\n",
      "total -439.0 avg -0.29986338797814005\n",
      "1465\n",
      "total -438.0 avg -0.298976109215015\n",
      "1466\n",
      "total -438.0 avg -0.2987721691678015\n",
      "1467\n",
      "total -443.0 avg -0.301976823449214\n",
      "1468\n",
      "total -438.0 avg -0.2983651226158018\n",
      "1469\n",
      "total -437.0 avg -0.2974812797821627\n",
      "1470\n",
      "total -438.0 avg -0.29795918367346735\n",
      "1471\n",
      "total -437.0 avg -0.29707681849082057\n",
      "1472\n",
      "total -436.0 avg -0.29619565217391103\n",
      "1473\n",
      "total -441.0 avg -0.29938900203665786\n",
      "1474\n",
      "total -446.0 avg -0.3025780189959274\n",
      "1475\n",
      "total -445.0 avg -0.30169491525423525\n",
      "1476\n",
      "total -448.75 avg -0.30403116531165103\n",
      "1477\n",
      "total -448.75 avg -0.3038253215978314\n",
      "1478\n",
      "total -447.75 avg -0.3029431664411346\n",
      "1479\n",
      "total -451.5 avg -0.30527383367139754\n",
      "1480\n",
      "total -450.5 avg -0.3043918918918898\n",
      "1481\n",
      "total -449.5 avg -0.30351114112086225\n",
      "1482\n",
      "total -445.75 avg -0.3007759784075553\n",
      "1483\n",
      "total -444.75 avg -0.2998988536749811\n",
      "1484\n",
      "total -443.75 avg -0.2990229110512109\n",
      "1485\n",
      "total -442.75 avg -0.29814814814814616\n",
      "1486\n",
      "total -441.75 avg -0.29727456258411644\n",
      "1487\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [16]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m game\u001B[38;5;241m.\u001B[39mnext_to_act[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m      9\u001B[0m     game\u001B[38;5;241m.\u001B[39mcreate_observation(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m     action \u001B[38;5;241m=\u001B[39m \u001B[43magent_0\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchoose_action\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobservations\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     game\u001B[38;5;241m.\u001B[39mimplement_action(\u001B[38;5;241m0\u001B[39m,action)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/Code/Python/PokerAI/Training/AgentSimulate.py:69\u001B[0m, in \u001B[0;36mAgent.choose_action\u001B[0;34m(self, observation)\u001B[0m\n\u001B[1;32m     67\u001B[0m observation\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m observation[\u001B[38;5;241m4\u001B[39m] \u001B[38;5;241m!=\u001B[39m observation[\u001B[38;5;241m6\u001B[39m] \u001B[38;5;28;01melse\u001B[39;00m observation\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     68\u001B[0m state \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mconvert_to_tensor([observation])\n\u001B[0;32m---> 69\u001B[0m probs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m action_probabilities \u001B[38;5;241m=\u001B[39m tfp\u001B[38;5;241m.\u001B[39mdistributions\u001B[38;5;241m.\u001B[39mCategorical(probs\u001B[38;5;241m=\u001B[39mprobs)\n\u001B[1;32m     71\u001B[0m action \u001B[38;5;241m=\u001B[39m action_probabilities\u001B[38;5;241m.\u001B[39msample()\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/engine/base_layer.py:1096\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1092\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_inputs(inputs, input_list)\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast_variable\u001B[38;5;241m.\u001B[39menable_auto_cast_variables(\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_dtype_object):\n\u001B[0;32m-> 1096\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mcall_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activity_regularizer:\n\u001B[1;32m   1099\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:92\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     90\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 92\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     94\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/engine/sequential.py:374\u001B[0m, in \u001B[0;36mSequential.call\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    372\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuilt:\n\u001B[1;32m    373\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_graph_network(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minputs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutputs)\n\u001B[0;32m--> 374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mSequential\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    376\u001B[0m outputs \u001B[38;5;241m=\u001B[39m inputs  \u001B[38;5;66;03m# handle the corner case where self.layers is empty\u001B[39;00m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m    378\u001B[0m   \u001B[38;5;66;03m# During each iteration, `inputs` are the inputs to `layer`, and `outputs`\u001B[39;00m\n\u001B[1;32m    379\u001B[0m   \u001B[38;5;66;03m# are the outputs of `layer` applied to `inputs`. At the end of each\u001B[39;00m\n\u001B[1;32m    380\u001B[0m   \u001B[38;5;66;03m# iteration `inputs` is set to `outputs` to prepare for the next layer.\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/engine/functional.py:451\u001B[0m, in \u001B[0;36mFunctional.call\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;129m@doc_controls\u001B[39m\u001B[38;5;241m.\u001B[39mdo_not_doc_inheritable\n\u001B[1;32m    433\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    434\u001B[0m   \u001B[38;5;124;03m\"\"\"Calls the model on new inputs.\u001B[39;00m\n\u001B[1;32m    435\u001B[0m \n\u001B[1;32m    436\u001B[0m \u001B[38;5;124;03m  In this case `call` just reapplies\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;124;03m      a list of tensors if there are more than one outputs.\u001B[39;00m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 451\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_internal_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    452\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/engine/functional.py:589\u001B[0m, in \u001B[0;36mFunctional._run_internal_graph\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    586\u001B[0m   \u001B[38;5;28;01mcontinue\u001B[39;00m  \u001B[38;5;66;03m# Node is not computable, try skipping.\u001B[39;00m\n\u001B[1;32m    588\u001B[0m args, kwargs \u001B[38;5;241m=\u001B[39m node\u001B[38;5;241m.\u001B[39mmap_arguments(tensor_dict)\n\u001B[0;32m--> 589\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;66;03m# Update tensor_dict.\u001B[39;00m\n\u001B[1;32m    592\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x_id, y \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(node\u001B[38;5;241m.\u001B[39mflat_output_ids, tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mflatten(outputs)):\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/engine/base_layer.py:1096\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1092\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_cast_inputs(inputs, input_list)\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast_variable\u001B[38;5;241m.\u001B[39menable_auto_cast_variables(\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_dtype_object):\n\u001B[0;32m-> 1096\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mcall_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activity_regularizer:\n\u001B[1;32m   1099\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:92\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     90\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 92\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     94\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     95\u001B[0m     \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/layers/core/dense.py:233\u001B[0m, in \u001B[0;36mDense.call\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    230\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mbias_add(outputs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 233\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactivation\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_ragged:\n\u001B[1;32m    236\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m original_inputs\u001B[38;5;241m.\u001B[39mwith_flat_values(outputs)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[1;32m   1081\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1082\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1084\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[1;32m   1085\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[1;32m   1086\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/activations.py:80\u001B[0m, in \u001B[0;36msoftmax\u001B[0;34m(x, axis)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;241m.\u001B[39mrank \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     79\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(axis, \u001B[38;5;28mint\u001B[39m):\n\u001B[0;32m---> 80\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     81\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     82\u001B[0m     \u001B[38;5;66;03m# nn.softmax does not support tuple axis.\u001B[39;00m\n\u001B[1;32m     83\u001B[0m     e \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(x \u001B[38;5;241m-\u001B[39m tf\u001B[38;5;241m.\u001B[39mreduce_max(x, axis\u001B[38;5;241m=\u001B[39maxis, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[1;32m   1081\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1082\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1084\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[1;32m   1085\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[1;32m   1086\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:3862\u001B[0m, in \u001B[0;36msoftmax_v2\u001B[0;34m(logits, axis, name)\u001B[0m\n\u001B[1;32m   3860\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3861\u001B[0m   axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 3862\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrap_2d_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgen_nn_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:3781\u001B[0m, in \u001B[0;36m_wrap_2d_function\u001B[0;34m(inputs, compute_op, dim, name)\u001B[0m\n\u001B[1;32m   3778\u001B[0m is_last_dim \u001B[38;5;241m=\u001B[39m (dim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (dim \u001B[38;5;241m==\u001B[39m shape\u001B[38;5;241m.\u001B[39mndims \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m   3780\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_last_dim:\n\u001B[0;32m-> 3781\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcompute_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3783\u001B[0m dim_val \u001B[38;5;241m=\u001B[39m dim\n\u001B[1;32m   3784\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dim, ops\u001B[38;5;241m.\u001B[39mTensor):\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py:10928\u001B[0m, in \u001B[0;36msoftmax\u001B[0;34m(logits, name)\u001B[0m\n\u001B[1;32m  10926\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[1;32m  10927\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m> 10928\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m  10929\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSoftmax\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogits\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m  10930\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[1;32m  10931\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "n_games = 10000\n",
    "total_chips = 0\n",
    "for ep in range(n_games):\n",
    "    print(ep)\n",
    "    game.reset()\n",
    "\n",
    "    while not game.done:\n",
    "        if game.next_to_act[0]==0:\n",
    "            game.create_observation(0)\n",
    "            action = agent_0.choose_action(game.observations[0])\n",
    "            game.implement_action(0,action)\n",
    "        else:\n",
    "            game.create_observation(1)\n",
    "            action = choose_action_q(game.observations[1])\n",
    "            game.implement_action(1,action)\n",
    "    result = game.stacks[0] - 5\n",
    "    total_chips += result\n",
    "    avg_chips = total_chips/(ep+0.00000000001)\n",
    "    print(\"total\", total_chips, \"avg\", avg_chips)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.run_ranges"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}